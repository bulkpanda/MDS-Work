{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "from variableUtils import *\n",
    "import variableUtils\n",
    "from Utils import *\n",
    "from ClassUtils import *\n",
    "from pprint import pprint\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from reportlab.lib.pagesizes import letter, landscape, A4, A3\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, PageBreak, Paragraph, Spacer, Image\n",
    "from reportlab.lib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reportlab.platypus import Paragraph, Spacer, KeepTogether, KeepInFrame\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import FormulaRule\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "from openpyxl import Workbook\n",
    "client = OpenAI()\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(sns.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Extra\\MCQ Creation'\n",
    "files = os.listdir(folder)\n",
    "dfDict = {}\n",
    "colTextDict = {}\n",
    "fullDf = pd.DataFrame(columns=['Question', 'Total Score', 'Section', 'Year', 'Question Code'])\n",
    "for file in files[:3]:\n",
    "    print(file)\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "    year = file.split(' ')[-1].split('.')[0]\n",
    "    questionDf = pd.DataFrame(columns = ['Question', 'Total Score', 'Section', 'Year', 'Question Code'])\n",
    "    df = pd.read_csv(f'{folder}/{file}')\n",
    "    # for i, col in enumerate(df.columns):\n",
    "    #     print(i, col)\n",
    "    # display(df.head(2))\n",
    "    columns = df.columns.to_list()\n",
    "    sectionACols = columns[10:90:2]\n",
    "    sectionBCols = columns[92:171:2]\n",
    "    print(f'# Section A columns: {len(sectionACols)}, {sectionACols}')\n",
    "    print(f'# Section B columns: {len(sectionBCols)}, {sectionBCols}')\n",
    "    # questionCols = [col for col in df.columns if re.match(r'\\d+:', col)]\n",
    "    # questionCols =questionCols[1:]\n",
    "    questionCols = sectionACols + sectionBCols\n",
    "    print(f'# questions: {len(questionCols)} || {questionCols}')\n",
    "    # markCols = df.columns.to_list()[11::2]\n",
    "    sectionAMarks = columns[11:91:2]\n",
    "    sectionBMarks = columns[93:172:2]\n",
    "    markCols = sectionAMarks + sectionBMarks\n",
    "    df[markCols] = df[markCols].apply(pd.to_numeric, errors='coerce')\n",
    "    print(f'# marks: {len(markCols)} || {markCols}')\n",
    "    totalSeries = df[markCols].sum(axis = 0, numeric_only=True)\n",
    "    df.loc['Column Total'] = totalSeries\n",
    "    # display(df.tail(3))\n",
    "    for i, col in enumerate(questionCols):\n",
    "        colText = col.split(':')[1]\n",
    "        colCode = f'Q{i+1}'\n",
    "        colTextDict[(colCode, year)] = colText\n",
    "        questionDf.loc[i] = [colText, totalSeries[i]/len(df), None, year, colCode]\n",
    "        if col in sectionACols:\n",
    "            questionDf.loc[i, 'Section'] = 'A'\n",
    "        elif col in sectionBCols:\n",
    "            questionDf.loc[i, 'Section'] = 'B'\n",
    "    print(len(colTextDict))\n",
    "    # for i, col in enumerate(sectionACols):\n",
    "    #     colText = col.split(':')[1]\n",
    "    #     questionDf.loc[i] = [colText, totalSeries[i], 'A']\n",
    "    \n",
    "    # for i, col in enumerate(sectionBCols):\n",
    "    #     colText = col.split(':')[1]\n",
    "    #     questionDf.loc[i] = [colText, totalSeries[i], 'B']\n",
    "    \n",
    "    questionDf['Year'] = year\n",
    "    # display(questionDf)\n",
    "    fullDf = pd.concat([fullDf, questionDf], axis = 0)\n",
    "\n",
    "    # break\n",
    "display(fullDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller model, effective for sentence similarity\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def getSimilarityMatrix(embeddings):\n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = util.pytorch_cos_sim(embeddings, embeddings).numpy()\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "fullDf['Embedding'] = fullDf['Question'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDf.sort_values(by = ['Section','Total Score'], ascending = [True, False], inplace = True)\n",
    "fullDf.reset_index(drop = True, inplace = True)\n",
    "display(fullDf)\n",
    "fullDf.to_csv(f'{folder}/Full MCQ.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "# df = pd.read_csv(f'{folder}/Full MCQ.csv')\n",
    "# # parse string to array\n",
    "# df['Embedding'] = df['Embedding'].apply(lambda x: ast.literal_eval(x))\n",
    "# # convert to numpy array\n",
    "# df['Embedding'] = df['Embedding'].apply(lambda x: np.array(x))\n",
    "# print(df['Embedding'][0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fullDf['Embedding'] = fullDf['Embedding'].apply(lambda x: np.array(x))\n",
    "# fullDf = df.copy()\n",
    "# print(fullDf['Embedding'].dtype)\n",
    "# print(fullDf['Embedding'][0].dtype)\n",
    "def createHist(data, ax, title):\n",
    "    sns.histplot(data = data, x = 'Total Score', kde = True, ax = ax, bins = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
    "    mean = data['Total Score'].mean()\n",
    "    median = data['Total Score'].median()\n",
    "    plt.axvline(mean, color='r', linestyle='--')\n",
    "    plt.axvline(median, color='g', linestyle='-')\n",
    "    ax.text(0.5, 0.5, f'Mean: {mean:.2f}', rotation=0, transform=ax.transAxes)\n",
    "    ax.text(0.5, 0.55, f'Median: {median:.2f}', rotation=0, transform=ax.transAxes)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "createHist(fullDf, ax, 'Overall')\n",
    "\n",
    "\n",
    "# do for each year\n",
    "years = fullDf['Year'].unique()\n",
    "for year in years:\n",
    "    yearDf = fullDf[fullDf['Year'] == year]\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    createHist(yearDf, ax, year)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectMostDissimilar(similarityMatrix, numQuestions=4):\n",
    "    n = similarityMatrix.shape[0]\n",
    "    # Ensure the diagonal of similarityMatrix is 0 to avoid self-similarity\n",
    "    # np.fill_diagonal(similarityMatrix, 0)\n",
    "    \n",
    "    # Initialize selected questions with the most dissimilar pair\n",
    "    first, second = np.unravel_index(np.argmin(similarityMatrix), similarityMatrix.shape)\n",
    "    selected = {first, second}\n",
    "    \n",
    "    while len(selected) < numQuestions:\n",
    "        maxDissimilarity = -np.inf\n",
    "        nextQuestion = None\n",
    "        for i in range(n):\n",
    "            if i not in selected:\n",
    "                # Calculate dissimilarity as the minimum similarity with the selected set\n",
    "                dissimilarity = sum(similarityMatrix[i][j] for j in selected)\n",
    "                if dissimilarity > maxDissimilarity:\n",
    "                    maxDissimilarity = dissimilarity\n",
    "                    nextQuestion = i\n",
    "        selected.add(nextQuestion)\n",
    "    \n",
    "    return list(selected)\n",
    "\n",
    "selectedDf = pd.DataFrame()\n",
    "for section in fullDf['Section'].unique():\n",
    "    sectionDf = fullDf[fullDf['Section'] == section]\n",
    "    for i in range(0, 10):\n",
    "        data = sectionDf.iloc[i*12:(i+1)*12]\n",
    "        print(len(data))\n",
    "        display(data)\n",
    "        # select four questions with most dissimilarities in embedding\n",
    "        similarity_matrix = getSimilarityMatrix(data['Embedding'].to_list())\n",
    "        df = pd.DataFrame(similarity_matrix, columns=[f\"Q{i+1}\" for i in range(12)], index=[f\"Q{i+1}\" for i in range(12)])\n",
    "        display(df)\n",
    "        selected = selectMostDissimilar(similarity_matrix, 4)\n",
    "        print(selected)\n",
    "        selectedData = data.iloc[selected]\n",
    "        display(selectedData)\n",
    "        selectedDf = pd.concat([selectedDf, selectedData], axis = 0)\n",
    "        #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedDf.reset_index(drop = True, inplace = True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "createHist(selectedDf, ax, 'Selected Questions')\n",
    "fig.savefig(f'{folder}/Selected Questions.png')\n",
    "selectedDf.drop(columns = ['Embedding'], inplace = True, errors='ignore')\n",
    "selectedDf.sort_values(by = ['Section','Year', 'Question Code'], ascending = [True, True, True], inplace = True)\n",
    "display(selectedDf)\n",
    "# selectedDf.to_csv(f'{folder}/Selected MCQ.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "# Convert dictionary to a list of comments and a matrix of embeddings\n",
    "def getCluster(df, colEmbedding):\n",
    "    embeddings = np.array(list(df[colEmbedding].values))\n",
    "    # Choose the number of clusters\n",
    "    linked = linkage(embeddings, 'ward')\n",
    "    # get the appropriate number of clusters from the dendrogram\n",
    "    # dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
    "    dendrogram(linked, truncate_mode='lastp', p=10)\n",
    "    plt.show()\n",
    "    num_clusters = int(input('Enter the number of clusters: '))\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans.fit(embeddings)\n",
    "    clusters = kmeans.labels_\n",
    "    df['Cluster'] = clusters\n",
    "\n",
    "    wcss = []\n",
    "    ran = range(1, 21)\n",
    "    for i in ran:\n",
    "        kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "        kmeans.fit(embeddings)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "\n",
    "    # Plot the Elbow Method\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(ran, wcss, marker='o')\n",
    "    plt.title('Elbow Method')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()\n",
    "\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
