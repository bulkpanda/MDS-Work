{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841.68, 1190.8799999999999)\n",
      "0.13.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "from variableUtils import *\n",
    "import variableUtils\n",
    "from Utils import *\n",
    "from ClassUtils import *\n",
    "from pprint import pprint\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from reportlab.lib.pagesizes import letter, landscape, A4, A3\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, PageBreak, Paragraph, Spacer, Image\n",
    "from reportlab.lib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reportlab.platypus import Paragraph, Spacer, KeepTogether, KeepInFrame\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import FormulaRule\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(sns.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating student wise data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'FullSpreadsheets\\CAF+v0.1_December+5,+2024\\CAF v0.1_December 5, 2024.csv'\n",
    "df = pd.read_csv(workbookpath, header=[0, 1])\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df[colId] = df[colId].astype(str)\n",
    "# row0 = df.iloc[0]\n",
    "ids = getStudentList()\n",
    "ids = [str(i) for i in ids]\n",
    "df = df[df[colId, colId].isin(ids)]\n",
    "print(df.shape)\n",
    "students = df[colId, colId].unique().tolist()\n",
    "students = sorted(students)\n",
    "# separate df based on students\n",
    "i=0\n",
    "path = f'{folder}\\\\studentwise data'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "for id in students:\n",
    "    i+=1\n",
    "    studentDf = df[df[colId, colId] == id]\n",
    "    # add row 0 to the student df\n",
    "    # studentDf = pd.concat([row0.to_frame().T, studentDf])\n",
    "    print(f'Writing student {i}', id, studentDf.shape)\n",
    "    # display(studentDf.head())\n",
    "    studentDf.to_csv(f'{path}/{id}.csv', index=False)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the checklist sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script\n",
    "workbookPath = 'FullSpreadsheets\\\\CAF+v0.1_December+5,+2024\\\\CAF v0.1_December 5, 2024 split.xlsx'\n",
    "workbook = load_workbook(workbookPath)\n",
    "folder, filename = os.path.split(workbookPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to adjust column widths\n",
    "def adjustColumnWidths(worksheet):\n",
    "    for col in worksheet.columns:\n",
    "        maxLength = 0\n",
    "        colLetter = col[0].column_letter  # Get the column letter\n",
    "        for cell in col:\n",
    "            if cell.value:\n",
    "                maxLength = max(maxLength, len(str(cell.value)))\n",
    "        worksheet.column_dimensions[colLetter].width = maxLength + 2  # Adjust width\n",
    "\n",
    "# Function to write DataFrame to Excel and adjust columns\n",
    "def writeSheetWithColumnAdjustment(df, sheetName):\n",
    "    df.to_excel(writer, sheet_name=sheetName, index=False)\n",
    "    workbook = writer.book\n",
    "    worksheet = workbook[sheetName]\n",
    "    adjustColumnWidths(worksheet)\n",
    "\n",
    "\n",
    "outputFilename = os.path.join(folder, 'checklists.xlsx')\n",
    "\n",
    "\n",
    "with open(mcReferenceFile) as f:\n",
    "    mcReference = json.load(f)\n",
    "\n",
    "for sheet in workbook.sheetnames:\n",
    "    sheetName = sheet.replace('_', ' ')\n",
    "    df = pd.DataFrame(columns=[\n",
    "    'Marking Checklist',\n",
    "    'Full Question',\n",
    "    'Type (MCQ/Subjective)',\n",
    "    'Importance (1-10) 1 being the least important',\n",
    "    'Difficulty (1-10) 1 being the least difficult'\n",
    "    ])\n",
    "    sheetdf = pd.read_excel(workbookPath, sheet_name=sheet)\n",
    "    mcCols = [col for col in sheetdf.columns if 'MC' in col and 'supervisor' in col]\n",
    "    code = sheet.split('_')[0]\n",
    "    mcCols = [col for col in mcCols if code in col]\n",
    "    mcCols = [re.sub(r'[^\\x00-\\x7F]+', '', item) for item in mcCols]\n",
    "    print(mcCols)\n",
    "    mcColsText = [mcReference[col] for col in mcCols if col in mcReference]\n",
    "    print(mcColsText)\n",
    "    # add mcCols to the Marcoing Checklist column\n",
    "    df['Marking Checklist'] = [x.split('_')[1] for x in mcCols]\n",
    "    df['Full Question'] = [mcColsText[i] if i<len(mcColsText) else pd.NA for i in range(len(mcCols))]\n",
    "    if os.path.exists(outputFilename):\n",
    "        with pd.ExcelWriter(outputFilename, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            writeSheetWithColumnAdjustment(df, sheetName)\n",
    "    else:\n",
    "        with pd.ExcelWriter(outputFilename, engine='openpyxl', mode = 'w') as writer:\n",
    "            writeSheetWithColumnAdjustment(df, sheetName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'Extra\\DCD\\DCD_Pros_clinical_forms_2024_and_comments.xlsx'\n",
    "workbook, folder, file = loadWorkbook(workbookpath)\n",
    "infoDf = pd.DataFrame(columns=['Student', 'Attribute', 'Value Counts'])\n",
    "scoreDf = pd.DataFrame(columns=['Student', 'Attribute', 'Score'])\n",
    "for sheet in workbook.sheetnames[:-1]:\n",
    "\n",
    "    print(sheet)\n",
    "    df = pd.read_excel(workbookpath, sheet_name=sheet, index_col=None)\n",
    "    sheet = sheet.split('_DCD')[0].replace('_', ' ')\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.drop(0)\n",
    "    colAttribute = 'Attribute'\n",
    "    colScores = df.columns.to_list()[2:8]\n",
    "    print(colScores )\n",
    "    # get value counts of each attribute\n",
    "    df[colAttribute] = df[colAttribute].str.strip()\n",
    "    for i, row in df.iterrows():\n",
    "        valueCounts = row[colScores].value_counts()\n",
    "        print(valueCounts)\n",
    "        infoDf = pd.concat([infoDf, pd.DataFrame({'Student': [sheet], 'Attribute': [row[colAttribute]], 'Value Counts': [valueCounts]})])\n",
    "    \n",
    "    scoreCounts = df[colScores].apply(pd.Series.value_counts).fillna(0)\n",
    "    \n",
    "    df[colScores] = df[colScores].replace({'S':0, 'P': 1, \"M\":2, \"G\":3, 'E':4})\n",
    "    df['Overall'] = df[colScores].mean(axis=1, numeric_only=True, skipna=True)\n",
    "    for attr in df[colAttribute].dropna().unique():\n",
    "        scoreDf = pd.concat([scoreDf, pd.DataFrame({'Student': [sheet], 'Attribute': [attr], 'Score': [df[df[colAttribute] == attr]['Overall'].mean()]})])\n",
    "    scoreDf = pd.concat([scoreDf, pd.DataFrame({'Student': [sheet], 'Attribute': ['Overall'], 'Score': [df['Overall'].mean()]})])\n",
    "    # display(df)\n",
    "    # display(scoreCounts)\n",
    "# display(infoDf)\n",
    "# drop na attributes\n",
    "infoDf = infoDf.dropna()\n",
    "display(infoDf.head())\n",
    "# display(scoreDf.head(50))\n",
    "scorepivot = scoreDf.pivot(index='Student', columns='Attribute', values='Score')\n",
    "display(scorepivot)\n",
    "scorepivot.to_excel('Extra\\DCD\\scores.xlsx')\n",
    "# for each attribute plot a stacked bar chart of the value counts with the student as the x axis\n",
    "# Creating plots for each attribute with students on x-axis\n",
    "attributes = infoDf[\"Attribute\"].unique()\n",
    "color_map = colorMap = {\n",
    "    'S': '#8B0000',  # Dark Red\n",
    "    'P': '#D2691E',  # Chocolate\n",
    "    'M': '#800080',  # Olive\n",
    "    'G': '#006400',  # Forest Green\n",
    "    'E': '#0022BB'   # Dark Green\n",
    "}\n",
    "# import colors form seaborn\n",
    "# color_map = sns.color_palette(\"tab10\").as_hex()\n",
    "# color_map = dict(zip(['S', 'P', 'M', 'G', 'E'], color_map))\n",
    "for attribute in attributes:\n",
    "    attribute_data = infoDf[infoDf[\"Attribute\"] == attribute]\n",
    "    \n",
    "    # Expand \"Value Counts\" for plotting\n",
    "    expanded_counts = attribute_data[\"Value Counts\"].apply(pd.Series).fillna(0).astype(int)\n",
    "    plot_data = pd.concat([attribute_data[\"Student\"], expanded_counts], axis=1).set_index(\"Student\")\n",
    "    \n",
    "    # Plot\n",
    "    plot_data.plot(kind=\"bar\", stacked=True, figsize=(10, 6), color = [color_map[col] for col in plot_data.columns])\n",
    "    plt.title(f\"{attribute}\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Student\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Performance Levels\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH1\\EOY Restorative\\data.xlsx'\n",
    "folder, filename, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath, sheet_name='Sheet1')\n",
    "rubricQues = ['TS', 'ES']\n",
    "mcCols = [col for col in df.columns if 'MC' in col]\n",
    "df[colCEReason] = df[['Q2.6_6', 'Q2.6_7', 'Q2.6_8', 'Q2.6_9', 'Q2.6_10', 'CI Details']].apply(lambda x: '\\n'.join(x.dropna().astype(str)), axis=1)\n",
    "df.drop(['Q2.6_6', 'Q2.6_7', 'Q2.6_8', 'Q2.6_9', 'Q2.6_10'], axis=1, inplace=True)\n",
    "# df.to_excel(workbookpath, sheet_name='Sheet1', index=False) \n",
    "fullTextDict = {col: df.loc[0, col] for col in mcCols}\n",
    "df = df.drop([0], axis=0)\n",
    "df[colId] = df[colId].astype(int)\n",
    "studenList = getStudentList(cohort = 'BOH1 (2024)')\n",
    "# find the missing students\n",
    "missingStudents = set(studenList) - set(df[colId].unique())\n",
    "print(missingStudents)\n",
    "print(df[colId].value_counts())\n",
    "students = df[colId].unique()\n",
    "for col in mcCols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "newRubricQues = set()\n",
    "df.sort_values(by=[colId, 'Examiners'], inplace=True)\n",
    "dfAgg = aggregator(df, mcCols, colCE, colCEReason, [colComments], 'Examiners')\n",
    "df = vectoriseRubricQues(df, rubricQues, newRubricQues)\n",
    "dfAgg = vectoriseRubricQues(dfAgg, rubricQues, newRubricQues)\n",
    "# get a total of columns in mcCols and newRubricQues\n",
    "calcCols = mcCols + list(newRubricQues)\n",
    "df.loc['Column Total'] = df[calcCols].sum(numeric_only=True, axis=0)\n",
    "\n",
    "# sort based on the total\n",
    "df = df.sort_values(by='Column Total', axis=1, ascending=False)\n",
    "df['MC Score'] = (df[mcCols].sum(axis=1)/len(mcCols)).round(2)\n",
    "rubricW = { 'TS': .1, 'ES': .1}\n",
    "rubricDenom = { 'TS': 3, 'ES': 4}\n",
    "df['Rubric Score'] = df.apply(lambda row: sum((row[ques]/rubricDenom[ques]) * rubricW[ques] for ques in rubricQues), axis=1)/sum(rubricW.values())\n",
    "df['Rubric Score'] = df['Rubric Score'].round(2)    \n",
    "df['Total'] = ((df['MC Score']*0.8 + df['Rubric Score']*0.2)*100).round(2)\n",
    "df['Total CE Penalty 20%'] = df['Total']*df[colCE].apply(lambda x: 0.8 if x == 'Yes' else 1)\n",
    "df['Total CE Penalty 20%'] = df['Total CE Penalty 20%'].round(2)\n",
    "df = df.sort_values(by='Total', axis=0, ascending=False)\n",
    "saveDf(df, f'{folder}\\\\{filename} guttman.xlsx', 'Sheet1', len(mcCols) + len(list(newRubricQues)))\n",
    "\n",
    "dfAgg.loc['Column Total'] = dfAgg[calcCols].sum(numeric_only=True, axis=0)\n",
    "dfAgg = dfAgg.sort_values(by='Column Total', axis=1, ascending=False)\n",
    "dfAgg['MC Score'] = (dfAgg[mcCols].sum(axis=1)/len(mcCols)).round(2)\n",
    "dfAgg['Rubric Score'] = dfAgg.apply(lambda row: sum((row[ques]/rubricDenom[ques]) * rubricW[ques] for ques in rubricQues), axis=1)/sum(rubricW.values())\n",
    "dfAgg['Rubric Score'] = dfAgg['Rubric Score'].round(2)\n",
    "dfAgg['Total'] = ((dfAgg['MC Score']*0.8 + dfAgg['Rubric Score']*0.2)*100).round(2)\n",
    "dfAgg['Total CE Penalty 20%'] = dfAgg['Total']*dfAgg[colCE].apply(lambda x: 0.8 if x == 'Yes' else 1)\n",
    "dfAgg['Total CE Penalty 20%'] = dfAgg['Total CE Penalty 20%'].round(2)\n",
    "dfAgg = dfAgg.sort_values(by='Total', axis=0, ascending=False)\n",
    "saveDf(dfAgg, f'{folder}\\\\{filename} guttman best.xlsx', 'Sheet1', len(mcCols) + len(list(newRubricQues)))\n",
    "colSupervisor = 'Examiners'\n",
    "paricounts, pair, dfBest = getSupervisorPairs(df, dfAgg, folder, filename)\n",
    "display(pair)\n",
    "# display(dfBest.head())\n",
    "paricounts.to_excel(f'{folder}\\\\{filename} paircounts.xlsx', index=False)\n",
    "pair.to_excel(f'{folder}\\\\{filename} difference.xlsx', index=False)\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workbookpath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\Rachel Data\\CAF v0.1_September 30, 2024_18.49.csv'\n",
    "workbookpath = 'FullSpreadsheets\\CAF+v0.1_December+5,+2024\\CAF v0.1_December 5, 2024.csv'\n",
    "# workbookpath = 'BOH2\\CAF+v0.1_October+14,+2024 few students\\CAF v0.1_October 14, 2024_16.56.csv'\n",
    "# workbookpath = 'BOH3\\CAF+v0.1_October+22,+2024_22.00\\CAF v0.1_October 22, 2024_22.00.csv'\n",
    "# savepath = 'BOH2\\Asma Fatima\\CAF v0.1_October 14, 2024_16.24 filtered.xlsx'\n",
    "# savepath = 'DDS2\\CAF+v0.1_October+17,+2024_20.45\\CAF v0.1_October 17, 2024_20.45 filtered.xlsx'\n",
    "# savepath = None\n",
    "savepath = 'FullSpreadsheets\\CAF+v0.1_December+5,+2024\\CAF v0.1_December 5, 2024 filtered.xlsx'\n",
    "guttmancreator = CreateGuttman(savepath, workbookpath) \n",
    "guttmancreator.saveSplitDf()\n",
    "# splitDfPath = 'FullSpreadsheets\\CAF+v0.1_October+7,+2024_18.49\\CAF v0.1_October 7, 2024_18.49 split.xlsx'\n",
    "# splitDfPath = 'FullSpreadsheets\\CAF+v0.1_December+5,+2024\\CAF v0.1_December 5, 2024 split.xlsx'\n",
    "# guttmancreator.createGuttman(splitDfPath, 'FullSpreadsheets\\CAF+v0.1_December+5,+2024\\CAF v0.1_December 5, 2024 guttman.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select from dates 5th Aug to 21st Sept\n",
    "folder, file = guttmancreator.folder, guttmancreator.fileName\n",
    "print(folder, file)\n",
    "df = guttmancreator.df\n",
    "print(df[colId].unique())\n",
    "df[colDate] = pd.to_datetime(df[colDate], format = '%d/%m/%Y')\n",
    "\n",
    "# Define the date range\n",
    "start_date = pd.to_datetime(\"2024-09-23\")\n",
    "end_date = pd.to_datetime(\"2024-11-30\")\n",
    "\n",
    "# Select rows within the date range\n",
    "print(df[colId].unique())\n",
    "filtered_df = df[(df[colDate] >= start_date) & (df[colDate] <= end_date)]\n",
    "filtered_df = filtered_df.reset_index(drop = True)\n",
    "print(filtered_df[colDate].min(), filtered_df[colDate].max())\n",
    "filtered_df[colDate] = filtered_df[colDate].dt.strftime('%d/%m/%Y')\n",
    "print(filtered_df[colId].unique())\n",
    "guttmancreator.df = filtered_df\n",
    "# splitDfPath = 'DDS2\\CAF+v0.1_October+17,+2024_20.45\\CAF v0.1_October 17, 2024_20.45 split.xlsx'\n",
    "guttmancreator.createGuttman(splitDfPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loaded workbook: FullSpreadsheets\\\\CAF+v0.1_December+5,+2024 | CAF '\n",
      " 'v0.1_December 5, 2024 split | .xlsx')\n",
      "(\"Workbook sheets: ['011_COE', '012_POE', '013_LIMITED OE', \"\n",
      " \"'014_CONSULTATION', '022_I-O RAD', '061_VITALITY', '071_DIAGNOSTIC MODEL', \"\n",
      " \"'072_PHOTOS', '074_PHYSICAL MODELS', '111_CLINIC', '111_SIM', '113_CLINIC', \"\n",
      " \"'113_SIM', '114_CLINIC', '114_SIM', '115_CLINIC', '121_CLINIC REMIN', \"\n",
      " \"'121_SIM REMIN', '123_CLINIC', '123_SIM', '131_CLINIC', '141_CLINIC', \"\n",
      " \"'142_CLINIC', '161_CLINIC', '161_SIM', '165_CLINIC', '165_SIM', \"\n",
      " \"'221_CLINIC', '221_SIM', '222_CLINIC', '222_SIM', '311_CLINIC', '311_SIM', \"\n",
      " \"'386_CLINIC', '386_SIM', '411_CLINIC', '411_SIM', '414_CLINIC CVEK', \"\n",
      " \"'414_CLINIC DECIDUOUS', '414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM \"\n",
      " \"ACCESS', '415_SIM WORK LENGTH', '416_SIM RCT ADD', '417_SIM CONE FIT', \"\n",
      " \"'417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '511_CLINIC', \"\n",
      " \"'511_SIM', '512_CLINIC', '513_SIM', '514_SIM', '521_CLINIC', '521_SIM', \"\n",
      " \"'522_CLINIC', '522_SIM', '523_CLINIC', '523_SIM', '524_CLINIC', '524_SIM', \"\n",
      " \"'525_CLINIC', '525_SIM', '531_CLINIC', '531_SIM', '532_CLINIC', '532_SIM', \"\n",
      " \"'533_CLINIC', '533_SIM', '534_CLINIC', '534_SIM', '535_CLINIC', '535_SIM', \"\n",
      " \"'536_SIM', '545_CLINIC', '545_SIM', '555_CLINIC', '555_SIM', '572_CLINIC', \"\n",
      " \"'572_SIM', '574_SIM', '575_SIM', '577_CLINIC', '577_SIM', '578_CLINIC', \"\n",
      " \"'578_SIM', '579_BONDING', '586_CLINIC', '586_SIM SEPARATORS', '586_SIM TOOTH \"\n",
      " \"PREP', '587_CLINIC', '587_SIM SEPARATORS', '587_SIM TOOTH PREP', \"\n",
      " \"'613_CLINIC', '613_SIM', '615_CLINIC', '615_SIM', '618_CLINIC', '618_SIM', \"\n",
      " \"'625_CLINIC', '627_CLINIC', '631_CLINIC', '631_SIM', '651_CLINIC', \"\n",
      " \"'655_CLINIC', '656_SIM', '711_FINISH', '711_PRIMARY', '711_REVIEW', \"\n",
      " \"'711_SECONDARY', '712_SECONDARY', '714_SECONDARY', '741_ADJUSTMENT', \"\n",
      " \"'LA_BLOCK', 'LA_INFILTRATION']\")\n"
     ]
    }
   ],
   "source": [
    "filepath = 'FullSpreadsheets\\CAF+v0.1_December+5,+2024\\CAF v0.1_December 5, 2024 split.xlsx'\n",
    "workbook, folder, file = loadWorkbook(filepath)\n",
    "dfAll = pd.DataFrame(columns=[colResponseId, colComments, colComments2, 'Item'])\n",
    "for sheet in workbook.sheetnames:\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    df = df[[colResponseId, colComments, colComments2]]\n",
    "    df['Item'] = sheet\n",
    "    dfAll = pd.concat([dfAll, df])\n",
    "    \n",
    "dfAll.to_excel(f'{folder}\\\\{file} comments.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'Extra\\Postgraduate Clinical Evaluation Paeds_October 27, 2024_19.20.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath)\n",
    "df =df[1:]\n",
    "# for i, col in enumerate(df.columns):\n",
    "#     print(i, col)\n",
    "markCols = df.columns.to_list()[24:67]\n",
    "print(markCols)\n",
    "df[markCols] = df[markCols].replace({'Completed independently (competent)': 3, 'Completed with minimal assistance':2,\n",
    "                                     'Completed with substantial assistance':1, 'No basis for evaluation': np.nan})\n",
    "df[markCols] = df[markCols].astype('Int64')\n",
    "rubricCols = df.columns.to_list()[68:74]\n",
    "print(rubricCols)\n",
    "df[rubricCols] = df[rubricCols].replace({'ALWAYS': 4, 'OFTEN':3, 'SOMETIMES':2, 'RARELY':1})\n",
    "df[rubricCols] = df[rubricCols].astype('Int64')\n",
    "# print(df['Q22'].unique())   \n",
    "replacement_dict = {\n",
    "    'Far exceeds expected level of performance considering stage of training: H1 (80-100)': 5,\n",
    "    'Exceeds expected level of performance considering stage of training: H 2A (75-79) and B (70-74)': 4,\n",
    "    'At expected level of performance considering stage of training: H3 (65-69)': 3,\n",
    "    'Barely meets expected level of performance considering stage of training: P (50-64)': 2,\n",
    "    'Does not meet expected level of performance considering stage of training: N (0-49)': 1\n",
    "}\n",
    "df['Q22'] = df['Q22'].replace(replacement_dict)\n",
    "# display(df.head())\n",
    "df['Marks Total'] = df[markCols].sum(axis = 1)\n",
    "# denominator is 3*number of non nan values in markCols row\n",
    "df['Denominator'] = 3*df[markCols].notna().sum(axis = 1)    \n",
    "df['Marks Total'] = (df['Marks Total'])/(3*df[markCols].notna().sum(axis = 1))\n",
    "df.rename(columns = {'Q22':'Final Grade'}, inplace = True)\n",
    "# df.to_excel(f'{folder}\\\\{file} filtered.xlsx', index = False)\n",
    "# display(df)\n",
    "sns.scatterplot(data = df, y = 'Marks Total', x = 'Final Grade')\n",
    "# draw a line of best fit\n",
    "x = df['Final Grade']\n",
    "y = df['Marks Total']\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "plt.plot(x, m*x + b)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOH3 Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH3\\\\2024+BOH3+Portfolio+Presentation_November+4,+2024_11.12\\\\2024 BOH3 Portfolio Presentation_November 4, 2024_11.12.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath)\n",
    "contentCol = 'Content_1'\n",
    "orgCol = 'Organisation_1'\t\n",
    "presCol1 = 'Presentation design_1'\t\n",
    "presCol2 = 'Presentation skills_1'\n",
    "markCol = [contentCol, orgCol, presCol1, presCol2]\n",
    "fullnameDict = {col: df.iloc[0][col] for col in markCol}\n",
    "df = df.iloc[1:]\n",
    "replaceDictContent = {'Provides very clear and concise overview of the how you engaged with the ePortfolio to document your development over the entire degree.': 4,\n",
    "               'Provides an overview of how you engaged with the ePortfolio to document your development over the entire degree.': 3,\n",
    "               'Attempted an overview of how you engaged with the ePortfolio to document your development over the entire degree.': 2}\n",
    "replaceDictOrg = {'Information is organised in a very clear, concise and logical manner. Presentation sections are very well structured with very clear links to ensure the presentation flows well.': 4,\n",
    "                  'Information is organised in logical manner, but more clarity needed. Presentation sections are generally well structured but links between sections could be more clearly established.': 3,\n",
    "                  'Information presented in separate sections but not consistent. Attempted to link presentation sections but structure compromised flow of the presentation.': 2}\n",
    "replaceDictPres1 = {'Proficient use of slide design, font, colour and graphics in the presentation. Visual aids appropriate for the research topic and mostly complement the style of presentation.': 4,\n",
    "        'Skilful use of slide design, font, colour and graphics to enhance the presentation. Visual aids highly appropriate for the research topic and complement the style of presentation.': 3,\n",
    "        'Slide design did not complement the style of the presentation. Attempted to use visual aids in the presentation but they did not complement the presentation style.': 2}\n",
    "replaceDictPres2 = {'Highly effective display of oral communication skills through speaking clearly and distinctly, and at an appropriate volume and speed. Demonstrates strong interest in and enthusiasm for the topic. Highly engaging delivery style and communication style. Articulately and confidently answers audience questions.': 4,\n",
    "                    'Effective display of oral communication skills but more dynamics in speech rhythm and tone needed. Demonstrates enthusiasm for the topic but delivery style could be more engaging. Clearly answers audience questions.': 3,\n",
    "                    'Oral communication skills adequate but delivery style detracts from the presentation. Lacks enthusiasm for the research topic. Answers audience questions but more clarity needed in responses.': 2,\n",
    "                    'Lack of effective oral communication skills, and pronunciation errors and hesitation in speech affected the presentation. Shows no interest in the research topic. Unable to answer or respond to audience questions.': 1}\n",
    "replaceDict = {contentCol: replaceDictContent, orgCol: replaceDictOrg, presCol1: replaceDictPres1, presCol2: replaceDictPres2}\n",
    "for col in markCol:\n",
    "    df[col] = df[col].map(replaceDict[col])\n",
    "\n",
    "df['Total'] = df[markCol].sum(axis = 1)\n",
    "colSupervisor='Assessor Name'\n",
    "df.sort_values(by = [colId, colSupervisor], inplace = True)\n",
    "display(df.head())\n",
    "df.to_excel(f'{folder}\\\\{file} filtered.xlsx', index = False)\n",
    "print(df[colId].value_counts())\n",
    "# calculate the difference for each student marked by the two markers})\n",
    "dfAgg  = df.groupby([colId]).agg({colSupervisor: lambda x: ', '.join(x), 'Total': lambda x: x.iloc[0] - x.iloc[1]}).reset_index()\n",
    "dfAgg = dfAgg.rename(columns = {'Total': 'Difference'})\n",
    "display(dfAgg.head())\n",
    "\n",
    "\n",
    "# Plotting\n",
    "unique_supervisor_pairs = dfAgg[colSupervisor].unique()\n",
    "color_palette = plt.cm.get_cmap('tab10', len(unique_supervisor_pairs))\n",
    "print(unique_supervisor_pairs)\n",
    "color_dict = {pair: color_palette(i) for i, pair in enumerate(dfAgg[colSupervisor].unique())}\n",
    "plt.figure(figsize=(10, 6))\n",
    "dfAgg.sort_values(by = 'Difference', inplace = True, ascending = False)\n",
    "bars = plt.bar(dfAgg[colId], dfAgg['Difference']/16*100, color=[color_dict[pair] for pair in unique_supervisor_pairs])\n",
    "# Creating a legend\n",
    "handles = [plt.Rectangle((0,0),1,1, color=color_dict[pair]) for pair in unique_supervisor_pairs]\n",
    "plt.legend(handles, unique_supervisor_pairs, title='Supervisors', loc='best')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Student ID')\n",
    "plt.ylabel('Difference in Marks (%)')\n",
    "plt.title('Difference in Marks by Supervisor Pair')\n",
    "# plt.legend(title='Supervisors', loc='best')\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.4\n",
    "         )\n",
    "plt.savefig(f'{folder}\\\\Difference in Marks by Supervisor Pair.png')\n",
    "\n",
    "# Get the average total for each student\n",
    "dfAvg = df.groupby([colId]).agg({'Total': 'mean'}).reset_index()\n",
    "# Get the maximum total for each student\n",
    "dfMax = df.groupby([colId]).agg({'Total': 'max'}).reset_index()\n",
    "# get max for each markColumn\n",
    "dfMaxMark = df.groupby([colId]).agg({col: 'max' for col in markCol}).reset_index()\n",
    "dfMaxMark['Total'] = dfMaxMark[markCol].sum(axis = 1)   \n",
    "# combine the totals\n",
    "dfAvg['Max of Total'] = dfMax['Total']\n",
    "dfAvg['Total with max for each checklist'] = dfMaxMark['Total']\n",
    "dfAvg.rename(columns = {'Total': 'Average'}, inplace = True)\n",
    "display(dfAvg.head())\n",
    "dfAvg.to_excel(f'{folder}\\\\Average and Max Marks.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDS4 Viva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'DDS4\\\\2024+DDS+4+Case+Pres+Viva_October+28,+2024_15.16\\\\2024 DDS 4 Case Pres Viva_October 28, 2024_15.16.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "gradeFile  = pd.read_excel(workbookpath, sheet_name = 'Sheet1')\n",
    "gradeFile[colId] = gradeFile[colId].astype(int)\n",
    "df = pd.read_excel(workbookpath, sheet_name = 'Marks')\n",
    "df[colId] = df[colId].astype(int)\n",
    "colTotalGrade = 'Unposted Final Score'\n",
    "totalGradeDict = {row[colId]: row[colTotalGrade] for index, row in gradeFile.iterrows()} \n",
    "df[colTotalGrade] = df[colId].map(totalGradeDict)\n",
    "# display(df)\n",
    "# scatter plot of Overall Grade vs Total Grades\n",
    "# color code based on Examiners column\n",
    "plt.figure(figsize = (10, 8))\n",
    "sns.scatterplot(x = 'Overall Grade', y = colTotalGrade, data = df)\n",
    "# sns.scatterplot(x = 'Overall Grade', y = colTotalGrade, data = df)\n",
    "plt.xlabel('Presentation Grade')\n",
    "plt.ylabel('Total Grade')\n",
    "# df[(df['Overall Grade']<55) & (df[colTotalGrade] > 55)] marks these as red outliers\n",
    "plt.scatter(df[(df['Overall Grade']<55) & (df[colTotalGrade] > 50)]['Overall Grade'], df[(df['Overall Grade']<55) & (df[colTotalGrade] > 50)][colTotalGrade], color = 'red')\n",
    "# plt.scatter(df[(df['Overall Grade']>65) & (df[colTotalGrade] < 55)]['Overall Grade'], df[(df['Overall Grade']>65) & (df[colTotalGrade] < 55)][colTotalGrade], color = 'green')\n",
    "plt.show()\n",
    "# display(df[(df['Overall Grade']<55) & (df[colTotalGrade] > 55)])\n",
    "marksCol = gradeFile.columns.to_list()[7:20]\n",
    "gradeFile[marksCol] = gradeFile[marksCol].fillna(0)\n",
    "# create a vector simlarity matrix for the marks\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "marksMatrix = gradeFile[marksCol].values\n",
    "similarityMatrix = cosine_similarity(marksMatrix)\n",
    "similarityDf = pd.DataFrame(similarityMatrix, columns = gradeFile[colId], index = gradeFile[colId])   \n",
    "# with pd.ExcelWriter(workbookpath, mode='a', engine='openpyxl') as writer:\n",
    "#     similarityDf.to_excel(writer, sheet_name='Similarity Matrix')\n",
    "# print(marksCol)\n",
    "# find the top 5 similar students for 1137740 914405 911686\n",
    "def getTop5SimilarStudents(studentId, similarityDf):\n",
    "    similarityDfCopy = similarityDf.copy()\n",
    "    # remove the ids that are given in the comment above\n",
    "    similarityDfCopy = similarityDfCopy.drop(index = [1137740, 914405, 911686])\n",
    "    top5 = similarityDfCopy[studentId].sort_values(ascending = False).head(6)\n",
    "    display(gradeFile[gradeFile[colId].isin(top5.index)])\n",
    "    print(f'Grade= {gradeFile[gradeFile[colId] == studentId][colTotalGrade]}')\n",
    "    # get average of the top 5 students from df['Overall Grade]\n",
    "    top5Id = top5.index.to_list()\n",
    "    dfsim = df[df[colId].isin(top5Id)]\n",
    "    # display(dfsim)\n",
    "    average = dfsim['Overall Grade'].mean()\n",
    "    print(f'Average of the top 5 students for {studentId} is {average}')\n",
    "    return top5\n",
    "\n",
    "top5_1 = getTop5SimilarStudents(1137740, similarityDf)\n",
    "top5_2 = getTop5SimilarStudents(914405, similarityDf)\n",
    "top5_3 = getTop5SimilarStudents(911686, similarityDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath =  'DDS4\\\\2024+DDS+4+Case+Pres+Viva_October+28,+2024_15.16\\\\2024 DDS 4 Case Pres Viva_October 28, 2024_15.16.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath, sheet_name = 'Clean')\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(i, col)\n",
    "df.rename(columns = {'Marks Diagnosis/es': 'Marks for Diagnosis'}, inplace = True)\n",
    "colset1 = df.columns.to_list()[6:18]\n",
    "colset2 = df.columns.to_list()[18:29]\n",
    "colset3 = df.columns.to_list()[29:35]\n",
    "colset4 = df.columns.to_list()[35:40]\n",
    "marksCol = ['Marks for Audience Engagement', 'Marks for Delivery of Presentation', 'Marks for Information Gathering', \n",
    "    'Marks for Diagnosis', 'Overall Marks for Treatment Plan', 'Overall marks for Clinical Outcomes ', 'Marks Knowledge']\n",
    "demoninator = [5, 5, 10, 30, 25, 25, 100]\n",
    "denominator = dict(zip(marksCol, demoninator))\n",
    "print(denominator)\n",
    "# Create a table for each set of columns\n",
    "for i, row in df.iterrows():\n",
    "    elements = []\n",
    "    studentId = row[colId]\n",
    "    studentName = row[colNameG] + ' ' + row[colNameF]\n",
    "    studentName = studentName.strip()\n",
    "    doc = SimpleDocTemplate(f\"{folder}/{studentId} ({studentName}).pdf\", pagesize=pageSize,\n",
    "                            rightMargin=rightMargin, leftMargin=leftMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    elements.append(Paragraph(f\"{studentName} ({studentId})\", headingStyle))\n",
    "    elements.append(Spacer(1, 0.5 * inch))\n",
    "    \n",
    "    # row.fillna('----', inplace=True)\n",
    "    totalMarks = 0\n",
    "    for col in row.index:\n",
    "        if col in marksCol:\n",
    "            totalMarks += int(row[col])\n",
    "            row[col] = str(int(row[col])) + ' / ' + str(denominator[col])\n",
    "\n",
    "    # Engagement, Information, Diagnosis\n",
    "    row1 = row[colset1]\n",
    "    row1 = row1.T\n",
    "    row1= row1.reset_index()\n",
    "    row1.columns = [\"Marking Criteria\", \"Result\"]\n",
    "    # display(row1)\n",
    "    table1 = createTable(row1, 'Engagement, Information, Diagnosis', [1, 1], customTextCols=[0, 1])\n",
    "    elements.append(table1)\n",
    "    elements.append(Spacer(1, 24))\n",
    "\n",
    "    # Clinical Outcomes\n",
    "    row3 = row[colset3]\n",
    "    row3 = row3.T\n",
    "    row3= row3.reset_index()\n",
    "    row3.columns = [\"Marking Criteria\", \"Result\"]\n",
    "    # display(row3)\n",
    "    table3 = createTable(row3, 'Clinical Outcomes', [1, 1], customTextCols=[0, 1])\n",
    "    elements.append(table3)\n",
    "    \n",
    "    # Treatment Plan\n",
    "    row2 = row[colset2]\n",
    "    row2 = row2.T\n",
    "    row2= row2.reset_index()\n",
    "    row2.columns = [\"Marking Criteria\", \"Result\"]\n",
    "    # display(row2)\n",
    "    table2 = createTable(row2, 'Treatment Plan', [1, 1], customTextCols=[0, 1])\n",
    "    elements.append(table2)\n",
    "    elements.append(Spacer(1, 24))\n",
    "\n",
    "\n",
    "    # Knowledge\n",
    "    row4 = row[colset4]\n",
    "    row4 = row4.T\n",
    "    row4= row4.reset_index()\n",
    "    row4.columns = [\"Marking Criteria\", \"Result\"]\n",
    "    # display(row4)\n",
    "    table4 = createTable(row4, 'Knowledge', [1, 1], customTextCols=[0, 1])\n",
    "    elements.append(table4)\n",
    "\n",
    "    # Overall Marks\n",
    "    elements.append(Spacer(1, 32))\n",
    "    elements.append(Paragraph(f\"Total Marks: {totalMarks} / {sum(denominator.values())}\", subheadingStyle))\n",
    "\n",
    "    doc.build(elements)\n",
    "    # break\n",
    "# table1 = createTable(df1, 'Engagement, Information, Diagnosis')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath =  'DDS4\\\\2024+DDS+4+Case+Pres+Viva_October+28,+2024_15.16\\\\2024 DDS 4 Case Pres Viva_October 28, 2024_15.16.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath, sheet_name = 'Marks')\n",
    "colMarks = 'Overall Grade'\n",
    "colSupervisor = 'Examiners'\n",
    "df[colId] = df[colId].astype(int)\n",
    "df1 = df[[colId, colMarks, colSupervisor]]\n",
    "# Aggregate over the examiners and get counts for each examiner and the average marks\n",
    "df1 = df1.groupby([colSupervisor]).agg({colMarks: ['mean', 'count', 'min', 'max']})\n",
    "# drop the top level of the multiindex\n",
    "df1.columns = df1.columns.droplevel(0)\n",
    "df1.reset_index(inplace=True)\n",
    "df1.sort_values(by = ['mean'], ascending = False, inplace = True)\n",
    "# plot a bar chart\n",
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "sns.barplot(data = df1, x = colSupervisor, y = 'mean', ax = ax)\n",
    "# add min and max marks as error bars\n",
    "# Calculate error margins (difference between mean and min/max)\n",
    "yerr = [df1['mean'] - df1['min'], df1['max'] - df1['mean']]\n",
    "\n",
    "# Add error bars with capsize for better visibility\n",
    "ax.errorbar(df1[colSupervisor], df1['mean'], yerr=yerr, fmt='none', ecolor='black', elinewidth=1.5, capsize=5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.grid(True, linestyle = '--', alpha = 0.6)\n",
    "plt.ylabel('Average Marks')\n",
    "plt.title('Average Marks by Examiner Pair')\n",
    "plt.show()\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each examiner cell have two examiners separated by a comma separate them and create a new row for each examiner\n",
    "workbookpath =  'DDS4\\\\2024+DDS+4+Case+Pres+Viva_October+28,+2024_15.16\\\\2024 DDS 4 Case Pres Viva_October 28, 2024_15.16.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath, sheet_name = 'Marks')\n",
    "df2 = df.copy()\n",
    "df2[colSupervisor] = df2[colSupervisor].apply(lambda x: x.split(','))\n",
    "df2 = df2.explode(colSupervisor)\n",
    "df2[colSupervisor] = df2[colSupervisor].str.strip()\n",
    "# display(df2)\n",
    "dfAvg = df2.groupby([colSupervisor]).agg({colMarks: ['mean', 'count', 'min', 'max']})\n",
    "dfAvg.columns = dfAvg.columns.droplevel(0)\n",
    "dfAvg.reset_index(inplace=True)\n",
    "dfAvg.sort_values(by = ['mean'], ascending = False, inplace = True)\n",
    "# plot a bar chart\n",
    "fig, ax = plt.subplots(figsize = (10, 6))\n",
    "sns.barplot(data = dfAvg, x = colSupervisor, y = 'mean', ax = ax)\n",
    "# Calculate error margins (difference between mean and min/max)\n",
    "yerr = [dfAvg['mean'] - dfAvg['min'], dfAvg['max'] - dfAvg['mean']]\n",
    "\n",
    "# Add error bars with capsize for better visibility\n",
    "ax.errorbar(dfAvg[colSupervisor], dfAvg['mean'], yerr=yerr, fmt='none', ecolor='black', elinewidth=1.5, capsize=5)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.grid(True, linestyle = '--', alpha = 0.6)\n",
    "plt.ylabel('Average Marks')\n",
    "plt.title('Average Marks by Examiner')\n",
    "plt.show()\n",
    "\n",
    "display(dfAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath =  'DDS4\\\\2024+DDS+4+Case+Pres+Viva_October+28,+2024_15.16\\\\2024 DDS 4 Case Pres Viva_October 28, 2024_15.16.xlsx'\n",
    "df = pd.read_excel(workbookpath, sheet_name = 'Clean')\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "commentCols = ['Comments for Audience Engagement', 'Comments for Delivery of Presentation', 'Comments for Information Gathering', 'Comments for Diagnosis/es', \n",
    "               'Comments for Treatment Plan', 'Comments for Clinical Outcomes', 'Comments for Knowledge']\n",
    "marksCols = ['Marks for Audience Engagement', 'Marks for Delivery of Presentation', 'Marks for Information Gathering', \n",
    "             'Marks Diagnosis/es', 'Overall Marks for Treatment Plan', 'Overall marks for Clinical Outcomes ', 'Marks Knowledge']\n",
    "demoninator = [5, 5, 10, 30, 25, 25, 100]\n",
    "for i, col in enumerate(marksCols):\n",
    "    df[col] = df[col] / demoninator[i]\n",
    "    df[col] = df[col].apply(lambda x: round(x, 2))\n",
    "commentMarkDict = dict(zip(commentCols, marksCols))\n",
    "print(commentMarkDict) \n",
    "display(df[marksCols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "from openpyxl import Workbook\n",
    "client = OpenAI()\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "workbookpath = 'FullSpreadsheets\\CE and Comment Analysis\\Comments.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath)\n",
    "colCEReason = 'Further comments'\n",
    "comments = df[colCEReason].dropna().values\n",
    "print(comments)\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller model, effective for sentence similarity\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   embeddings = model.encode(text, convert_to_tensor=True)\n",
    "   return embeddings\n",
    "#    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def getSimilarityMatrix(embeddings):\n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = util.pytorch_cos_sim(embeddings, embeddings).numpy()\n",
    "    return similarity_matrix\n",
    "\n",
    "df['Embedding'] = df[colCEReason].apply(lambda x: get_embedding(x))\n",
    "# embeddingDict = {comment: get_embedding(comment) for comment in comments}\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'FullSpreadsheets\\CE and Comment Analysis\\Critical Incidents Clustered.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath)\n",
    "\n",
    "elements = []\n",
    "# elements.append(Paragraph(f\"{file} Grouped\", headingStyle))\n",
    "# elements.append(Spacer(1, 0.5 * inch))\n",
    "for cluster in df['Group'].unique():\n",
    "    dfCluster = pd.DataFrame(df[df['Group'] == cluster]['Comments'], columns = ['Comments'])\n",
    "    table = createTable(dfCluster, f\"{cluster}\", [1], 0.9, [0], tableTextStyle= tableTextStyle)\n",
    "    \n",
    "    elements.append(table)\n",
    "    elements.append(Spacer(1, 0.5 * inch))\n",
    "\n",
    "\n",
    "doc = SimpleDocTemplate(f\"{folder}\\\\{file} Clustered 2.pdf\", pagesize=pageSize,\n",
    "                            rightMargin=rightMargin, leftMargin=leftMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "# elements.append(Paragraph(f\"{file} Clustered\", headingStyle))\n",
    "# elements.append(table)\n",
    "doc.build(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary to a list of comments and a matrix of embeddings\n",
    "\n",
    "comments = list(df[colCEReason].values)\n",
    "embeddings = np.array(list(df['Embedding'].values))\n",
    "\n",
    "# Choose the number of clusters\n",
    "num_clusters = 41\n",
    "\n",
    "# Perform K-Means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Map each comment to its assigned cluster\n",
    "clusters = kmeans.labels_\n",
    "comment_cluster_mapping = {comment: cluster for comment, cluster in zip(comments, clusters)}\n",
    "savedf = pd.DataFrame(comment_cluster_mapping.items(), columns = ['Comments', 'Cluster'])\n",
    "savedf.sort_values(by = 'Cluster', inplace = True)\n",
    "# savedf.to_excel(f'{folder}\\\\{file} Clustered.xlsx', index = False)\n",
    "elements = []\n",
    "elements.append(Paragraph(f\"{file} Grouped\", headingStyle))\n",
    "elements.append(Spacer(1, 0.5 * inch))\n",
    "for cluster in savedf['Cluster'].unique():\n",
    "    dfCluster = pd.DataFrame(savedf[savedf['Cluster'] == cluster]['Comments'], columns = ['Comments'])\n",
    "    table = createTable(dfCluster, f\"Group {cluster+1}\", [1], 0.9, [0], tableTextStyle= tableTextStyle)\n",
    "    elements.append(table)\n",
    "    elements.append(Spacer(1, 0.5 * inch))\n",
    "\n",
    "\n",
    "doc = SimpleDocTemplate(f\"{folder}\\\\{file} Clustered.pdf\", pagesize=pageSize,\n",
    "                            rightMargin=rightMargin, leftMargin=leftMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "# elements.append(Paragraph(f\"{file} Clustered\", headingStyle))\n",
    "elements.append(table)\n",
    "doc.build(elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WCSS for a range of cluster numbers\n",
    "wcss = []\n",
    "for i in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(embeddings)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow Method\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 21), wcss, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "linked = linkage(embeddings, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked, truncate_mode='lastp', p=10)\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Points')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Vectorize the comments\n",
    "vectorizer = TfidfVectorizer()\n",
    "commentVectors = {col: vectorizer.fit_transform(df[col].fillna('')) for col in commentCols}\n",
    "print(commentVectors)\n",
    "# Step 2: Compute average vectors for each comment column\n",
    "avgCommentVectors = {col: np.array(commentVectors[col].mean(axis=1)).flatten() for col in commentCols}\n",
    "print(avgCommentVectors)\n",
    "\n",
    "# Step 3: Compute cosine similarity with marks\n",
    "for commentCol, markCol in commentMarkDict.items():\n",
    "    # Reshape marks column to have compatible dimensions\n",
    "    marksArray = df[markCol].fillna(0).values.reshape(1, -1)  # 2D array with single row\n",
    "    \n",
    "    similarity = cosine_similarity([avgCommentVectors[commentCol]], marksArray)\n",
    "    print(f\"Similarity between {commentCol} and {markCol}: {similarity}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using LLM vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments_stacked = df[commentCols].stack().reset_index(drop=True).to_frame(name='AllComments')\n",
    "marks_stacked = df[marksCols].stack().reset_index(drop=True).to_frame(name='AllMarks')\n",
    "stacked_df = pd.concat([comments_stacked, marks_stacked], axis=1)\n",
    "display(stacked_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "from openpyxl import Workbook\n",
    "client = OpenAI()\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller model, effective for sentence similarity\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "# Function to calculate sentiment score and adjust similarity matrix\n",
    "def sentiment_adjustment(remarks, similarity_matrix, weight=0.1):\n",
    "    adjusted_matrix = similarity_matrix.copy()\n",
    "    for i in range(len(remarks)):\n",
    "        for j in range(len(remarks)):\n",
    "            if i != j:\n",
    "                # Calculate sentiment for each remark\n",
    "                sentiment_i = TextBlob(remarks[i]).sentiment.polarity\n",
    "                sentiment_j = TextBlob(remarks[j]).sentiment.polarity\n",
    "                # Increase similarity if both remarks are positive\n",
    "                if sentiment_i > 0 and sentiment_j > 0:\n",
    "                    adjusted_matrix[i][j] += weight * abs(sentiment_i - sentiment_j)\n",
    "    return np.clip(adjusted_matrix, 0, 1)  # Ensure values are within [0, 1]\n",
    "\n",
    "def getSimilarityMatrix(remarks):\n",
    "    # Generate embeddings\n",
    "    embeddings = model.encode(remarks, convert_to_tensor=True)\n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = util.pytorch_cos_sim(embeddings, embeddings).numpy()\n",
    "    return similarity_matrix\n",
    "\n",
    "def computeSimilarity(df, colMarks, colComments, columnNames=None, indexNames=None):\n",
    "   # Convert embeddings column to a numpy array for efficient calculation\n",
    "   # embedding_matrix = np.array(df['embeddings'].tolist())\n",
    "\n",
    "   # # Step 1: Compute pairwise cosine similarity for embeddings\n",
    "   # embedding_similarity = cosine_similarity(embedding_matrix)\n",
    "   if columnNames is None:\n",
    "       columnNames = df[colComments].values\n",
    "   if indexNames is None:\n",
    "       indexNames = df[colComments].values\n",
    "   embedding_similarity = getSimilarityMatrix(df[colComments].values)\n",
    "   embedding_similarity = sentiment_adjustment(df[colComments].values, embedding_similarity, 0.5)\n",
    "   embedding_similarity = 1 - embedding_similarity  # Convert cosine similarity to cosine distance\n",
    "   embedding_similarity = np.round(embedding_similarity, 2)\n",
    "   # create a multiiindex dataframe with supervisor, column names as index\n",
    "   \n",
    "   embedding_similarity_df = pd.DataFrame(embedding_similarity, columns = columnNames, index = indexNames)\n",
    "\n",
    "   marks_difference = np.abs(df[colMarks].values.reshape(-1, 1) - df[colMarks].values)\n",
    "   marks_difference_df = pd.DataFrame(marks_difference, columns = columnNames, index = indexNames)\n",
    "\n",
    "   print(\"Marks difference matrix shape:\", marks_difference.shape)\n",
    "\n",
    "   # Step 3: Flatten matrices and calculate correlation between similarity and marks difference\n",
    "   embedding_similarity_flat = embedding_similarity[np.triu_indices_from(embedding_similarity, k=1)]\n",
    "   marks_difference_flat = marks_difference[np.triu_indices_from(marks_difference, k=1)]\n",
    "\n",
    "   # # Calculate correlation\n",
    "   correlation = np.corrcoef(embedding_similarity_flat, marks_difference_flat)[0, 1]\n",
    "   print(\"Correlation between embedding similarity and marks difference:\", correlation)\n",
    "   return correlation, embedding_similarity_df, marks_difference_df\n",
    "\n",
    "\n",
    "def getSimilarity(df, commentCol, markCol,  columnNames=None, IndexNames=None):\n",
    "   # remove all nan comments\n",
    "   df = df.dropna(subset=[commentCol])\n",
    "   # display(df[[commentCol, markCol]].head(), df[[commentCol, markCol]].shape)\n",
    "   embeddings = df.apply(lambda x: get_embedding(x[commentCol]), axis=1)\n",
    "   print('Finished embeddings')\n",
    "   if embeddings.empty:\n",
    "      return None\n",
    "   df['embeddings'] = embeddings\n",
    "   # display(df[['embeddings', markCol]].head())\n",
    "   return computeSimilarity(df, markCol, commentCol, columnNames, IndexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "colSupervisor = 'Examiners'\n",
    "df2[colSupervisor] = df2[colSupervisor].apply(lambda x: x.split(','))\n",
    "df2 = df2.explode(colSupervisor)\n",
    "df2[colSupervisor] = df2[colSupervisor].str.strip()\n",
    "display(df2.head())\n",
    "print(df2[colSupervisor].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commentCol = 'AllComments'\n",
    "# markCol = 'AllMarks'\n",
    "# similarity = getSimilarity(stacked_df, commentCol, markCol)\n",
    "similarityDf = pd.DataFrame(columns = df2[colSupervisor].unique(), index = commentMarkDict.keys())\n",
    "savefolder = f'{folder}/Similarity'\n",
    "os.makedirs(savefolder, exist_ok=True)\n",
    "\n",
    "for supervisor in df2[colSupervisor].unique():\n",
    "    print(f'\\nSupervisor: {supervisor}')\n",
    "    x = df2[df2[colSupervisor] == supervisor]\n",
    "    file_path = f'{savefolder}/{supervisor} similarity.xlsx' if supervisor is not None else f'{folder}/similarity.xlsx'\n",
    "    for commentCol, markCol in commentMarkDict.items():    \n",
    "        print('\\n', commentCol, markCol)\n",
    "        similarity, commentEmbeddingDf, marksEmbeddingDf = getSimilarity(x, commentCol, markCol)\n",
    "        similarityDf.loc[commentCol, supervisor] = similarity\n",
    "        \n",
    "    if not os.path.exists(file_path):\n",
    "        with pd.ExcelWriter(file_path, engine='openpyxl', mode='w') as writer:\n",
    "            commentEmbeddingDf.to_excel(writer, sheet_name=colComments[::-1][:30][::-1].replace('/', '-'), index=True)\n",
    "    else:\n",
    "        with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace')    as writer:\n",
    "            commentEmbeddingDf.to_excel(writer, sheet_name=colComments[::-1][:30][::-1].replace('/', '-'), index=True)\n",
    "    \n",
    "    with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "      marksEmbeddingDf.to_excel(writer, sheet_name=colMarks.replace('/', '-'), index=True)\n",
    "        \n",
    "    # break\n",
    "similarityDf.to_excel(f'{folder}/similarityDf.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFolder = f'{folder}/Itemwise'\n",
    "os.makedirs(saveFolder, exist_ok=True)\n",
    "for commentCol, markCol in commentMarkDict.items():\n",
    "    # create double level index for the similarity matrix with [Supervisor, Comment]\n",
    "    indexNames = [(row[colSupervisor], row[commentCol]) for i, row in df2.iterrows()]\n",
    "    columnNames = [(row[colSupervisor], row[commentCol]) for i, row in df2.iterrows()]\n",
    "    print(indexNames[:5])\n",
    "    similarity, commentEmbeddingDf, marksEmbeddingDf = getSimilarity(df2, commentCol, markCol, columnNames, indexNames)\n",
    "    file_path = f'{saveFolder}/{commentCol} similarity.xlsx'\n",
    "    if not os.path.exists(file_path):\n",
    "        with pd.ExcelWriter(file_path, engine='openpyxl', mode='w') as writer:\n",
    "            commentEmbeddingDf.to_excel(writer, sheet_name=colComments[::-1][:30][::-1].replace('/', '-'), index=True)\n",
    "            marksEmbeddingDf.to_excel(writer, sheet_name=colMarks.replace('/', '-'), index=True)\n",
    "    else:\n",
    "        with pd.ExcelWriter(f'{saveFolder}/{commentCol} similarity.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "            commentEmbeddingDf.to_excel(writer, sheet_name=colComments[::-1][:30][::-1].replace('/', '-'), index=True)\n",
    "            marksEmbeddingDf.to_excel(writer, sheet_name=colMarks.replace('/', '-'), index=True)\n",
    "\n",
    "    print(f'Similarity between {commentCol} and {markCol}: {similarity}')\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'FullSpreadsheets\\CAF+v0.1_October+28,+2024_00.59\\CAF v0.1_October 28, 2024_00.59.csv'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_csv(workbookpath)\n",
    "df = df[[colId, colDate, colCE, colCEReason]]\n",
    "df[colId] = pd.to_numeric(df[colId], errors = 'coerce')\n",
    "df = df[df[colId].isin(getStudentList())]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data by student id and date\n",
    "df[colDate] = df[colDate].apply(convertDate)\n",
    "df[colId] = df[colId].astype(int)\n",
    "df[colCE] = df[colCE].astype(str)\n",
    "df[colCEReason] = df[colCEReason].fillna(' ')\n",
    "df[colCEReason] = df[colCEReason].astype(str)\n",
    "# remove non-ascii characters\n",
    "df[colCEReason] = df[colCEReason].apply(lambda x: re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', x))\n",
    "def CEReasonAgg(x):\n",
    "    # if all nan, return nan\n",
    "    if x.isnull().all():\n",
    "        return ''\n",
    "    else:\n",
    "        return (', '.join(x.dropna())).strip().strip(',')\n",
    "def CEAgg(x):\n",
    "    if 'Yes' in x:\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "    \n",
    "dfAgg = df.groupby([colId, colDate]).agg({colCE: lambda x: 'Yes' if 'Yes' in x.values else 'No', colCEReason: lambda x: CEReasonAgg(x)}).reset_index()\n",
    "dfAgg= df.copy()\n",
    "dfAgg = dfAgg[dfAgg[colCE] == 'Yes']\n",
    "dfAgg.sort_values([colId, colDate], inplace = True)\n",
    "dfAgg = dfAgg[[colId, colDate, colCEReason]]\n",
    "dfAgg = dfAgg.rename(columns = {colCEReason: 'Critical Incident Reason'})\n",
    "display(dfAgg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = SimpleDocTemplate(f'{folder}/ Critical Events Report.pdf', pagesize = pageSize, \n",
    "                        rightMargin = rightMargin, leftMargin = leftMargin, topMargin = topMargin, bottomMargin = bottomMargin)\n",
    "elements = []   \n",
    "table = createTable(dfAgg, 'Critical Incidents', [2, 2, 5], 0.9, [2])\n",
    "elements.append(table)\n",
    "doc.build(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOH2 Assessment Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment1path = 'BOH2\\Assessment 1\\\\522+SIM+Supervisor_October+14,+2024_22.57\\\\522 SIM Supervisor_October 14, 2024_22.57.xlsx'\n",
    "assessment2path = 'BOH2\\Assessment 2\\BOH2 Sim Assessment data 578 Complete\\BOH2 Sim Assessment data 524_578 Complete best guttman.xlsx'\n",
    "assessment3path = 'BOH2\\Assessment 3\\Sim Clinic Assessment 3_October 2, 2024\\ORAL20005 Sim Clinic Assessment 3_October 2, 2024_18 best guttman.xlsx'\n",
    "assessment4path = 'BOH2\\Assessment 4\\BOH2+SIM+Exo+Assessment\\BOH2 SIM Exo Assessment_All_processed.xlsx'\n",
    "ass3Resits = [1377061, 1443777, 1460189, 1462155, 1463086, 1472769, 1472800, 1473169]\n",
    "ass2Resits = [1280725, 1387538, 1462377, 1472336, 1472717, 1473664]\n",
    "\n",
    "\n",
    "df1 = pd.read_excel(assessment1path)\n",
    "df1[colComments] = df1[colComments].fillna(' ').astype(str)\n",
    "df1[colComments] = df1[colComments].astype(str)\n",
    "df2M = pd.read_excel(assessment2path, sheet_name = 'Main')\n",
    "df2R = pd.read_excel(assessment2path, sheet_name = 'Resits')\n",
    "\n",
    "# to get full mc names for assessment 2\n",
    "dftemp2 = pd.read_excel('BOH2\\Assessment 2\\BOH2 Sim Assessment data 578 Complete\\BOH2 Sim Assessment data 524_578 Complete.xlsx')\n",
    "mcCols2 = [col for col in dftemp2.columns if 'MC' in col]\n",
    "df3M = pd.read_excel(assessment3path, sheet_name = 'Main')\n",
    "df3R = pd.read_excel(assessment3path, sheet_name = 'Resits')\n",
    "\n",
    "# to get full mc names for assessment 3\n",
    "dftemp3 = pd.read_csv('BOH2\\Assessment 3\\Sim Clinic Assessment 3_October 2, 2024\\ORAL20005 Sim Clinic Assessment 3_October 2, 2024_18.csv',\n",
    "                      encoding = 'ISO-8859-1')\n",
    "mcCols3 = [col for col in dftemp3.columns if 'MC' in col]\n",
    "\n",
    "# to get full mc names for assessment 4\n",
    "df4M = pd.read_excel(assessment4path, sheet_name = 'Main')\n",
    "df4R = pd.read_excel(assessment4path, sheet_name = 'Resits')\n",
    "mcCols4 = [col for col in df4M.columns if 'SIM Exo' in col]\n",
    "df4M[mcCols4] = df4M[mcCols4].replace({'Yes': 1, 'No': 0})    \n",
    "df4R[mcCols4] = df4R[mcCols4].replace({'Yes': 1, 'No': 0})\n",
    "colnewDict = {}\n",
    "for col in mcCols4:\n",
    "    colnew = col.replace('SIM Exo item#2', 'MC')\n",
    "    colnewDict[col] = colnew\n",
    "mcCols4 = [colnewDict[col] for col in mcCols4]\n",
    "df4M = df4M.rename(columns = colnewDict)\n",
    "df4R = df4R.rename(columns = colnewDict)\n",
    "\n",
    "ids = df1[colId].unique()\n",
    "outDir = 'BOH2/Assessment Reports'\n",
    "os.makedirs(outDir, exist_ok = True)\n",
    "allDict = {id: {} for id in ids}\n",
    "\n",
    "rubricRefDf = pd.read_excel('Rubric Reference Table.xlsx')\n",
    "rubricFullNames = {'PS': 'Professionalism', 'TS': 'Time Management', 'ES': 'Entrustment', 'CS': 'Communication'}\n",
    "\n",
    "tableTextStyleLarge = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=15, alignment=1, leading=18)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "def plotRubric(df):\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(figSize[0], figSize[1]/2))\n",
    "    ax_flat = ax.flatten()\n",
    "    for i, column in enumerate(df.columns):\n",
    "        series = df[column].dropna()\n",
    "        series.plot(marker='o', linestyle='-', title=f\"{column} over Assessments\", ax = ax_flat[i])\n",
    "            # Set only specific labels\n",
    "        if i % 2 == 0:  # Set y-label only for the left column (0 and 2)\n",
    "            ax_flat[i].set_ylabel('Score')\n",
    "        else:\n",
    "            ax_flat[i].set_ylabel(\"\")  # Hide y-label for the right column (1 and 3)\n",
    "        \n",
    "        if i >= 2:  # Set x-label only for the bottom row (2 and 3)\n",
    "            ax_flat[i].set_xlabel(\"Assessment\")\n",
    "        else:\n",
    "            ax_flat[i].set_xlabel(\"\")  # Hide x-label for the top row (0 and 1)\n",
    "\n",
    "        ax_flat[i].set_ylim(0, 4.2)\n",
    "        ax_flat[i].set_xticks(range(len(series.index)))\n",
    "        ax_flat[i].set_xticklabels([x.replace('Assessment', 'Ass') for x in series.index], rotation = 45)\n",
    "        ax_flat[i].set_title(rubricFullNames[column])\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    return fig\n",
    "\n",
    "def getComments(df, id):\n",
    "    comment = df[df[colId] == id][colComments].values[0] if not df[df[colId] == id][colComments].empty else ' '\n",
    "    comment = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', comment)\n",
    "    comment = comment if comment != ' ' else 'No Comments'\n",
    "    return comment\n",
    "\n",
    "def assessment2Page(df2M, id, rubricFullNames, mcCols, dftemp, heading = 'Assessment 2', \n",
    "                    splitelement = 'comments -', dfrubric = None, dfMC = None):\n",
    "    elements2 = []\n",
    "    ass2heading = Paragraph(heading, subheadingStyle)\n",
    "    elements2.append(ass2heading)\n",
    "    elements2.append(Spacer(1, 12))\n",
    "    df = df2M[df2M[colId] == id]\n",
    "    if df.empty:\n",
    "        elements2.append(Paragraph('No data found', subsubheadingStyle))\n",
    "        elements2.append(PageBreak())\n",
    "        return elements2\n",
    "    display(df)\n",
    "    # get both the supervisors\n",
    "    tableDf = pd.DataFrame(columns=['Item', 'Full Question', 'Result'])\n",
    "    # Read file to get full text\n",
    "    fulltextDict = {col: dftemp[col].values[0].split(splitelement)[-1].strip() for col in mcCols}\n",
    "    \n",
    "    for col in mcCols:\n",
    "            colText = col.replace('_', ' ')\n",
    "            score = df[col].values[0]\n",
    "            score = 'Yes' if score == 1 else 'No'\n",
    "            if heading in dfMC.index:\n",
    "                # print(heading, score)\n",
    "                dfMC.loc[heading, score] = dfMC.loc[heading, score] + 1 if not pd.isna(dfMC.loc[heading, score]) else 1\n",
    "            else:\n",
    "                # print('Heading not in dfMC', heading, score)\n",
    "                dfMC.loc[heading, score] = 1\n",
    "            tableDf = pd.concat([tableDf, pd.DataFrame([[colText, fulltextDict[col], score]], columns=['Item', 'Full Question', 'Result'])])\n",
    "    table = createTable(tableDf, title = 'Marking Checklist', \n",
    "                        colRatio = [1, 3, 1], tableWidth=0.9, customTextCols=[1], cellHighlight=True)\n",
    "    elements2.append(table)\n",
    "    elements2.append(Spacer(1, 12))\n",
    "\n",
    "    # rubric table\n",
    "    rubricQues = [col for col in df2M.columns if col in variableUtils.rubricQues]\n",
    "    rubricDf = pd.DataFrame(columns = ['Rubric Question', 'Score', 'Description'])\n",
    "    for q in rubricQues:\n",
    "        score = df[q].values[0]\n",
    "        # score = re.findall(r'Lvl (\\d+)', score)[0]\n",
    "        score = int(score)\n",
    "        if dfrubric is not None:\n",
    "            dfrubric.loc[heading, q] = score\n",
    "        fulltext = rubricRefDf[rubricRefDf['Score'] == score][rubricFullNames[q]].iloc[0]\n",
    "        rubricDf = pd.concat([rubricDf, pd.DataFrame([[rubricFullNames[q], score, fulltext]], columns = rubricDf.columns)])\n",
    "    rubricTable = createTable(rubricDf, 'Rubric Scores', [2, 1, 6], 0.9, [2])\n",
    "    elements2.append(rubricTable)\n",
    "    elements2.append(Spacer(1, 12))\n",
    "\n",
    "    # Add comments\n",
    "    if colComments in df.columns:\n",
    "        df[colComments] = df[colComments].fillna(' ').astype(str).apply(lambda x: re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', x))\n",
    "        dfAgg = df.groupby(colId)[colComments].apply(lambda x: ' '.join(x)).reset_index()\n",
    "        # display(dfAgg)\n",
    "        comments = dfAgg[colComments].values[0]\n",
    "        elements2.append(KeepTogether([Paragraph('Comments', subsubheadingStyle), Spacer(1, 12), Paragraph(f\"{comments if comments!= ' ' else 'No Comments'}\", tableTextStyleLarge)]))\n",
    "    \n",
    "    # Add critical incidents\n",
    "    elements2.append(Spacer(1, 12))\n",
    "    cetext = df[colCE].values[0]\n",
    "    cereason = df[colCEReason].values[0] if cetext == 'Yes' else 'No Critical Incident Occurred'\n",
    "    elements2.append(KeepTogether([Paragraph('Critical Incident', subsubheadingStyle), Spacer(1, 12), Paragraph(f\"{cereason}\", tableTextStyleLarge)]))\n",
    "    # elements2.append(PageBreak())\n",
    "    return elements2\n",
    "\n",
    "for id in ids[1:]:\n",
    "    # id = int(id)\n",
    "    if id in done:\n",
    "        continue\n",
    "    commentDict = {}\n",
    "    dfrubric = pd.DataFrame(columns =  rubricQues)\n",
    "    dfMC = pd.DataFrame(columns = ['Yes', 'No'])\n",
    "    print(f'\\n============================ ({id}) ====================================')\n",
    "    # if int(id)!= 1295910:\n",
    "    #     continue\n",
    "    doc = SimpleDocTemplate(f'{outDir}/{id}.pdf', pagesize = pageSize, rightMargin = rightMargin, \n",
    "                            leftMargin = leftMargin, topMargin = topMargin, bottomMargin = bottomMargin)\n",
    "    elements = []\n",
    "    name = df1[df1[colId] == id][colNameG].values[0] + ' ' + df1[df1[colId] == id][colNameF].values[0]\n",
    "    elements.append(Paragraph(f'{name} ({id})', headingStyle))\n",
    "    elements.append(Spacer(1, 16))\n",
    "    \n",
    "    # Assessment 1--------------------------------------------------\n",
    "    elements1 = []\n",
    "    ass1heading = Paragraph('Assessment 1', subheadingStyle)\n",
    "    elements1.append(ass1heading)\n",
    "    elements1.append(Spacer(1, 12))\n",
    "    mcCols = [col for col in df1.columns if 'MC' in col]\n",
    "    fulltextDict = {col: df1[col].values[0].split('comments -')[-1].strip() for col in mcCols}\n",
    "    # print(fulltextDict)\n",
    "    tableDf = pd.DataFrame(columns=['Item', 'Full Question', 'Result'])\n",
    "    dfid1 = df1[df1[colId] == id]\n",
    "    for col in mcCols:\n",
    "        colText = col.replace('_', ' ')\n",
    "        score = dfid1[col].values[0]\n",
    "        score = 'Yes' if score == 1 else 'No'\n",
    "        if 'Assessment 1' in dfMC.index:\n",
    "            dfMC.loc['Assessment 1', score] = dfMC.loc['Assessment 1', score] + 1 if not pd.isna(dfMC.loc['Assessment 1', score]) else 1\n",
    "        else:\n",
    "            dfMC.loc['Assessment 1', score] = 1\n",
    "        tableDf = pd.concat([tableDf, pd.DataFrame([[colText, fulltextDict[col], score]], columns=['Item', 'Full Question', 'Result'])])\n",
    "    \n",
    "    table = createTable(tableDf, title = 'Marking Checklist', \n",
    "                        colRatio = [1, 3, 1], tableWidth=0.9, customTextCols=[1], cellHighlight=True)\n",
    "    elements1.append(table)\n",
    "    elements1.append(Spacer(1, 12))\n",
    "    \n",
    "    # rubric table\n",
    "    rubricQues = [col for col in df1.columns if col in variableUtils.rubricQues]\n",
    "    rubricDf = pd.DataFrame(columns = ['Rubric Question', 'Score', 'Description'])\n",
    "    for q in rubricQues: \n",
    "        score = df1[df1[colId] == id][q].values[0]\n",
    "        score = re.findall(r'Lvl (\\d+)', score)[0]\n",
    "        score = int(score)\n",
    "        # add to rubric df with Assessment 1 as index\n",
    "        dfrubric.loc['Assessment 1', q] = score\n",
    "        fulltext = rubricRefDf[rubricRefDf['Score'] == score][rubricFullNames[q]].iloc[0]\n",
    "        rubricDf = pd.concat([rubricDf, pd.DataFrame([[rubricFullNames[q], score, fulltext]], columns = rubricDf.columns)])\n",
    "    rubricTable = createTable(rubricDf, 'Rubric Scores', [2, 1, 6], 0.9, [2])\n",
    "    elements1.append(rubricTable)\n",
    "    elements1.append(Spacer(1, 12))\n",
    "\n",
    "    # Add comments\n",
    "    dfAgg = df1.groupby(colId)[colComments].apply(lambda x: ' '.join(x)).reset_index()\n",
    "    comments = dfAgg[dfAgg[colId] == id][colComments].values[0]\n",
    "    elements1.append(KeepTogether([Paragraph('Comments', subsubheadingStyle), Spacer(1, 12), Paragraph(f\"{comments if comments!= ' ' else 'No Comments'}\",\n",
    "                                                                                         tableTextStyleLarge)]))\n",
    "    commentDict['Assessment 1'] = getComments(df1, int(id))\n",
    "    elements1.append(PageBreak())\n",
    "    \n",
    "\n",
    "    # Assessment 2--------------------------------------------------\n",
    "\n",
    "    elements2 = assessment2Page(df2M, int(id), rubricFullNames, mcCols2, dftemp2,\n",
    "                                 heading = 'Assessment 2', dfrubric = dfrubric, dfMC = dfMC)\n",
    "    commentDict['Assessment 2'] = getComments(df2M, int(id))\n",
    "\n",
    "    ass2resitIds = df2R[colId].unique()\n",
    "    # remove nan\n",
    "    ass2resitIds = [int(i) for i in ass2resitIds if i == i]\n",
    "    # print(ass2resitIds)\n",
    "    if int(id) in ass2resitIds:\n",
    "        elements2.append(PageBreak())\n",
    "        elements2resit = assessment2Page(df2R, int(id), rubricFullNames, mcCols2, dftemp2, \n",
    "                                         heading = 'Assessment 2 Resit', dfrubric = dfrubric, dfMC = dfMC)\n",
    "        elements2 = elements2 + elements2resit\n",
    "        commentDict['Assessment 2 Resit'] = getComments(df2R, int(id))\n",
    "    elements2.append(PageBreak())\n",
    "\n",
    "    # Assessment 3--------------------------------------------------\n",
    "    elements3 = assessment2Page(df3M, int(id), rubricFullNames, mcCols3, dftemp3, \n",
    "                                heading = 'Assessment 3', splitelement = 'Supervisor -', dfrubric = dfrubric, dfMC = dfMC)\n",
    "    commentDict['Assessment 3'] = getComments(df3M, int(id))\n",
    "    ass3ResitIds = df3R[colId].unique()\n",
    "    # remove nan\n",
    "    ass3ResitIds = [int(i) for i in ass3ResitIds if i == i]\n",
    "    # print(f'Assessment 3 Resit ids: {ass3ResitIds}')\n",
    "    if int(id) in ass3ResitIds:\n",
    "        elements3.append(PageBreak())\n",
    "        elements3resit = assessment2Page(df3R, int(id), rubricFullNames, mcCols3, dftemp3, \n",
    "                                         heading = 'Assessment 3 Resit', splitelement = 'Supervisor -', dfrubric = dfrubric, dfMC = dfMC)\n",
    "        elements3 = elements3 + elements3resit\n",
    "        commentDict['Assessment 3 Resit'] = getComments(df3R, int(id))\n",
    "    elements3.append(PageBreak())\n",
    "    \n",
    "    # Assessment 4--------------------------------------------------\n",
    "    dfid4 = df4M[df4M[colId] == id]\n",
    "    elements4 = []\n",
    "    if not dfid4.empty:\n",
    "        fulltextDict = {col: df4M[col].values[0].split('Supervisor -')[-1].strip() for col in mcCols4}\n",
    "        # print(fulltextDict)\n",
    "        commentDict['Assessment 4'] = getComments(df4M, id)\n",
    "        elements4 = assessment2Page(dfid4.copy(), id, rubricFullNames, mcCols4, df4M, \n",
    "                                    heading = 'Assessment 4', splitelement = 'Supervisor -', dfrubric = dfrubric, dfMC = dfMC)\n",
    "        fail = dfid4['Fail'].values[0]\n",
    "        result = 'Pass' if fail == 0 else 'Fail'\n",
    "        elements4.append(KeepTogether([Paragraph('Outcome', subsubheadingStyle), Spacer(1, 12), Paragraph(result, tableTextStyleLarge)]))\n",
    "        elements4.append(PageBreak())\n",
    "        if fail:\n",
    "            # Add resit\n",
    "            df4R[colId] = df4R[colId].astype(str)\n",
    "            dfid4R = df4R[df4R[colId] == str(id)]\n",
    "            print(df4R[colId].unique())\n",
    "            print(id)\n",
    "            elements4resit = assessment2Page(df4R, str(id), rubricFullNames, mcCols4, df4R, heading = 'Assessment 4 Resit', \n",
    "                                            splitelement = 'Supervisor -', dfrubric = dfrubric, dfMC = dfMC)\n",
    "            commentDict['Assessment 4 Resit'] = getComments(df4R, id)\n",
    "            fail = dfid4R['Fail'].values[0]\n",
    "            result = 'Pass' if fail == 0 else 'Fail'\n",
    "            elements4resit.append(KeepTogether([Paragraph('Outcome', subsubheadingStyle), Spacer(1, 12), Paragraph(result, tableTextStyleLarge)]))\n",
    "            elements4 = elements4 + elements4resit\n",
    "            elements4.append(PageBreak())\n",
    "\n",
    "\n",
    "    # Add dfMC subplots\n",
    "    nsubplots = len(dfMC.index)\n",
    "    ncols = 2\n",
    "    nrows = nsubplots // ncols + 1\n",
    "    ratio = nrows/ncols\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(figSize[0]*1.3, figSize[1]*ratio))\n",
    "    ax_flat = ax.flatten()\n",
    "    for i, (index, row) in enumerate(dfMC.iterrows()):\n",
    "        # pie chart\n",
    "        total = row.sum()\n",
    "        row.plot.pie(autopct = lambda x: autopct(x, total), ax = ax_flat[i], title = index, startangle=120)\n",
    "        ax_flat[i].set_ylabel('')\n",
    "        ax_flat[i].set_title(index, fontsize = 15)\n",
    "    # remove unused subplots\n",
    "    for i in range(nsubplots, nrows*ncols):\n",
    "        fig.delaxes(ax_flat[i])\n",
    "    plt.tight_layout()\n",
    "    image = addPlotImage(fig, 0.9)\n",
    "    elements.append(KeepTogether([Paragraph('Marking Checklist Counts', subheadingStyle), Spacer(1, 12), image]))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # Add comments\n",
    "    dfComments = pd.DataFrame(list(commentDict.items()), columns=['Assessment', 'Supervisor Comments'])\n",
    "    table = createTable(dfComments, 'Supervisor Comments', [3, 6], 0.9, [1])\n",
    "    elements.append(table)\n",
    "    if len(dfrubric) <2:\n",
    "        dfrubric.fillna(0, inplace = True)\n",
    "    display(dfrubric)\n",
    "    fig = plotRubric(dfrubric)\n",
    "    image = addPlotImage(fig, 0.9)\n",
    "    elements.append(KeepTogether([Paragraph('Rubric Scores', subsubheadingStyle), Spacer(1, 12), image]))\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    elements = elements + elements1\n",
    "    elements = elements + elements2\n",
    "    elements = elements + elements3\n",
    "    elements = elements + elements4\n",
    "\n",
    "    doc.build(elements)\n",
    "    done.append(id)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDS2 and DDS3 Fixed Pros Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'DDS3\\Fix Pros\\CAF+v0.1_October+17,+2024_20.46\\CAF v0.1_October 17, 2024_20.46 marks.xlsx'\n",
    "folder, file, ext = getFolderandFileName(filepath)\n",
    "df = pd.read_excel(filepath)\n",
    "# Filter items 555_SIM, 545_SIM, 631_SIM, 613_SIM, 615_SIM and 618_SIM\n",
    "# filteredItems = ['555_SIM', '545_SIM', '631_SIM', '613_SIM', '615_SIM', '618_SIM']\n",
    "# df = df[df['Item'].isin(filteredItems)]\n",
    "# if colFinished is 0 then set the value of Total Score CE Penalty (20%) to 0\n",
    "df.loc[df[colFinished] == 0, 'Total Score CE Penalty (20%)'] = 0\n",
    "pivotDf = df.pivot_table(index=[colId], columns='Item', values='Total Score CE Penalty (20%)', dropna=False, aggfunc='max')\n",
    "\n",
    "\n",
    "pivotDf = pivotDf.reset_index()\n",
    "# sort columns based on length of column name\n",
    "# pivotDf = pivotDf.reindex(sorted(pivotDf.columns, key=len), axis=1)\n",
    "pivotDf.to_excel(f'{folder}/{file} pivot.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOH2 Paeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'BOH2\\CAF+v0.1_October152024_19.01\\CAF v0.1_October 15, 2024_19.01.csv'\n",
    "folder, file, ext = getFolderandFileName(filepath)\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[colAge].unique())\n",
    "# remove rows that are of not number type\n",
    "dfPaed = df[pd.to_numeric(df[colAge], errors='coerce').between(0, 17.9)]\n",
    "print(dfPaed[colAge].unique())\n",
    "print(len(dfPaed))\n",
    "# add row 0 of df to the row 0 dataframe\n",
    "dfPaed = pd.concat([df.iloc[0:1], dfPaed], axis = 0)\n",
    "display(dfPaed.head())\n",
    "dfPaed.to_csv(f'{folder}\\\\{file} Paeds.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = f'{folder}\\\\{file} Paeds.csv'\n",
    "savepath = None\n",
    "guttmancreator = CreateGuttman(savepath, workbookpath)\n",
    "splitDfPath = None\n",
    "guttmancreator.createGuttman(splitDfPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOH2 Assessment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'BOH2\\BOH2+SIM+Exo+Assessment_October7'\n",
    "# find all csv files in the folder\n",
    "files = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "for file in files:\n",
    "# file = files[0]\n",
    "    print(file)\n",
    "    df = pd.read_csv(folder + '/' + file)\n",
    "    # create a dictionary of the columns to first row\n",
    "    colnamedict = {col: df[col][0].split('- Supervisor -')[-1] for col in df.columns}\n",
    "    # remove first 4 rows\n",
    "    row0 = df.iloc[0]\n",
    "    df = df.iloc[4:]\n",
    "    # display(df.head())\n",
    "    mcCols = [col for col in df.columns if '#2' in col]\n",
    "    print(mcCols)\n",
    "    timeCol = 'TM Scale'\n",
    "    entrustCol = 'Entrustment'\n",
    "    commCol = 'Comms scale'\n",
    "    colCE = 'CI occurred'\n",
    "    colCEReason = 'CI explanation'\n",
    "\n",
    "    rubricQues = [timeCol, entrustCol, commCol]\n",
    "    for col in rubricQues:\n",
    "        df[col] = df[col].str.extract(r'Lvl (\\d+)')[0]\n",
    "    # for a row define fail criteria\n",
    "    notimportantCols = ['SIM Exo item#2_1', 'SIM Exo item#2_2', 'SIM Exo item#2_4', 'SIM Exo item#2_11']\n",
    "    def failCriteria(row):\n",
    "        name = row[colNameG] + ' ' + row[colNameF]\n",
    "        print(f'{row[colId]} ({name})----------------------------------')\n",
    "        noItems =[]\n",
    "        fail = False\n",
    "        # if any of the mc columns except the 0, 1, 3, -3 positions are No they are failed\n",
    "        importantCols = [col for col in mcCols if col not in notimportantCols + ['SIM Exo item#2_5']]\n",
    "        for col in importantCols:\n",
    "            if row[col] == 'No':\n",
    "                noItems.append(colnamedict[col])\n",
    "                fail = True\n",
    "        # if more than 2 of the not important columns are No, then fail\n",
    "        count = 0\n",
    "        for col in notimportantCols:\n",
    "            if row[col] == 'No':\n",
    "                noItems.append(colnamedict[col])\n",
    "                count += 1\n",
    "        if count > 2:\n",
    "            fail = True\n",
    "        \n",
    "        if row['SIM Exo item#2_5'] == 'No':\n",
    "            noItems.append(colnamedict['SIM Exo item#2_5'])\n",
    "            if count>1:\n",
    "                fail = True\n",
    "        \n",
    "        if row[entrustCol] == '1' or row[entrustCol] == '2':\n",
    "            noItems.append(entrustCol)\n",
    "            # print(f'{row[\"Student ID\"]} failed on {entrustCol}, Value: {row[entrustCol]}')\n",
    "            fail = True\n",
    "        \n",
    "        if row[timeCol] == '1' or row[timeCol] == '2':\n",
    "            noItems.append(timeCol)\n",
    "            # print(f'Failed on {timeCol}, Value: {row[timeCol]}')\n",
    "            fail = True\n",
    "        \n",
    "\n",
    "        if row[colCE] == 'Yes':\n",
    "            noItems.append(f'{colCE}. Reason: {row[colCEReason]}')\n",
    "            print(f'Failed on critical incident. Reason: {row[colCEReason]}')\n",
    "            fail = True\n",
    "        \n",
    "        reason = f'{\"  |  \". join(noItems)}'\n",
    "        print(f\"Unsatisfactory on {noItems} \\nConclusion: {'Fail' if fail else 'Pass'}\\n\")\n",
    "        return fail, reason\n",
    "\n",
    "    # for i, row in df.iterrows():\n",
    "    #     print(f'{i}-----------------')\n",
    "    #     failCriteria(row)\n",
    "        \n",
    "    print('\\n\\n')\n",
    "    # Invesree the current order of rows\n",
    "    df = df.iloc[::-1]\n",
    "    df[['Fail', 'Reason']] = pd.DataFrame(df.apply(failCriteria, axis=1).tolist(), index=df.index)\n",
    "    df.head()\n",
    "\n",
    "    # add the first row back\n",
    "    df = pd.concat([row0.to_frame().T, df])\n",
    "    df.to_excel(f'{folder}/{file.split(\".\")[0]}_processed2.xlsx', index=False)\n",
    "    wb = load_workbook(f'{folder}/{file.split(\".\")[0]}_processed2.xlsx')\n",
    "    ws = wb.active\n",
    "\n",
    "    # Define the red fill color\n",
    "    red_fill = PatternFill(start_color='FFC7CE', end_color= 'FFC7CE', fill_type='solid')\n",
    "\n",
    "    # Apply conditional formatting to the \"Student ID\" column based on the \"Fail\" column\n",
    "    # Find the column indexes by names\n",
    "    student_id_col = df.columns.get_loc('Student ID') + 1  # 1-based index for openpyxl\n",
    "    fail_col = df.columns.get_loc('Fail') + 1  # 1-based index for openpyxl\n",
    "    uom_col = df.columns.get_loc('uomid') + 1  # 1-based index for openpyxl\n",
    "    gname_col = df.columns.get_loc('gname') + 1  # 1-based index for openpyxl\n",
    "    fname_col = df.columns.get_loc('fname') + 1  # 1-based index for openpyxl\n",
    "    # Loop through the rows to apply formatting\n",
    "    for row in range(2, len(df) + 2):  # Starting from row 2 (skipping the header)\n",
    "        if ws.cell(row=row, column=fail_col).value:  # If 'Fail' is True\n",
    "            ws.cell(row=row, column=student_id_col).fill = red_fill\n",
    "            ws.cell(row=row, column=fail_col).fill = red_fill\n",
    "            ws.cell(row=row, column=uom_col).fill = red_fill\n",
    "            ws.cell(row=row, column=gname_col).fill = red_fill\n",
    "            ws.cell(row=row, column=fname_col).fill = red_fill\n",
    "\n",
    "    # Save the workbook with the applied formatting\n",
    "    wb.save(f'{folder}/{file.split(\".\")[0]}_processed2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDS2 Endo Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guttmanPath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo guttman teeth standard 28 Aug.xlsx'\n",
    "workbook, folder, file = loadWorkbook(guttmanPath)\n",
    "studentInfoDict = {}\n",
    "for sheet in workbook.sheetnames:\n",
    "    df = loadDfFromSheet(workbook, sheetName=sheet)\n",
    "    tooth = sheet.split('_')[-1]\n",
    "    code = sheet.split('_')[0]\n",
    "    print(sheet)\n",
    "    # print(df[colId].value_counts())\n",
    "    df[colId] = df[colId].astype('Int64')\n",
    "    for i, row in df.iterrows():\n",
    "        if row[colId] not in studentInfoDict.keys():\n",
    "            studentInfoDict[row[colId]] = {sheet: row}\n",
    "        else:\n",
    "            studentInfoDict[row[colId]][sheet] = row\n",
    "\n",
    "# names get\n",
    "\n",
    "namedf = pd.read_excel('2024 MDS Student List_v10.xlsx')\n",
    "namedict = {}\n",
    "# create id name dict\n",
    "for i, row in namedf.iterrows():\n",
    "    namedict[int(row[colId])] = row['First Name'] + ' ' + row['Surname']\n",
    "\n",
    "print(namedict) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageSize = ( 11.69 * inch, 8.27 * 1 * inch) # page size\n",
    "print(pageSize)\n",
    "figSize = (pageSize[0] / 100, pageSize[1] / 100)\n",
    "\n",
    "# Define the margins\n",
    "leftMargin = 0 * inch\n",
    "rightMargin = 0 * inch\n",
    "topMargin = 0.5 * inch\n",
    "bottomMargin = 0 * inch\n",
    "sns.set_palette('colorblind')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "def createPlotImage(fig):\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        return buf\n",
    "\n",
    "def addPlotImage(fig, ratio = None):\n",
    "        plotImage = createPlotImage(fig)\n",
    "        image = Image(plotImage)\n",
    "        # print(image.drawWidth, image.drawHeight)\n",
    "        \n",
    "        # Resize image to fit within margins\n",
    "        max_height = pageSize[1] - topMargin - bottomMargin  # Max height for Page\n",
    "        max_width = pageSize[0] - leftMargin - rightMargin  # Max width for Page\n",
    "        if ratio is not None:\n",
    "            max_width = max_width * ratio\n",
    "            max_height = max_height * ratio\n",
    "        aspect_ratio = min(max_width / image.drawWidth, max_height / image.drawHeight)\n",
    "        image.drawWidth *= aspect_ratio\n",
    "        image.drawHeight *= aspect_ratio\n",
    "        # print(image.drawWidth, image.drawHeight, aspect_ratio)\n",
    "        # if idx + 1 < numSubplots:\n",
    "        #    self.elements.append(PageBreak())\n",
    "        #self.elements.append(PageBreak())\n",
    "        plt.close(fig)\n",
    "        return(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubricRefDf = pd.read_excel('Rubric Reference Table.xlsx')\n",
    "rubricFullNames = {'PS': 'Professionalism', 'TS': 'Time Management', 'ES': 'Entrustment', 'CS': 'Communication'}\n",
    "with open('MC Reference Dictionary.json', 'r') as f:\n",
    "    mcReferenceDict = json.load(f)\n",
    "# get the dict part of mcReferenceDict based on the respectiveMCKey\n",
    "countsDfDict = {}\n",
    "def createReport(studentDict, id):\n",
    "    name = namedict[id]\n",
    "    os.makedirs(f'{folder}/Endo Report', exist_ok=True)\n",
    "    doc = SimpleDocTemplate(f'{folder}/Endo Report/{id} ({name}).pdf', pagesize = pageSize, leftMargin=leftMargin,\n",
    "                    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    elements = []\n",
    "    # first sort based on tooth\n",
    "    keys = studentDict.keys()\n",
    "    sortedKeys = sorted(keys, key=lambda x: (int(x.split('_')[-1]), x.split('_')[0]))\n",
    "\n",
    "    \n",
    "    idheading = Paragraph(f'{id} ({name})', headingStyle)\n",
    "    elements.append(KeepTogether([idheading, Spacer(1, 22)]))\n",
    "    prevTooth = None\n",
    "    i=0\n",
    "    for sheet in sortedKeys:\n",
    "        row = studentDict[sheet]\n",
    "        row = pd.DataFrame([row])\n",
    "        code = sheet.split('_')[0]\n",
    "        tag = sheet.split('_')[1]\n",
    "        mcCols = findMCColumns(row, code)\n",
    "        rubricQues = [q for q in variableUtils.rubricQues if q in row.columns]\n",
    "        # print(mcCols, rubricQues)\n",
    "        tooth = sheet.split('_')[-1]\n",
    "        \n",
    "        if tooth!=prevTooth:\n",
    "            i=0\n",
    "            prevTooth = tooth\n",
    "            # page 1\n",
    "            # print('This is page one, adding rubric info')\n",
    "            heading = Paragraph(f'Teeth Number {tooth} ', heading2Style)\n",
    "            elements.append(heading)\n",
    "            elements.append(Spacer(1, 12))\n",
    "            \n",
    "            # Add a table for rubric info\n",
    "            rubricDf = pd.DataFrame(columns = ['Rubric Question', 'Score', 'Description'])\n",
    "            for q in rubricQues:\n",
    "                score = int(row[q].iloc[0])\n",
    "                fulltext = rubricRefDf[rubricRefDf['Score'] == score][rubricFullNames[q]].iloc[0]\n",
    "                rubricDf = pd.concat([rubricDf, pd.DataFrame([[rubricFullNames[q], score, fulltext]], columns = rubricDf.columns)])\n",
    "            # display(rubricDf)\n",
    "            rubricTable = createTable(rubricDf, 'Rubric Scores', [2, 1, 6], 0.9, [2])\n",
    "            elements.append(rubricTable)\n",
    "\n",
    "            # Add critical incident info\n",
    "            ceheading = Paragraph('Critical Incident', subsubheadingStyle)\n",
    "            elements.append(ceheading)\n",
    "            elements.append(Spacer(1, 12))\n",
    "            if row[colCE].iloc[0] == 'Yes':\n",
    "                reason = row[colCEReason].iloc[0]\n",
    "                ceText = f'Critical Incident occurred. Reason: {reason if reason != \"\" else \"No reason provided\"}'\n",
    "                ce = Paragraph(ceText, tableTextStyle)\n",
    "                elements.append(ce)\n",
    "                elements.append(Spacer(1, 12))\n",
    "            elif row[colCE].iloc[0] == 'No':\n",
    "                ce = Paragraph('No Critical Incident occurred', tableTextStyle)\n",
    "                elements.append(ce)\n",
    "                elements.append(Spacer(1, 12))\n",
    "            # Add comments\n",
    "            comments = row[colComments].iloc[0]\n",
    "            if comments != '' and comments is not None:\n",
    "                commentHeading = Paragraph('Supervisor Comments', subsubheadingStyle)\n",
    "                elements.append(commentHeading)\n",
    "                elements.append(Spacer(1, 12))\n",
    "                comment = Paragraph(comments, tableTextStyle)\n",
    "                elements.append(comment)\n",
    "                elements.append(Spacer(1, 12))\n",
    "            # Add a page break\n",
    "            elements.append(PageBreak())\n",
    "\n",
    "        \n",
    "\n",
    "        # each row is for a tooth/one page of items\n",
    "\n",
    "\n",
    "        \n",
    "        # add heading for teeth\n",
    "        heading = Paragraph(f'Teeth Number {tooth} ', heading2Style)\n",
    "        elements.append(heading)\n",
    "        elements.append(Spacer(1, 12))\n",
    "        # add subheading for code\n",
    "        subheading = Paragraph(f'{code} {tag}', subheadingStyle)\n",
    "        elements.append(subheading)\n",
    "\n",
    "        # add a table for the mc items\n",
    "        respectiveMCKey = [key for key in mcReferenceDict.keys() if re.match(f'{code}_MC\\d+', key)]\n",
    "        respectiveMCKey = [key for key in respectiveMCKey if tag in key]\n",
    "        # print(respectiveMCKey)\n",
    "        mcRef = {key: mcReferenceDict[key] for key in respectiveMCKey}\n",
    "        # change keys to the respective MC number\n",
    "        mcRef = {re.search(r'MC(\\d+)', key).group(): value for key, value in mcRef.items()}\n",
    "        # print(mcRef)\n",
    "        mcDf = pd.DataFrame(columns = ['Question', 'Full Text', 'Marking'])\n",
    "        for mc in mcRef.keys():\n",
    "            mcText = mcRef[mc]\n",
    "            score = row[f'{code}_{mc}'].iloc[0]\n",
    "            mcDf = pd.concat([mcDf, pd.DataFrame([[mc, mcText, score]], columns = mcDf.columns)])\n",
    "        mcDf.replace({1: 'Yes', 0: 'No'}, inplace=True) \n",
    "        # display(mcDf)\n",
    "        mcTable = createTable(mcDf, 'MC Questions', [1, 3, 1], 0.9, [1], tableTextStyle, cellHighlight=True)\n",
    "        elements.append(mcTable)\n",
    "        elements.append(PageBreak())\n",
    "    doc.build(elements)\n",
    "for id, studentDict in studentInfoDict.items():\n",
    "    print(id)\n",
    "    # if not (id == 1420119 or id == 1184941):\n",
    "    #     continue\n",
    "    try:\n",
    "        createReport(studentDict, id)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    # break\n",
    "# createReport(studentDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPie(ax, valueCounts, title, colors=None):\n",
    "    # print(valueCounts)\n",
    "    # define a fixed colour palette color blind friendly\n",
    "    # print(valueCounts.index)\n",
    "    colorList = [colors[val] for val in valueCounts.index] if colors is not None else None\n",
    "    total = valueCounts.values.sum()\n",
    "    \n",
    "    wedges, texts, autotexts = ax.pie(valueCounts, labels=valueCounts.index, autopct= lambda x: autopct(x, total), startangle=90, colors=sns.color_palette() if colorList is None else colorList,\n",
    "            wedgeprops={'edgecolor': 'black', 'linewidth': 0.35}, labeldistance = 0.7, pctdistance=1.15, textprops={'color': 'black', 'fontsize': 10})\n",
    "    for autotext in texts:\n",
    "        autotext.set_color('black')\n",
    "        autotext.set_fontsize(10)\n",
    "    ax.set_title(title)\n",
    "\n",
    "def processLabel(label):\n",
    "    words = label.split()  # Split the label into words\n",
    "    if len(words) >= 3:\n",
    "        # Truncate the third word to its first four letters\n",
    "        words = words[:2] + [words[2][:4]]\n",
    "    elif len(words) == 2:\n",
    "        # If there are only two words, use them as is\n",
    "        words = words\n",
    "    elif len(words) == 1:\n",
    "        # If there is only one word, use it as is\n",
    "        words = words\n",
    "    return ' '.join(words)\n",
    "\n",
    "def createSubplot(ax, subset, show_legend=False, colors = None, xticks = None):\n",
    "    \n",
    "    subset.plot(kind='bar', stacked=True, ax=ax, edgecolor='black', color=colors if colors is not None else sns.color_palette(), legend=show_legend)\n",
    "    # Add the legend only if show_legend is True\n",
    "    if show_legend:\n",
    "        ax.legend(title='', loc='upper right', bbox_to_anchor=(1.25, 1), bbox_transform=ax.transAxes)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Count')\n",
    "    # desired_ticks = range(len(xticks))\n",
    "    # print(desired_ticks)\n",
    "    # ax.set_xticks(range(len(xticks)))\n",
    "    # ax.set_xticklabels(xticks)\n",
    "    # y ticks should be integers\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    # ylim should start from 0\n",
    "    ax.set_ylim(0, ax.get_ylim()[1] * 1.1)\n",
    "    # minimum gap of y ticks is 1\n",
    "    if ax.get_ylim()[1] < 5:\n",
    "        ax.yaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "    # Show gridlines on the y-axis\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    # Convert index to strings to avoid errors with re.sub\n",
    "    subset.index = [str(i) for i in subset.index]\n",
    "    # x tick labels, remove _ and put space\n",
    "    subset.index = [processLabel(i) for i in subset.index]\n",
    "    ax.set_xticklabels(subset.index, rotation=45, ha='center')\n",
    "\n",
    "    # Check for bars with total value of zero\n",
    "    for i, total in enumerate(subset.sum(axis=1)):\n",
    "        if total == 0 and subset.index[i] != '':\n",
    "            # Overlay 'No data available' text vertically, adjusted lower\n",
    "            ax.text(i, ax.get_ylim()[0] + 0.25 * ax.get_ylim()[1], 'No data available', \n",
    "                    ha='center', va='center', rotation=90, fontsize=10, color='black', alpha=0.7)\n",
    "\n",
    "def createMcReferenceDf(code, tag):\n",
    "    respectiveMCKey = [key for key in mcReferenceDict.keys() if re.match(f'{code}_MC\\d+', key)]\n",
    "    respectiveMCKey = [key for key in respectiveMCKey if tag in key]\n",
    "    # get the dict part of mcReferenceDict based on the respectiveMCKey\n",
    "    mcRef = {key: mcReferenceDict[key] for key in respectiveMCKey}\n",
    "    # print(mcRef)\n",
    "    # Trun mcRef into a DataFrame\n",
    "    if mcRef:\n",
    "        mcRefdf = pd.DataFrame(list(mcRef.items()), columns=['Abbreviation', 'Full Text'])\n",
    "    \n",
    "        # extract MC\\d+ from Abbreviation and replace it\n",
    "        if code!= '114' and code != '115':\n",
    "            mcRefdf['MC'] = mcRefdf['Abbreviation'].str.extract(r'(MC\\d+)')\n",
    "        else:\n",
    "            mcRefdf['MC'] = mcRefdf['Abbreviation'].str.extract(r'(MC\\d+)')\n",
    "            extracted_values = mcRefdf['Abbreviation'].str.extract(r'(H/S|U/S)', expand=False)\n",
    "            # print(extracted_values)\n",
    "            # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "            mcRefdf['MC'] = mcRefdf['MC'] + ' ' + extracted_values\n",
    "        # drop the Abbreviation column\n",
    "        # print(mcRefdf.columns)\n",
    "        # Swap columns\n",
    "        mcRefdf = mcRefdf[['MC', 'Full Text']]\n",
    "        # mcRefdf.drop(columns=['Abbreviation'], inplace=True)\n",
    "        # display(mcRefdf)\n",
    "    \n",
    "    else:\n",
    "        # print(mcRef)\n",
    "        mcRefdf = None\n",
    "    return mcRefdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageSize = ( 11.69 * inch, 8.27 * 2 * inch) # page size\n",
    "print(pageSize)\n",
    "figSize = (pageSize[0] / 100, pageSize[1] / 100)\n",
    "\n",
    "# Define the margins\n",
    "leftMargin = 0 * inch\n",
    "rightMargin = 0 * inch\n",
    "topMargin = 0.5 * inch\n",
    "bottomMargin = 0 * inch\n",
    "sns.set_palette('colorblind')\n",
    "labelYes = 'Yes'\n",
    "labelNo = 'No'\n",
    "labelNA = 'Not Reviewed'\n",
    "countsDfDict = {}\n",
    "Checklistcolors = {'Yes': 'blue', 'No': 'orange', 'Not Reviewed': 'lightgrey'}\n",
    "doc = SimpleDocTemplate(f'{folder}/Endo Report/Summary.pdf', pagesize = pageSize, leftMargin=leftMargin,\n",
    "                    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "sheetNames = workbook.sheetnames\n",
    "sortedKeys = sorted(sheetNames, key=lambda x: (int(x.split('_')[-1]), x.split('_')[0]))\n",
    "elements = []\n",
    "\n",
    "for sheet in sortedKeys:\n",
    "    df = loadDfFromSheet(workbook, sheetName=sheet)\n",
    "    df.fillna('NA', inplace=True)\n",
    "    tooth = sheet.split('_')[-1]\n",
    "    code = sheet.split('_')[0]\n",
    "    tag = sheet.split('_')[1]\n",
    "    mcCols = findMCColumns(df, code)\n",
    "    # sort the columns based on the number\n",
    "    mcCols = sorted(mcCols, key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "    rubricQues = [q for q in variableUtils.rubricQues if q in df.columns]\n",
    "\n",
    "    # add heading for teeth\n",
    "    heading = Paragraph(f'Teeth Number {tooth} ', heading2Style)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    # add subheading for code\n",
    "    subheading = Paragraph(f'{code} {tag}', subheadingStyle)\n",
    "    elements.append(subheading)\n",
    "    elements.append(Spacer(1, 15))\n",
    "\n",
    "    # mc questions graph\n",
    "    countsMCWiseDf = pd.DataFrame(index=mcCols, columns=[labelYes, labelNo, labelNA])\n",
    "    for col in mcCols:\n",
    "        countsMCWiseDf.at[col, labelYes] = (df[col] == 1).sum() + (df[col] == '1').sum()\n",
    "        countsMCWiseDf.at[col, labelNo] = (df[col] == 0).sum() + (df[col] == '0').sum()\n",
    "        countsMCWiseDf.at[col, labelNA] = (df[col] == 'NA').sum()\n",
    "    \n",
    "    # value counts for rubric questions\n",
    "    display(countsMCWiseDf)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(figSize[0], figSize[1] / 3))\n",
    "    createSubplot(ax, countsMCWiseDf, show_legend=True, colors=Checklistcolors)\n",
    "    ax.set_title('MC Questions')\n",
    "    ax.set_xticklabels([i.split('_')[1] for i in countsMCWiseDf.index], rotation=0, ha='center')\n",
    "    image = addPlotImage(fig)\n",
    "    elements.append(image)\n",
    "    elements.append(Spacer(1, 15))\n",
    "    # mc reference table\n",
    "    mcRefdf = createMcReferenceDf(code, tag)\n",
    "    if mcRefdf is not None:\n",
    "        mcRefTable = createTable(mcRefdf, 'MC Reference Table', [1, 4], 0.9, [1], tableTextStyle)\n",
    "        elements.append(mcRefTable)\n",
    "        elements.append(Spacer(1, 15))\n",
    "    elements.append(PageBreak())\n",
    "    \n",
    "    # Add rubric pie chart\n",
    "    heading = Paragraph(f'Rubrics', subheadingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 15))\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(figSize[0], figSize[1]))\n",
    "    for i, q in enumerate(rubricQues):\n",
    "        valueCounts = df[q].value_counts()\n",
    "        # remove NA from value counts\n",
    "        valueCounts = valueCounts.drop('NA', errors='ignore')\n",
    "        # keys as int\n",
    "        valueCounts.index = valueCounts.index.astype(int)\n",
    "        plotPie(ax.flatten()[i], valueCounts, rubricFullNames[q], colors=None)\n",
    "    image = addPlotImage(fig, 0.8)\n",
    "    elements.append(image)\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "doc.build(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'BOH2\\BOH2+524_578_September+22,+2024_21.24\\\\578_September 22, 2024_21.24.xlsx'\n",
    "folder, file, ext = getFolderandFileName(filepath)\n",
    "df = pd.read_excel(filepath)\n",
    "aggFunc = {'Comments': lambda x: '\\n==============\\n '.join(x)}\n",
    "df = df.groupby([colId]).agg(aggFunc).reset_index()\n",
    "df.to_excel(f'{folder}/comments.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OSCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main OSCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOH1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH1\\OSCE\\All OSCE.xlsx'\n",
    "workbook, folder, file = loadWorkbook(workbookpath)\n",
    "colCEReason = 'Critical comments'\n",
    "colCE = 'Critical incident'\n",
    "colNameG = 'Given name'\n",
    "colNameF = 'Family name'\n",
    "studentlist = getStudentList(cohort = 'BOH1 (2024)')\n",
    "colRating = 'Overall rating_1'\n",
    "colComments = 'Feedback'\n",
    "def getTotals(df, mcCols, newRubricQues):\n",
    "    df['MC Total'] = df[mcCols].sum(axis=1)/len(mcCols)\n",
    "    df['MC Total'] = df['MC Total'].round(2)\n",
    "    # add a row for sum of each column\n",
    "    total_row = pd.Series({col: df[col].sum() if col in mcCols + list(newRubricQues) else None for col in df.columns}, name='Total')\n",
    "    df = pd.concat([df, total_row.to_frame().T])\n",
    "\n",
    "    df.sort_values(by='Total', ascending=False, inplace=True, axis=1)\n",
    "    df.sort_values(by='MC Total', ascending=False, inplace=True, axis=0)\n",
    "    return df\n",
    "rubricW = {'PS': 0.05, 'CS': 0.1, 'TS': .1, 'ES': .2}\n",
    "rubricDenom = {'PS': 2, 'CS': 4, 'TS': 4, 'ES': 4}\n",
    "dflowes= pd.DataFrame(columns=['Station', colId, 'Total CE Penalty 20%', 'ES'])\n",
    "for station in workbook.sheetnames:\n",
    "    df = loadDfFromSheet(workbook, sheetName=station)\n",
    "    print('='*20)\n",
    "    print(station)\n",
    "    df.rename(columns = {'Q3.5':colSupervisor}, inplace=True)\n",
    "    \n",
    "    mcColsText = f'{station}_\\d+'\n",
    "    mcCols = [col for col in df.columns if re.match(mcColsText, col)]\n",
    "    # extract \\d+ and replace name with MC\\d+\n",
    "    df.rename(columns={col: ('MC' + re.search(r'_(\\d+)', col).group()).replace('_', '') for col in mcCols}, inplace=True)\n",
    "    mcCols = [col for col in df.columns if 'MC' in col]\n",
    "    # print(mcCols)\n",
    "    renameCols = {'Professionalism': 'PS', 'Entrustment': 'ES', 'Communication': 'CS', 'Time Management': 'TS'}\n",
    "    df.rename(columns = {col: newCol for col, newCol in renameCols.items() if col in df.columns}, inplace=True)\n",
    "    \n",
    "    rubricQues = [q for q in variableUtils.rubricQues if q in df.columns]\n",
    "    # full name dict\n",
    "    mcFullText = {col: df.iloc[0][col].split(' - ')[-1] for col in mcCols}\n",
    "    df.drop(0, inplace=True)\n",
    "    \n",
    "    df[colSupervisor] = df[colSupervisor].str.strip()\n",
    "    # filter out supervisors\n",
    "    if station =='Station 1':\n",
    "        print(df[colSupervisor].value_counts())\n",
    "        df = df[(df[colSupervisor]=='Quor Teh')|(df[colSupervisor]=='Susan Tran')]\n",
    "\n",
    "    df[colId] = pd.to_numeric(df[colId], errors='coerce').astype('Int64')\n",
    "    df = df[df[colId].isin(studentlist)]\n",
    "    print('Number of students:', df[colId].nunique())\n",
    "    # print(df[colId].value_counts())\n",
    "    # find students in studentlist but not in df\n",
    "    missing = [id for id in studentlist if id not in df[colId].values]\n",
    "    print(f'Missing students: {missing}')\n",
    "\n",
    "    df[mcCols] = df[mcCols].replace({'Yes': 1, 'No': 0})\n",
    "    df[colSupervisor] = df[colSupervisor].fillna(' ').astype(str)   \n",
    "    for ques in rubricQues:\n",
    "        df[ques] = df[ques].str.extract(r'Lvl (\\d+)')[0]\n",
    "        df[ques] = pd.to_numeric(df[ques], errors='coerce').astype('Int64')\n",
    "    newRubricQues = set()\n",
    "    df = vectoriseRubricQues(df, rubricQues, newRubricQues)\n",
    "    \n",
    "    dfguttman = df[[colId, colNameG, colNameF, colFinished, colSupervisor]+mcCols+list(newRubricQues)+ rubricQues + [colCE, colCEReason, colComments, colRating, colDate]]\n",
    "    dfguttmanbest = aggregator(dfguttman, mcCols + list(newRubricQues), colCE, colCEReason, [colComments], colSupervisor)\n",
    "    thisrubricDenom = {key: rubricDenom[key] for key in rubricQues}\n",
    "    thisrubricW = {key: rubricW[key] for key in rubricQues}\n",
    "    \n",
    "    dfguttman = getTotals(dfguttman, mcCols, newRubricQues)\n",
    "    dfguttman['Rubric Score'] = dfguttman.apply(lambda row: sum(row[ques] * thisrubricW[ques] / thisrubricDenom[ques] for ques in rubricQues), axis=1)/sum(thisrubricW.values())\n",
    "    dfguttman['Rubric Score'] = dfguttman['Rubric Score'].round(2)\n",
    "    dfguttman['Total'] = 0.7*dfguttman['MC Total'] + 0.3*dfguttman['Rubric Score']    \n",
    "    df = dfguttman.sort_values(by='Total', ascending=False)\n",
    "    dfguttman['Total'] = dfguttman['Total'].round(2)\n",
    "\n",
    "    dfguttmanbest = getTotals(dfguttmanbest, mcCols, newRubricQues)\n",
    "    dfguttmanbest['Rubric Score'] = dfguttmanbest.apply(lambda row: sum(row[ques] * thisrubricW[ques] / thisrubricDenom[ques] for ques in rubricQues), axis=1)/sum(thisrubricW.values())\n",
    "    dfguttmanbest['Rubric Score'] = dfguttmanbest['Rubric Score'].round(2)\n",
    "    dfguttmanbest['Total'] = 0.7*dfguttmanbest['MC Total'] + 0.3*dfguttmanbest['Rubric Score']\n",
    "    dfguttmanbest = dfguttmanbest.sort_values(by='Total', ascending=False)\n",
    "    dfguttmanbest['Total'] = dfguttmanbest['Total'].round(2)*100\n",
    "    dfguttmanbest['Total CE Penalty 20%'] = dfguttmanbest['Total'] * dfguttmanbest[colCE].apply(lambda x: 0.8 if x == 'Yes' else 1.0)\n",
    "    dfguttmanbest['Total CE Penalty 20%'] = dfguttmanbest['Total CE Penalty 20%'].round(2)\n",
    "    dfguttmanbest.sort_values(by=colId, inplace=True)\n",
    "    # scatter plot of Total CE Penalty 20% vs colOverallRating\n",
    "\n",
    "    # correlation matrix between each mc question and the total score\n",
    "    corr = dfguttmanbest[mcCols + ['Total']].corr()['Total']\n",
    "    # plot correlation matrix\n",
    "    sns.heatmap(corr.to_frame().T, annot=True, cmap='coolwarm', cbar=False, fmt=\".2f\")\n",
    "    plt.title(f'{station} Correlation Matrix')\n",
    "    plt.savefig(f'{folder}/{station} Correlation Matrix.png')\n",
    "    plt.show()\n",
    "    #  filter with 'ES' == 1\n",
    "    lowes = dfguttmanbest\n",
    "    lowes['Station'] = station\n",
    "    lowes = lowes[['Station', colId, 'Total CE Penalty 20%', 'ES']]\n",
    "\n",
    "    dflowes = pd.concat([dflowes, lowes])\n",
    "    \n",
    "    # display(dfguttman.tail())\n",
    "    # saveDf(dfguttman, f'{folder}/{file} processed.xlsx', sheet_name=station, numColsToColor=len(mcCols) + len(newRubricQues))\n",
    "    saveDf(dfguttmanbest, f'{folder}/BOH1 OSCE best.xlsx', sheet_name=f'{station}', numColsToColor=len(mcCols) + len(newRubricQues))\n",
    "# find correlation between ES and Total CE Penalty 20%\n",
    "corr = dflowes['ES'].corr(dflowes['Total CE Penalty 20%'])\n",
    "plt.scatter(dflowes['ES'], dflowes['Total CE Penalty 20%'])\n",
    "plt.xlabel('ES')\n",
    "plt.ylabel('Total CE Penalty 20%')\n",
    "plt.title(f'Correlation: {corr}')\n",
    "plt.show()\n",
    "print(corr)\n",
    "# dflowes = dflowes.pivot(index=colId, columns='Station', values='Total CE Penalty 20%').reset_index()\n",
    "# dflowes.to_excel(f'{folder}/BOH1 OSCE ES.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOH2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH2\\OSCE\\All OSCE.xlsx'\n",
    "workbook, folder, file = loadWorkbook(workbookpath)\n",
    "colCEReason = 'Critical comments'\n",
    "colCE = 'Critical incident'\n",
    "colNameG = 'Given name'\n",
    "colNameF = 'Family name'\n",
    "# studentlist = getStudentList(cohort = 'BOH2 (2024)')\n",
    "colRating = 'Overall rating_1'\n",
    "colComments = 'Feedback'\n",
    "def getTotals(df, mcCols, newRubricQues):\n",
    "    df['MC Total'] = df[mcCols].sum(axis=1)/len(mcCols)\n",
    "    df['MC Total'] = df['MC Total'].round(2)\n",
    "    # add a row for sum of each column\n",
    "    total_row = pd.Series({col: df[col].sum() if col in mcCols + list(newRubricQues) else None for col in df.columns}, name='Total')\n",
    "    df = pd.concat([df, total_row.to_frame().T])\n",
    "\n",
    "    df.sort_values(by='Total', ascending=False, inplace=True, axis=1)\n",
    "    df.sort_values(by='MC Total', ascending=False, inplace=True, axis=0)\n",
    "    return df\n",
    "rubricW = {'PS': 0.05, 'CS': 0.1, 'TS': .1, 'ES': .2}\n",
    "rubricDenom = {'PS': 2, 'CS': 4, 'TS': 4, 'ES': 4}\n",
    "dflowes= pd.DataFrame(columns=['Station', colId, 'Total CE Penalty 20%', 'ES'])\n",
    "for station in workbook.sheetnames:\n",
    "    df = loadDfFromSheet(workbook, sheetName=station)\n",
    "    print('='*20)\n",
    "    print(station)\n",
    "    df.rename(columns = {'Q3.5':colSupervisor}, inplace=True)\n",
    "    \n",
    "    mcColsText = f'{station}_\\d+'\n",
    "    mcCols = [col for col in df.columns if re.match(mcColsText, col)]\n",
    "    # extract \\d+ and replace name with MC\\d+\n",
    "    df.rename(columns={col: ('MC' + re.search(r'_(\\d+)', col).group()).replace('_', '') for col in mcCols}, inplace=True)\n",
    "    mcCols = [col for col in df.columns if 'MC' in col]\n",
    "    # print(mcCols)\n",
    "    renameCols = {'Professionalism': 'PS', 'Entrustment': 'ES', 'Communication': 'CS', 'Time Management': 'TS'}\n",
    "    df.rename(columns = {col: newCol for col, newCol in renameCols.items() if col in df.columns}, inplace=True)\n",
    "    \n",
    "    rubricQues = [q for q in variableUtils.rubricQues if q in df.columns]\n",
    "    # full name dict\n",
    "    mcFullText = {col: df.iloc[0][col].split(' - ')[-1] for col in mcCols}\n",
    "    df.drop(0, inplace=True)\n",
    "    \n",
    "    # filter out supervisors\n",
    "    df[colSupervisor] = df[colSupervisor].str.strip()\n",
    "    df[colSupervisor] = df[colSupervisor].str.lower()   \n",
    "    df[colId] = pd.to_numeric(df[colId], errors='coerce').astype('Int64')\n",
    "    # df = df[df[colId].isin(studentlist)]\n",
    "    print(df[colId].value_counts())\n",
    "    print('Number of students:', df[colId].nunique())\n",
    "    # missing = [id for id in studentlist if id not in df[colId].values]\n",
    "    # print(f'Missing students: {missing}')\n",
    "    if station =='Station 3':\n",
    "        print(df[colSupervisor].value_counts())\n",
    "        df = df[(df[colSupervisor]=='venessa misale')|(df[colSupervisor]=='lucyanne')]\n",
    "\n",
    "    # find students in studentlist but not in df\n",
    "    # missing = [id for id in studentlist if id not in df[colId].values]\n",
    "    # print(f'Missing students: {missing}')\n",
    "    \n",
    "    df[mcCols] = df[mcCols].replace({'Yes': 1, 'No': 0})\n",
    "    df[colSupervisor] = df[colSupervisor].fillna(' ').astype(str)   \n",
    "    for ques in rubricQues:\n",
    "        df[ques] = df[ques].str.extract(r'Lvl (\\d+)')[0]\n",
    "        df[ques] = pd.to_numeric(df[ques], errors='coerce').astype('Int64')\n",
    "    newRubricQues = set()\n",
    "    df = vectoriseRubricQues(df, rubricQues, newRubricQues)\n",
    "    \n",
    "    dfguttman = df[[colId, colNameG, colNameF, colFinished, colSupervisor]+mcCols+list(newRubricQues)+ rubricQues + [colCE, colCEReason, colComments, colRating, colDate]]\n",
    "    dfguttmanbest = aggregator(dfguttman, mcCols + list(newRubricQues), colCE, colCEReason, [colComments], colSupervisor)\n",
    "    thisrubricDenom = {key: rubricDenom[key] for key in rubricQues}\n",
    "    thisrubricW = {key: rubricW[key] for key in rubricQues}\n",
    "    \n",
    "    dfguttman = getTotals(dfguttman, mcCols, newRubricQues)\n",
    "    dfguttman['Rubric Score'] = dfguttman.apply(lambda row: sum(row[ques] * thisrubricW[ques] / thisrubricDenom[ques] for ques in rubricQues), axis=1)/sum(thisrubricW.values())\n",
    "    dfguttman['Rubric Score'] = dfguttman['Rubric Score'].round(2)\n",
    "    dfguttman['Total'] = 0.7*dfguttman['MC Total'] + 0.3*dfguttman['Rubric Score']    \n",
    "    df = dfguttman.sort_values(by='Total', ascending=False)\n",
    "    dfguttman['Total'] = dfguttman['Total'].round(2)\n",
    "\n",
    "    dfguttmanbest = getTotals(dfguttmanbest, mcCols, newRubricQues)\n",
    "    dfguttmanbest['Rubric Score'] = dfguttmanbest.apply(lambda row: sum(row[ques] * thisrubricW[ques] / thisrubricDenom[ques] for ques in rubricQues), axis=1)/sum(thisrubricW.values())\n",
    "    dfguttmanbest['Rubric Score'] = dfguttmanbest['Rubric Score'].round(2)\n",
    "    dfguttmanbest['Total'] = 0.7*dfguttmanbest['MC Total'] + 0.3*dfguttmanbest['Rubric Score']\n",
    "    dfguttmanbest = dfguttmanbest.sort_values(by='Total', ascending=False)\n",
    "    dfguttmanbest['Total'] = dfguttmanbest['Total'].round(2)*100\n",
    "    dfguttmanbest['Total CE Penalty 20%'] = dfguttmanbest['Total'] * dfguttmanbest[colCE].apply(lambda x: 0.8 if x == 'Yes' else 1.0)\n",
    "    dfguttmanbest['Total CE Penalty 20%'] = dfguttmanbest['Total CE Penalty 20%'].round(2)\n",
    "    dfguttmanbest.sort_values(by=colId, inplace=True)\n",
    "\n",
    "    lowes = dfguttmanbest#[dfguttmanbest['ES'] == 1]\n",
    "    lowes['Station'] = station\n",
    "    lowes = lowes[['Station', colId, 'Total CE Penalty 20%', 'ES']]\n",
    "    dflowes = pd.concat([dflowes, lowes])    \n",
    "    # display(dfguttman.tail())\n",
    "\n",
    "    # saveDf(dfguttman, f'{folder}/{file} processed.xlsx', sheet_name=station, numColsToColor=len(mcCols) + len(newRubricQues))\n",
    "    # saveDf(dfguttmanbest, f'{folder}/BOH2 OSCE best.xlsx', sheet_name=f'{station}', numColsToColor=len(mcCols) + len(newRubricQues))\n",
    "    # break\n",
    "# pivot the dflowes\n",
    "corr = dflowes['ES'].corr(dflowes['Total CE Penalty 20%'])\n",
    "plt.scatter(dflowes['ES'], dflowes['Total CE Penalty 20%'])\n",
    "plt.xlabel('ES')\n",
    "plt.ylabel('Total CE Penalty 20%')\n",
    "plt.title(f'Correlation: {corr}')\n",
    "plt.show()\n",
    "print(corr)\n",
    "dflowes = dflowes.pivot(index=colId, columns='Station', values='Total CE Penalty 20%').reset_index()\n",
    "# dflowes.to_excel(f'{folder}/BOH2 OSCE ES.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp\n",
    "elements = []\n",
    "elements.append(Paragraph('1536455 (Xiao Yang)', headingStyle))\n",
    "elements.append(Spacer(1, 32))\n",
    "workbookpath = 'DDS1\\DDS1+Periodontics+Sim+Reassessment_November+25,+2024_15.18\\DDS1 Periodontics Sim Reassessment_November 25, 2024_15.18.xlsx'\n",
    "df0 = pd.read_excel(workbookpath, sheet_name='Sheet0')\n",
    "df1 = pd.read_excel(workbookpath, sheet_name='Sheet1')\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df1 = df1.T\n",
    "df1.replace({'Not observed or not recorded': 'NA'}, inplace=True)\n",
    "df1.reset_index(inplace=True)\n",
    "df1.columns = ['Question', 'Full Text', 'Abella Huynh', 'Clare McNally']\n",
    "df1.drop(0, inplace=True)\n",
    "df1['Full Text'].loc[1:52] = df1['Full Text'].loc[1:52].apply(lambda x: (x.split('Marking Checklist')[0].split('debridement ')[-1]).upper() + ':' + x.split(' - ')[-1])\n",
    "df1mc = df1.loc[1:52]\n",
    "df1misc = df1.loc[53:56]\n",
    "df1rubric = df1.loc[57:58]\n",
    "df1rubric = df1rubric.drop('Full Text', axis=1)\n",
    "display(df1rubric)\n",
    "tablemc = createTable(df1mc, 'MC Questions', [1, 3, 1, 1], 0.9, [1], tableTextStyle, cellHighlight=True)\n",
    "\n",
    "rubricTable = createTable(df1rubric, 'Rubric Scores', [2.2, 6, 6], 0.9, [1,2])\n",
    "elements.append(rubricTable)\n",
    "elements.append(Spacer(1, 32))\n",
    "\n",
    "df1misc.drop('Full Text', axis=1, inplace=True)\n",
    "tablemisc = createTable(df1misc, 'Miscellaneous Questions', [1, 3, 3], 0.9, [0, 1, 2], tableTextStyleSmall, cellHighlight=True) \n",
    "elements.append(tablemisc)\n",
    "elements.append(tablemc)\n",
    "elements.append(Spacer(1, 32))\n",
    "\n",
    "\n",
    "doc = SimpleDocTemplate(f'{folder}/1536455 (Xiao Yang).pdf', pagesize = pageSize, leftMargin=leftMargin, rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "doc.build(elements)\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH2\\OSCE\\BOH2 OSCE best.xlsx'\n",
    "workbookpath2 = 'BOH2\\OSCE\\All OSCE.xlsx'\n",
    "savefolder = 'BOH2\\OSCE\\Individual Reports'\n",
    "workbook, folder, file = loadWorkbook(workbookpath)\n",
    "sheet1 = workbook.sheetnames[0]\n",
    "df = loadDfFromSheet(workbook, sheetName=sheet1)\n",
    "studentIds = df[colId].unique().tolist()\n",
    "\n",
    "rubricRefDf = pd.read_excel('data/Rubric Reference Table.xlsx')\n",
    "rubricFullNames = {'PS': 'Professionalism', 'TS': 'Time Management', 'ES': 'Entrustment', 'CS': 'Communication'}\n",
    "\n",
    "rubricQues = [q for q in variableUtils.rubricQues if q in df.columns]\n",
    "studentIds = [id for id in studentIds if not pd.isnull(id)]\n",
    "studentIds = [int(id) for id in studentIds] # convert to int\n",
    "idnamedict = {id: f'{df[df[colId] == id][colNameG].iloc[0]} {df[df[colId] == id][colNameF].iloc[0]}' for id in studentIds}\n",
    "dfDict = {}\n",
    "for sheet in workbook.sheetnames:\n",
    "    if not re.match(r'Station \\d+', sheet):\n",
    "        continue\n",
    "    dfDict[sheet] = loadDfFromSheet(workbook, sheetName=sheet)\n",
    "\n",
    "\n",
    "os.makedirs(savefolder, exist_ok=True)\n",
    "workbook2, folder2, file2 = loadWorkbook(workbookpath2)\n",
    "fullnameDict = {}\n",
    "for sheet in workbook2.sheetnames:\n",
    "    if not re.match(r'Station \\d+', sheet):\n",
    "        continue\n",
    "    df = loadDfFromSheet(workbook2, sheetName=sheet)\n",
    "    stationcols = [col for col in df.columns if 'Station' in col]\n",
    "    print(len(stationcols), stationcols)\n",
    "    fullname = {f'MC{col.split(\"_\")[-1]}': df[col].iloc[0].split(' additional comments')[-1] for col in df.columns if sheet in col}\n",
    "    fullname = {key: value.strip() for key, value in fullname.items()}\n",
    "    # extract valid characters from the fullname\n",
    "    fullname = {key: re.sub(r'[^a-zA-Z0-9 ]', '', value) for key, value in fullname.items()}\n",
    "    print(len(fullname), fullname)\n",
    "    fullnameDict[sheet] = fullname\n",
    "for id in studentIds:\n",
    "    elements = []\n",
    "    elements.append(Paragraph(f'{idnamedict[id]} ({id})', heading2Style))\n",
    "    elements.append(Spacer(1, 32))\n",
    "    for station, df in dfDict.items():\n",
    "        if id in df[colId].values:\n",
    "            print(id, station)\n",
    "            thisdf = df[df[colId] == id]\n",
    "            score = round(thisdf['Total CE Penalty 20%'].iloc[0],2)\n",
    "            if score < 50:\n",
    "                status = 'Fail'\n",
    "            else:\n",
    "                status = 'Pass'\n",
    "            thisdf = thisdf.T\n",
    "            mcCols = [col for col in thisdf.index if 'MC' in col and 'Total' not in col]\n",
    "            thisdf = thisdf.loc[mcCols]\n",
    "            thisdf.reset_index(inplace=True)    \n",
    "            thisdf.columns = ['Question', 'Score']\n",
    "            # display(thisdf)\n",
    "            thisdf['Full Text'] = thisdf['Question'].apply(lambda x: fullnameDict[station][x])\n",
    "            # sort based on MC number MC\\d+\n",
    "            thisdf.sort_values(by='Question', inplace=True, key=lambda x: x.str.extract(r'MC(\\d+)').astype(int).squeeze())  \n",
    "            thisdf['Score'] = thisdf['Score'].replace({1: 'Yes', 0: 'No'})\n",
    "            thisdf = thisdf[['Question', 'Full Text', 'Score']]\n",
    "            # thisdf = thisdf.sort_index(key=lambda x: x.str.extract(r'MC(\\d+)').astype(int))\n",
    "            display(thisdf)\n",
    "            # create rubric table\n",
    "            rubricDf = pd.DataFrame(columns = ['Rubric Question', 'Score', 'Description'])\n",
    "            for q in rubricQues: \n",
    "                scoreq = df[df[colId] == id][q].values[0]\n",
    "                # score = re.findall(r'Lvl (\\d+)', score)[0]\n",
    "                scoreq = int(scoreq)\n",
    "                fulltext = rubricRefDf[rubricRefDf['Score'] == scoreq][rubricFullNames[q]].iloc[0]\n",
    "                rubricDf = pd.concat([rubricDf, pd.DataFrame([[rubricFullNames[q], scoreq, fulltext]], columns = rubricDf.columns)])\n",
    "            rubricTable = createTable(rubricDf, 'Rubric Scores', [2, 1, 6], 0.9, [2], bottomPadding=7, topPadding=7)\n",
    "            elements.append(Paragraph(f'{station}', subheadingStyle))\n",
    "            elements.append(Spacer(1, 15))\n",
    "\n",
    "            elements.append(rubricTable)\n",
    "            elements.append(Spacer(1, 12))\n",
    "            # create a table\n",
    "            mcTable = createTable(thisdf, f'MC Scores', [1, 8, 1], 0.9, [1], tableTextStyleSmall, cellHighlight=True, bottomPadding=7, topPadding=7)\n",
    "            elements.append(mcTable)\n",
    "            elements.append(Spacer(1, 6))\n",
    "            elements.append(Paragraph(f'Station Score: {score}   ||    Station result: {status}', subsubheadingStyle))\n",
    "            elements.append(Spacer(1, 15))\n",
    "            # add feedback\n",
    "            feedback = df[df[colId] == id]['Feedback'].iloc[0]\n",
    "            elements.append(Paragraph('Feedback', subsubheadingStyle))\n",
    "            elements.append(Paragraph(feedback, tableTextStyleLarge))\n",
    "            elements.append(PageBreak())\n",
    "            # elements.append(Spacer(1, 15))\n",
    "        \n",
    "    doc = SimpleDocTemplate(f'{savefolder}/{id} ({idnamedict[id]}).pdf', pagesize = pageSize, leftMargin=leftMargin,\n",
    "                    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    doc.build(elements)\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'BOH1\\OSCE\\BOH1 Practice OSCE 2024_October 2, 2024_18 best.xlsx'\n",
    "folder, filename, ext = getFolderandFileName(filepath)\n",
    "df = pd.read_excel(filepath)\n",
    "df[colId] = df[colId].astype('Int64')\n",
    "studentIds = df[colId].unique()\n",
    "rubricQues = variableUtils.rubricQues.copy()\n",
    "rubricQues.remove('TS')\n",
    "nameDict = {id: df[df[colId] == id][colNameG].iloc[0] + ' ' + df[df[colId] == id][colNameF].iloc[0] for id in studentIds}\n",
    "# display(df[colId].value_counts())\n",
    "\n",
    "station1Cols = [col for col in df.columns if 'Station 1' in col]\n",
    "station2Cols = [col for col in df.columns if 'Station 2' in col]\n",
    "station3Cols = [col for col in df.columns if 'Station 3' in col]\n",
    "stationColsDict = {'Station 1': station1Cols, 'Station 2': station2Cols, 'Station 3': station3Cols}\n",
    "print(station1Cols, station2Cols, station3Cols)\n",
    "# for each student merge the rows of the 3 stations\n",
    "aggFunc = {col: 'first' for col in df.columns}\n",
    "aggFunc.pop(colId)\n",
    "aggFunc.update({col: 'max' for col in station1Cols + station2Cols + station3Cols})\n",
    "aggFunc.update({col: 'max' for col in rubricQues})\n",
    "aggFunc.update({'StationScore': 'sum'})\n",
    "aggFunc.update({'Rating_1': 'mean'})\n",
    "\n",
    "def examineragg(list_):\n",
    "    newlist = []\n",
    "    for item in list_:\n",
    "        supervisor = list(set(item.split(', ')))[0]\n",
    "        newlist.append(supervisor)\n",
    "    return ', '.join(newlist)\n",
    "aggFunc.update({'Examiner': lambda x: examineragg(x)})\n",
    "dfAgg = df.groupby(colId).agg(aggFunc).reset_index()\n",
    "# dfAgg.to_excel(f'{folder}/{filename} Aggregate.xlsx', index=False)\n",
    "dfS1 = df[df['Station'] == 'Station 1']\n",
    "dfS2 = df[df['Station'] == 'Station 2']\n",
    "dfS3 = df[df['Station'] == 'Station 3']\n",
    "dfDict = {'Station 1': dfS1, 'Station 2': dfS2, 'Station 3': dfS3}\n",
    "display(dfAgg.head())\n",
    "\n",
    "# get the MC full text items\n",
    "xsheet = pd.read_csv('BOH1\\OSCE\\BOH1 Practice OSCE 2024_October 2, 2024_18.csv', encoding='ISO-8859-1')\n",
    "colfulltextDictDf = pd.DataFrame(columns=['Station', 'Question', 'Full Text'])\n",
    "for i, col in enumerate(station1Cols):\n",
    "    text = xsheet[col][0].split('comments - ')[-1]\n",
    "    print(text)\n",
    "    colfulltextDictDf = pd.concat([colfulltextDictDf, pd.DataFrame({'Station': ['Station 1'], 'Question': f'MC {i+1}', 'Full Text': [text]})])\n",
    "\n",
    "for i, col in enumerate(station2Cols):\n",
    "    text = xsheet[col][0].split('comments - ')[-1]\n",
    "    print(text)\n",
    "    colfulltextDictDf = pd.concat([colfulltextDictDf, pd.DataFrame({'Station': ['Station 2'], 'Question': f'MC {i+1}', 'Full Text': [text]})])\n",
    "\n",
    "for i, col in enumerate(station3Cols):\n",
    "    text = xsheet[col][0].split('comments - ')[-1]\n",
    "    print(text)\n",
    "    colfulltextDictDf = pd.concat([colfulltextDictDf, pd.DataFrame({'Station': ['Station 3'], 'Question': f'MC {i+1}', 'Full Text': [text]})])\n",
    "\n",
    "display(colfulltextDictDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertToGuttman(dfAgg, colId, colDate, rubricQues, filepath, 'All', None, station1Cols + station2Cols + station3Cols, ['Comments'])\n",
    "convertToGuttman(df[df['Station'] == 'Station 1'], colId, colDate, rubricQues, filepath, 'Station 1', None, station1Cols, ['Comments'])\n",
    "convertToGuttman(df[df['Station'] == 'Station 2'], colId, colDate, rubricQues, filepath, 'Station 2', None, station2Cols, ['Comments'])\n",
    "convertToGuttman(df[df['Station'] == 'Station 3'], colId, colDate, rubricQues, filepath, 'Station 3', None, station3Cols, ['Comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter, landscape, A4, A3\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, PageBreak, Paragraph, Spacer, Image\n",
    "from reportlab.lib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reportlab.platypus import Paragraph, Spacer, KeepTogether, KeepInFrame\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pageSize = ( 11.69 * inch, 8.27 * 2 * inch) # page size\n",
    "print(pageSize)\n",
    "figSize = (pageSize[0] / 100, pageSize[1] / 100)\n",
    "\n",
    "# Define the margins\n",
    "leftMargin = 1 * inch\n",
    "rightMargin = 1 * inch\n",
    "topMargin = 1 * inch\n",
    "bottomMargin = 0 * inch\n",
    "\n",
    "# Define the styles for the headings\n",
    "styles = getSampleStyleSheet()\n",
    "styles.add(ParagraphStyle(name='Center', alignment=1))  # Center alignment\n",
    "headingStyle = ParagraphStyle('Heading1', parent=styles['Heading1'], fontSize=32, alignment=1)  # Centered\n",
    "heading2Style = ParagraphStyle('Heading2', parent=styles['Heading2'], fontSize=28, alignment=1)  # Centered\n",
    "subheadingStyle = ParagraphStyle('Heading2', parent=styles['Heading2'], fontSize=24, alignment=1)  # Centered\n",
    "subsubheadingStyle = ParagraphStyle('Heading3', parent=styles['Heading3'], fontSize=20, alignment=1)  # Centered\n",
    "normalLargeStyleLeft = ParagraphStyle('NormalLarge', parent=styles['Normal'], fontSize=18, alignment=0)  # Left aligned\n",
    "normalLargeStyleCenter = ParagraphStyle('NormalLarge2', parent=styles['Normal'], fontSize=18, alignment=1)  # Center aligned\n",
    "tableTextStyle = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=13, alignment=1)\n",
    "tableTextStyleSmall= ParagraphStyle('SmallFont', parent=styles['Normal'], fontSize=11, alignment=1)\n",
    "\n",
    "Checklistcolors = {'Yes': 'blue', 'No': 'orange', 'Not Reviewed': 'lightgrey'}\n",
    "# Set the colorblind-friendly palette\n",
    "sns.set_palette(\"colorblind\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of each Yes, No, NA, Not Finished for each station and question\n",
    "# Station X\n",
    "def getStationCounts(dfS, stationCols, station):\n",
    "    countsDf = pd.DataFrame(columns=['Yes', 'No'], index= stationCols)\n",
    "    # vertical sum of 1 for each Yes, 0 for each No\n",
    "    for col in stationCols:\n",
    "        countsDf.loc[col, 'Yes'] = (dfS[col] == 1).sum() + (dfS[col] == '1').sum()\n",
    "        countsDf.loc[col, 'No'] = (dfS[col] == 0).sum() + (dfS[col] == '0').sum()\n",
    "    display(countsDf)\n",
    "    return countsDf\n",
    "\n",
    "# Plot counts\n",
    "def plotCounts(countsDf, station):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "    countsDf.plot(kind='bar', ax=ax, stacked=True)\n",
    "    xticklabels = [re.sub(r'Station 1_', 'MC ', col) for col in countsDf.index]\n",
    "    ax.set_xticklabels(xticklabels, rotation=0)\n",
    "    plt.title(f'Marking Checklist Yes/No Counts')\n",
    "    return fig\n",
    "\n",
    "def createPlotImage(fig):\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        return buf\n",
    "\n",
    "def addPlotImage(fig, ratio = None):\n",
    "        plotImage = createPlotImage(fig)\n",
    "        image = Image(plotImage)\n",
    "        # print(image.drawWidth, image.drawHeight)\n",
    "        \n",
    "        # Resize image to fit within margins\n",
    "        max_height = pageSize[1] - topMargin - bottomMargin  # Max height for Page\n",
    "        max_width = pageSize[0] - leftMargin - rightMargin  # Max width for Page\n",
    "        if ratio is not None:\n",
    "            max_width = max_width * ratio\n",
    "            max_height = max_height * ratio\n",
    "        aspect_ratio = min(max_width / image.drawWidth, max_height / image.drawHeight)\n",
    "        image.drawWidth *= aspect_ratio\n",
    "        image.drawHeight *= aspect_ratio\n",
    "        plt.close(fig)\n",
    "        return image\n",
    "\n",
    "def addMCReferenceTable(mcRefdf, header):\n",
    "\n",
    "    largeFontStyle = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=13, alignment=0)\n",
    "\n",
    "    # Create a table with MC and Full Text columns\n",
    "    data = [mcRefdf.columns.to_list()] + mcRefdf.values.tolist()\n",
    "    for i in range(1, len(data)):\n",
    "        data[i][1] = Paragraph(data[i][1], largeFontStyle)\n",
    "        data[i][0] = Paragraph(data[i][0], largeFontStyle)\n",
    "    table = Table(data, colWidths=[1.5 * inch, 9 * inch])\n",
    "\n",
    "    # Set the style for the table text as large font\n",
    "    \n",
    "\n",
    "    table_style = TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#236DB0')),  # Header row\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "        ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),  # Increase bottom padding\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 12),  # Increase top padding\n",
    "    ])\n",
    "    table.setStyle(table_style)\n",
    "    mergedElement = KeepTogether([header, Spacer(1, 12), table])\n",
    "    return mergedElement\n",
    "\n",
    "def addStationInfo(station, elements):\n",
    "    heading = Paragraph(f'{station}', headingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 32))\n",
    "    countsDf = getStationCounts(dfDict[station], stationColsDict[station], station)\n",
    "    fig = plotCounts(countsDf, station)\n",
    "    image = addPlotImage(fig)\n",
    "    elements.append(image)\n",
    "    mcreftable = addMCReferenceTable(colfulltextDictDf[colfulltextDictDf['Station']==station][['Question', 'Full Text']], Paragraph('MC Reference', subheadingStyle))\n",
    "    elements.append(mcreftable)\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "rubricFullText = {'PS': 'Professionalism', 'CS': 'Communication', 'ES': 'Entrustment'}\n",
    "# Function to add pie chart for each rubric question\n",
    "def addPie(station, elements):\n",
    "    heading = Paragraph(f'Rubric Grades', subheadingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 32))\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "    for i, col in enumerate(rubricQues):\n",
    "        plotdata = dfDict[station][col].value_counts()\n",
    "        total = plotdata.sum()\n",
    "        dfDict[station][col].value_counts().plot(kind='pie', ax=ax[i//2, i%2], autopct= lambda x: autopct(x, total), \n",
    "                colors=sns.color_palette(), startangle=90)\n",
    "        ax[i//2, i%2].set_title(rubricFullText[col])\n",
    "    # remove the last subplot\n",
    "    fig.delaxes(ax[1, 1])\n",
    "    image = addPlotImage(fig)\n",
    "    elements.append(image)\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "def addCorrelationMatrix(station, elements):\n",
    "    dfS = dfDict[station].copy()\n",
    "    dfS.dropna(subset=rubricQues, inplace=True)\n",
    "    \n",
    "     # Get the correlation matrix between the rubric questions and the station score as well\n",
    "    dfS.rename(columns={'StationScore': 'Station Score', 'PS': 'Professionalism', 'CS': 'Communication', 'ES': 'Entrustment'}, inplace=True)\n",
    "    # print(dfS.columns)\n",
    "    # dfS.rename(columns={'PS': 'Professionalism'}, inplace=True)\n",
    "    corr = dfS[[rubricFullText[q] for q in rubricQues] + ['Station Score']].corr()\n",
    "    # display(corr)\n",
    "    # heatmap of the correlation matrix\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "    # display numerical values in the heatmap\n",
    "    sns.set(font_scale=1)\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax, annot_kws={\"size\": 22})\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=15)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=15)\n",
    "    ax.set_title(f'Correlation Matrix for {station}', fontsize=25)\n",
    "    \n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.ax.tick_params(labelsize=14)  # Adjust font size of the color bar\n",
    "\n",
    "    # plt.title(f'Correlation Matrix for {station}')\n",
    "    image = addPlotImage(fig, 0.5)\n",
    "    if station == 'Station 1':\n",
    "        para = Paragraph(\"Correlation matrix shows high correlation between rubrics and the station score, which shouldn't happen\\\n",
    "                          as they all measure different aspects of a student's performance.\", tableTextStyle)\n",
    "    elif station == 'Station 2':\n",
    "         para = Paragraph(\"Correlation matrix shows low to no correlation between rubrics and the station score, which is what we expect\\\n",
    "                          as they all measure different aspects of a student's performance.\", tableTextStyle)\n",
    "    elif station == 'Station 3':\n",
    "        para = Paragraph(\"Correlation matrix shows high correlation between rubrics and the station score, which shouldn't happen\\\n",
    "                          as they all measure different aspects of a student's performance. Since, in professionalism all students scored\\\n",
    "                         maximum scores it won't be considered for correlation\", tableTextStyle)\n",
    "    elementsTogether = KeepTogether([image, Spacer(1, 12), para])\n",
    "    elements.append(elementsTogether)\n",
    "    elements.append(PageBreak())\n",
    "    display(corr) \n",
    "\n",
    "elements = []\n",
    "\n",
    "\n",
    "\n",
    "for station in ['Station 1', 'Station 2', 'Station 3']:\n",
    "    addStationInfo(station, elements)\n",
    "    addPie(station, elements)\n",
    "    addCorrelationMatrix(station, elements)\n",
    "\n",
    "doc = SimpleDocTemplate(f'{folder}/{filename} Report.pdf', pagesize=pageSize, leftMargin=leftMargin, rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "doc.build(elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Wise Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultDf = pd.read_excel('BOH1\\OSCE\\Results.xlsx', sheet_name='Information PF', header = [1, 2])\n",
    "resultDf2 = pd.read_excel('BOH1\\OSCE\\Results.xlsx', sheet_name='Comments for all students', header = [0])\n",
    "# create a dict with id as key and the P/F col as value\n",
    "# Create an empty dictionary to store the data\n",
    "data = {}\n",
    "outcomeDict = {}\n",
    "# Loop through the columns for each station\n",
    "for station in ['Station 1', 'Station 2', 'Station 3']:\n",
    "    for i, row in resultDf[station].iterrows():\n",
    "        studentId = row[colId]\n",
    "        title = resultDf2[resultDf2['Station']==station]['Title'].iloc[0]\n",
    "        generalDescrip = resultDf2[resultDf2['Station']==station]['General description'].iloc[0]\n",
    "        passComment = resultDf2[resultDf2['Station']==station]['Students who passed'].iloc[0]\n",
    "        failComment = resultDf2[resultDf2['Station']==station]['Students who failed'].iloc[0]\n",
    "        cols = ['Station', 'Title', 'General Description', 'Students who passed', 'Students who failed',  'Your Outcome']\n",
    "        if studentId not in outcomeDict.keys():\n",
    "            outcomeDict[studentId] = pd.DataFrame(columns=cols)\n",
    "        outcomeDict[studentId] = pd.concat([outcomeDict[studentId], pd.DataFrame([[station, title, generalDescrip, passComment, failComment, row['P/F']]], \n",
    "                                                                                 columns=cols)])\n",
    "    # Store them in the dictionary\n",
    "    data[station] = {resultDf[station, colId][id]: resultDf[station, 'P/F'][id] for id in resultDf.index}\n",
    "\n",
    "print(data)\n",
    "print(outcomeDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefolder = f'{folder}/Student Reports'\n",
    "os.makedirs(savefolder, exist_ok=True)\n",
    "rubricRefDf = pd.read_excel('Rubric Reference Table.xlsx')\n",
    "rubricFullText = {'PS': 'Professionalism', 'TS': 'Time Management', 'ES': 'Entrustment', 'CS': 'Communication'}\n",
    "def createPage(id, station):\n",
    "    elements = []\n",
    "    dfS = dfDict[station]\n",
    "    dfS = dfS[dfS[colId] == id]\n",
    "    if dfS.empty:\n",
    "        return elements\n",
    "    display(dfS)\n",
    "\n",
    "\n",
    "    # Add the station name\n",
    "    stationheading = Paragraph(f'{station}', heading2Style)\n",
    "    elements.append(stationheading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "    # Add the rubric scores\n",
    "    rubricDf = pd.DataFrame(columns = ['Rubric Question', 'Score', 'Description'])\n",
    "    for q in rubricQues:\n",
    "        score = int(dfS[q].iloc[0])\n",
    "        fulltext = rubricRefDf[rubricRefDf['Score'] == score][rubricFullText[q]].iloc[0]\n",
    "        rubricDf = pd.concat([rubricDf, pd.DataFrame([[rubricFullText[q], score, fulltext]], columns = rubricDf.columns)])\n",
    "    rubricTable = createTable(rubricDf, 'Rubric Scores', [2, 1, 6], 0.9, [2])\n",
    "    elements.append(rubricTable)\n",
    "    elements.append(Spacer(1, 24))\n",
    "\n",
    "    # Add comments\n",
    "    comments = dfS['Comments'].iloc[0]\n",
    "    comments = \" \" if comments is None or pd.isna(comments) else comments\n",
    "    if comments != '' and comments is not None:\n",
    "        commentHeading = Paragraph('Supervisor Comments', subsubheadingStyle)\n",
    "        elements.append(commentHeading)\n",
    "        elements.append(Spacer(1, 12))\n",
    "        # remove weird characters\n",
    "        comments = re.sub(r'[^\\na-zA-Z0-9., ]', '', comments)\n",
    "        comment = Paragraph(comments, tableTextStyle)\n",
    "        elements.append(comment)\n",
    "    elements.append(Spacer(1, 24))\n",
    "\n",
    "    # Add MC values table\n",
    "    mcDf = pd.DataFrame(columns = ['Question', 'Full Text', 'Marking'])\n",
    "    stationCols = stationColsDict[station]\n",
    "    for i, col in enumerate(stationCols):\n",
    "        mcText = colfulltextDictDf[colfulltextDictDf['Station'] == station]['Full Text'].iloc[i]\n",
    "        score = dfS[col].iloc[0]\n",
    "        mcDf = pd.concat([mcDf, pd.DataFrame([[f'MC {i+1}', mcText, score]], columns = mcDf.columns)])\n",
    "    mcDf.replace({1: 'Yes', 0: 'No'}, inplace=True)\n",
    "    mcTable = createTable(mcDf, 'MC Questions', [1, 3, 1], 0.9, [1], tableTextStyle, cellHighlight=True)\n",
    "    elements.append(mcTable)\n",
    "    elements.append(PageBreak())\n",
    "    return elements\n",
    "\n",
    "for id in studentIds:\n",
    "    elements = []\n",
    "    # Add the student ID and name\n",
    "    idheading = Paragraph(f'{id} ({nameDict[id].strip()})', headingStyle)\n",
    "    elements.append(KeepTogether([idheading, Spacer(1, 22)]))\n",
    "    # Add all outcome\n",
    "    outcomeDf = outcomeDict[id]\n",
    "    outcomeDf.replace({'P': 'Pass', 'F': 'Fail'}, inplace=True)\n",
    "    #['Station', 'Title', 'General Description', 'Outcome', 'Students who passed', 'Students who failed']\n",
    "    # transpose the df and Station as columns\n",
    "    outcomeDf = outcomeDf.T\n",
    "    \n",
    "    outcomeDf.drop('Station', inplace=True)\n",
    "    outcomeDf.reset_index(inplace=True) \n",
    "    outcomeDf.columns = ['Station', 'Station 1', 'Station 2', 'Station 3']\n",
    "    # outcomeDf.columns = ['Station 1', 'Station 2', 'Station 3']\n",
    "    display(outcomeDf)\n",
    "    outcomeTable = createTable(outcomeDf, 'Outcome', [3, 4, 4, 4], 0.9, [1, 2, 3], tableTextStyleSmall)\n",
    "    elements.append(outcomeTable)\n",
    "    # elements.append(PageBreak())\n",
    "    elements.append(Spacer(1, 12))\n",
    "    # Add a pie chart of MC values for each station\n",
    "    emptyPlot =[]\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(figSize[0], figSize[1]))\n",
    "    for i, station in enumerate(['Station 1', 'Station 2', 'Station 3']):\n",
    "        dfS = dfDict[station]\n",
    "        dfS = dfS[dfS[colId] == id]\n",
    "        if dfS.empty:\n",
    "            emptyPlot.append(i)\n",
    "            # Write a message that the student did not attend the station\n",
    "            ax.flatten()[i].text(0.5, 0.5, 'Student did not complete this station', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black')\n",
    "            ax.flatten()[i].axis('off')\n",
    "            ax.flatten()[i].set_title(station)   \n",
    "            continue\n",
    "        dfS = dfS[stationColsDict[station]]\n",
    "        # display(dfS)\n",
    "        # transpose the df\n",
    "        dfS = dfS.T\n",
    "        dfS.columns = ['Marking']\n",
    "        dfS.replace({1: 'Yes', 0: 'No'}, inplace=True)\n",
    "        valueCounts = dfS['Marking'].value_counts()\n",
    "        plotPie(ax.flatten()[i], valueCounts, station)\n",
    "    # remove the last subplot\n",
    "    fig.delaxes(ax[1, 1])\n",
    "    # remove empty plots\n",
    "    # for i in emptyPlot:\n",
    "    #     fig.delaxes(ax.flatten()[i])\n",
    "    # reduce vertical space between subplots\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    image = addPlotImage(fig, 0.9)\n",
    "    imageTitle = Paragraph('Marking Checklist Counts', subsubheadingStyle)\n",
    "    elements.append(KeepTogether([imageTitle, Spacer(1, 12), image]))\n",
    "    # elements.append(image)\n",
    "    elements.append(PageBreak()) \n",
    "    elements += createPage(id, 'Station 1')\n",
    "    elements += createPage(id, 'Station 2')\n",
    "    elements += createPage(id, 'Station 3')\n",
    "    doc = SimpleDocTemplate(f'{savefolder}/{id} ({nameDict[id].strip()}).pdf', pagesize=pageSize, leftMargin=leftMargin, rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    doc.build(elements)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'BOH1\\OSCE\\BOH1 Practice OSCE 2024_October 2, 2024_18 best.xlsx'\n",
    "folder, filename, ext = getFolderandFileName(filepath)\n",
    "df = pd.read_excel(filepath, encoding='ISO-8859-1')\n",
    "df.drop(0, axis=0, inplace=True)\n",
    "df[colId] = df[colId].astype('Int64')\n",
    "df = removeFakeNames(df, colNameG, colNameF)\n",
    "rubricQues = variableUtils.rubricQues.copy()\n",
    "rubricQues.remove('TS')\n",
    "\n",
    "# convert rubric scale\n",
    "df = convertRubricScale(df, rubricQues)\n",
    "display(df.head())\n",
    "display(df[colId].value_counts())\n",
    "\n",
    "station1Cols = [col for col in df.columns if 'Station 1' in col]\n",
    "station2Cols = [col for col in df.columns if 'Station 2' in col]\n",
    "station3Cols = [col for col in df.columns if 'Station 3' in col]\n",
    "print(station1Cols, station2Cols, station3Cols)\n",
    "# overall ration column\n",
    "colOverall = 'Rating_1'\n",
    "colStation = 'Station'\n",
    "colSupervisor = 'Examiner'\n",
    "# display(df[colOverall].value_counts())\n",
    "df[colOverall] = df[colOverall].str.extract(r'(\\d+)').astype('Int64')\n",
    "display(df.describe())\n",
    "# display()\n",
    "\n",
    "# replace the Yes/No with 1/0 in station 1, 2, 3\n",
    "df[station1Cols] = df[station1Cols].replace({'Yes': 1, 'No': 0})\n",
    "df[station2Cols] = df[station2Cols].replace({'Yes': 1, 'No': 0})\n",
    "df[station3Cols] = df[station3Cols].replace({'Yes': 1, 'No': 0})\n",
    "# replace Completed/Not Completed with 1/0 in station 1, 2, 3\n",
    "df[station1Cols] = df[station1Cols].replace({'Completed': 1, 'Not completed': 0})\n",
    "df[station2Cols] = df[station2Cols].replace({'Completed': 1, 'Not completed': 0})\n",
    "df[station3Cols] = df[station3Cols].replace({'Completed': 1, 'Not completed': 0})\n",
    "# display(df.head())\n",
    "\n",
    "# # First merge rows based on colId and Station\n",
    "# aggFunc = {col: 'first' for col in df.columns if col not in station1Cols + station2Cols + station3Cols}\n",
    "# aggFunc.update({col: 'max' for col in rubricQues})\n",
    "# aggFunc.update({colOverall: 'max'})\n",
    "# aggFunc.update({col: custom_agg for col in station1Cols + station2Cols + station3Cols})\n",
    "# aggFunc.update({colSupervisor: lambda x: ', '.join(x)})\n",
    "# df = df.groupby([colId, colStation]).agg(aggFunc).reset_index(drop=True)\n",
    "# display(df.head())\n",
    "\n",
    "# # create a station score column\n",
    "# df['StationScore'] = df[station1Cols].sum(axis=1) + df[station2Cols].sum(axis=1) + df[station3Cols].sum(axis=1)\n",
    "# df.to_excel(f'{folder}\\\\{filename} best.xlsx', index=False)\n",
    "# display(df['StationScore'].value_counts())\n",
    "# # Create a pivot table with colId as key, Station as columns and values as the sum of the station score\n",
    "# # Pivot for both 'StationScore' and 'colOverall'\n",
    "# dfPivot = df.pivot_table(index=colId, \n",
    "#                          columns='Station', \n",
    "#                          values=['StationScore', colOverall], \n",
    "#                          aggfunc='max').reset_index()\n",
    "\n",
    "# # Flatten the multi-level column index\n",
    "# dfPivot.columns = ['_'.join(col).strip() if col[1] else col[0] for col in dfPivot.columns.values]\n",
    "\n",
    "# # Rename columns to make them more readable\n",
    "# dfPivot.rename(columns={\n",
    "#     f'StationScore_Station 1': 'Station1 Score',\n",
    "#     f'StationScore_Station 2': 'Station2 Score',\n",
    "#     f'StationScore_Station 3': 'Station3 Score',\n",
    "#     f'{colOverall}_Station 1': 'Station1 Rating',\n",
    "#     f'{colOverall}_Station 2': 'Station2 Rating',\n",
    "#     f'{colOverall}_Station 3': 'Station3 Rating'\n",
    "# }, inplace=True)\n",
    "\n",
    "# # dfPivot = df.pivot_table(index=colId, columns='Station', values='StationScore', aggfunc='max').reset_index()\n",
    "# dfPivot.to_excel(f'{folder}\\\\{filename}_pivot.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform borderline regression for each station\n",
    "dfPivot = pd.read_excel(f'{folder}\\\\{filename}_pivot.xlsx')\n",
    "print(dfPivot.shape)\n",
    "dfPivot = dfPivot.dropna(subset=['Station1 Score', 'Station2 Score', 'Station3 Score', 'Station1 Rating', 'Station2 Rating', 'Station3 Rating'])\n",
    "print(dfPivot.shape)\n",
    "# Plot the scatter plot for each station\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 15))\n",
    "for i, station in enumerate(['Station1', 'Station2', 'Station3']):\n",
    "    x = dfPivot[f'{station} Rating']\n",
    "    y = dfPivot[f'{station} Score']\n",
    "    ax[i].scatter(x, y)\n",
    "    # ax[i].set_title(f'{station} Score vs Rating')\n",
    "    ax[i].set_xlabel(f'Global Rating')\n",
    "    \n",
    "    ax[i].set_ylabel(f'Score')\n",
    "    ax[i].set_title(f'{station}')\n",
    "    # draw a regression line\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    xline = np.linspace(1, 5, 100)\n",
    "    ax[i].plot(xline, m*xline + b, color='red')\n",
    "    ax[i].set_xticks(range(1, 6))\n",
    "    ax[i].grid(linestyle='--', alpha=0.5)\n",
    "    # ax[i].text(1, 0, f'y = {m:.2f}x + {b:.2f}', fontsize=12, color='red')\n",
    "\n",
    "# increase the space between the plots\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.savefig(f'{folder}\\\\borderline.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\Rachel Data\\CAF v0.1_September 30, 2024_18.49.csv'\n",
    "workbookpath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\Ruby and Samir\\CAF v0.1_October 7, 2024_08.42.csv'\n",
    "# workbookpath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo.xlsx'\n",
    "# savepath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo filtered.xlsx'\n",
    "# savepath = 'BOH3\\CAF+v0.1_September+25,+2024_20.31\\CAF v0.1_September 25, 2024_20.31 filtered.xlsx'\n",
    "savepath = None\n",
    "guttmancreator = CreateGuttman(savepath, workbookpath) \n",
    "# splitDfPath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo split.xlsx'\n",
    "splitDfPath = None\n",
    "guttmancreator.createGuttman(splitDfPath)\n",
    "# guttmancreator.saveSplitDf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDS2 Endo marks based on tooth number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for standardization\n",
    "standard_mapping = {\n",
    "    'premolar': '24', \n",
    "    'incisor': '11',\n",
    "    '24': '24',\n",
    "    '11': '11',\n",
    "    '21': '11',\n",
    "    '25': '24',\n",
    "    '45': '24'\n",
    "}\n",
    "\n",
    "def standardize_tooth_number(value):\n",
    "    print(value)\n",
    "    if value is None:\n",
    "        return None\n",
    "    value = str(value)\n",
    "    value = value.strip().lower()\n",
    "    for key in standard_mapping:\n",
    "        if re.search(key, value):\n",
    "            return standard_mapping[key]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the possible tooth numbers\n",
    "guttmanPath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo guttman.xlsx'\n",
    "guttmanPath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\\\1402039\\CAF v0.1_October 6, 2024_11.29 guttman.xlsx'\n",
    "workbook, folder, filename = loadWorkbook(guttmanPath)\n",
    "toothnumberlist = []\n",
    "requriedCodes = ['416', '415', '417', '418']\n",
    "for sheet in workbook.sheetnames:\n",
    "    code = sheet.split('_')[0]\n",
    "    if code not in requriedCodes:\n",
    "        continue\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    # find the column with Tooth Number in its name\n",
    "    toothNumberCol = None\n",
    "    for col in df.columns:\n",
    "        if 'Tooth Number' in col:\n",
    "            toothNumberCol = col\n",
    "            break\n",
    "    if toothNumberCol is None:\n",
    "        print(f'No tooth number column found in {sheet}')\n",
    "        continue\n",
    "    # get the tooth numbers\n",
    "    # df[toothNumberCol].fillna('', inplace=True)\n",
    "    df['Tooth Number'] = df[toothNumberCol].astype(str)\n",
    "    df['Tooth Number'] = df[toothNumberCol].apply(standardize_tooth_number)\n",
    "    df['Tooth Number'] = df['Tooth Number'].astype(str)\n",
    "    toothnumbers = df['Tooth Number'].unique().tolist()\n",
    "    print(toothnumbers)\n",
    "    toothnumberlist.extend(toothnumbers)\n",
    "    df24= df[df['Tooth Number'] == '24']\n",
    "    df11= df[(df['Tooth Number'] == '11')]\n",
    "    # display(df)\n",
    "    # None values\n",
    "    dfNone = df[~df['Tooth Number'].isin(['24', '11'])]\n",
    "    # dfNone = df[df['Tooth Number']]\n",
    "    print(len(df24), len(df11), len(dfNone))\n",
    "    saveDf(df24, f'{folder}/{filename} teeth standard.xlsx', f'{sheet}_24')\n",
    "    saveDf(df11, f'{folder}/{filename} teeth standard.xlsx', f'{sheet}_11')\n",
    "    if len(dfNone) > 0:\n",
    "        saveDf(dfNone, f'{folder}/{filename} teeth standard.xlsx', f'{sheet}_None')\n",
    "toothnumberlist = list(set(toothnumberlist))\n",
    "print(toothnumberlist)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newGuttman = f'{folder}/{filename} teeth standard.xlsx'\n",
    "workbook, folder, filename2 = loadWorkbook(newGuttman)\n",
    "cols = [colId, 'MC Score', 'Rubric Score', colDate, colCE, colCEReason, colFinished, colClinicType, 'Item', 'Tooth Number', colResponseId]\n",
    "df = pd.DataFrame([], columns=cols)\n",
    "\n",
    "for sheet in workbook.sheetnames:\n",
    "    code = sheet.split('_')[0]\n",
    "    tag = sheet.split('_')[1]\n",
    "    item = code + '_' + tag\n",
    "    df1 = loadDfFromSheet(workbook, sheet)\n",
    "    df1['Item'] = item\n",
    "    # df1 = df1[df1[colFinished] == 1]\n",
    "    dfnew = df1[cols]\n",
    "    df1.drop(columns='Item', inplace=True)\n",
    "    dfnew = dfnew[dfnew[colFinished] == 1]\n",
    "    # remove rows with rubric score 0 and empty MC score\n",
    "    dfnew['MC Score'] = dfnew['MC Score'].replace('', np.nan)\n",
    "    dfnew['MC Score'] = dfnew['MC Score'].astype(float)\n",
    "    dfnew = dfnew[dfnew['MC Score'].notna()]\n",
    "    # remove with  empty colClinicType\n",
    "    dfnew = dfnew[dfnew[colClinicType].notna()]\n",
    "    # Also take only for date 28 of August\n",
    "    # display(dfnew[colDate])\n",
    "    # dfnew = dfnew[dfnew[colDate] == '28/08/2024']\n",
    "    df = pd.concat([df, dfnew])\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # df1 = df1[df1[colDate] == '28/08/2024']\n",
    "    dropCols = [\n",
    "    'ICC_MC1_supervisor',\n",
    "    'ICC_MC2_supervisor',\n",
    "    'RKC_MC1_supervisor',\n",
    "    'CC_MC1_supervisor',\n",
    "    'Cohort',\n",
    "    'Subject',\n",
    "    'Sim or Clinic',\n",
    "    'Sim or Clinic_999_TEXT',\n",
    "    'Patient',\n",
    "    'Complexity',\n",
    "    'Patient Age',\n",
    "    'Role',\n",
    "    'ResponseId',\n",
    "    'Diagnostics',\n",
    "    'OMFS Sim/Clinic',\n",
    "    'General services',\n",
    "    'Rem Pros CLINIC',\n",
    "    'Paeds specific',\n",
    "    'Preventive, Prophylactic and Bleaching Services',\n",
    "    'Periodontics',\n",
    "    'Restorative Services',\n",
    "    'Fixed Prosthodontics',\n",
    "    'MC Total',\n",
    "    'Grand Total',\n",
    "    'Not Filled',\n",
    "    'Total MC items'\n",
    "    ]\n",
    "    df1.drop(columns=dropCols, inplace=True, errors='ignore')\n",
    "    colorCols = getColorColumns(df1, code)\n",
    "    print(colorCols)\n",
    "    numColorCols = len(colorCols)\n",
    "    # create a row with total\n",
    "    df1[colorCols] = df1[colorCols].replace('NA', np.nan).astype(float)\n",
    "    df1.loc['Column Total'] = df1[colorCols].sum(numeric_only=False)\n",
    "    # sort the columns based on the total\n",
    "    df1 = df1.sort_values(by='Column Total', axis=1, ascending=False)\n",
    "    # drop the column total row\n",
    "    # df1.drop(index='Column Total', inplace=True)\n",
    "    df1[colorCols] = df1[colorCols].replace(np.nan, 'NA')\n",
    "    saveDf(df1, f'{folder}/{filename2} 28 Aug.xlsx', sheet, numColorCols)\n",
    "\n",
    "# exit(0)\n",
    "df[colDate] = pd.to_datetime(df[colDate], errors='coerce')\n",
    "df.sort_values(by= [colId, colDate], inplace=True)\n",
    "df[colDate] = df[colDate].dt.strftime('%d-%m-%Y')\n",
    "# display(df[colDate])\n",
    "df.to_excel(f'{folder}/{filename2} marks.xlsx', index=False)\n",
    "\n",
    "# create a pivot table with item as columns and tooth number as values with Student ID as index\n",
    "# create a row with Tooth Number (Date) only date\n",
    "df['Day'] = df[colDate].str.split('-').str[0]\n",
    "df['Tooth Number (Date)'] =  df['Tooth Number'] + ' (' + df['Day'].astype(str) + ')'\n",
    "pivotDf = df.pivot_table(index=[colId], columns='Item', values='Tooth Number', aggfunc= lambda x: ', '.join(x))\n",
    "pivotDf = pivotDf.reset_index()\n",
    "# pivotDf.to_excel(f'{folder}/{filename2} pivot.xlsx', index=False)\n",
    "df.drop(columns=['Day', 'Tooth Number (Date)'], inplace=True)\n",
    "\n",
    "# To fill the None values with an algorithm\n",
    "teethItem = {'11': ['415_SIM ACCESS', '415_SIM WORK LENGTH', '417_SIM CONE FIT', '417_SIM ROOT FLG'],\n",
    "             '24': ['415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG',\n",
    "                    '418_SIM CONE FIT', '418_SIM ROOT FLG']}\n",
    "\n",
    "noneList = []\n",
    "# Fill all the values in 416 and  418 tooth number with 24\n",
    "for i, row in df.iterrows():\n",
    "    if row['Tooth Number'] == 'None':\n",
    "        if row['Item'] in ['416_SIM', '418_SIM CONE FIT', '418_SIM ROOT FLG']:\n",
    "            df.at[i, 'Tooth Number'] = '24'\n",
    "        else:\n",
    "            # find another row with the same student id and item\n",
    "            studentId = row[colId]\n",
    "            item = row['Item']\n",
    "            print(f'\\n----Empty tooth number for {studentId} {item}, finding similar row not self')\n",
    "            # remove the index i\n",
    "            df_ = df.drop(i)\n",
    "            df_ = df_[df_[colId] == studentId]\n",
    "            df2 = df_[(df_[colId] == studentId) & (df_['Item'] == item)]\n",
    "            display(df2)\n",
    "            # find the tooth number\n",
    "            tooth2 = df2['Tooth Number'].values\n",
    "            print(f'Other tooth numbers: {tooth2}')\n",
    "            if len(tooth2) ==0:\n",
    "                print('No other tooth number found')\n",
    "                continue\n",
    "            if len(tooth2) ==1:\n",
    "                toothnumber2 = tooth2[0]\n",
    "            else:\n",
    "                # get the most frequent tooth number\n",
    "                toothnumber2 = tooth2[0]\n",
    "            \n",
    "            # If the other tooth number is None, check MC score and Rubric score if they are the same fill one with 24 and the other with 11\n",
    "            df2['MC Score'] = df2['MC Score'].astype(float)\n",
    "            df2['Rubric Score'] = df2['Rubric Score'].astype(float)\n",
    "            \n",
    "            if toothnumber2 == 'None':\n",
    "                print('Both are None')\n",
    "                noneList.append(int(studentId))\n",
    "                mcScore1 = row['MC Score']\n",
    "                rubricScore1 = row['Rubric Score']\n",
    "                mcScore2 = df2['MC Score'].values[0]\n",
    "                rubricScore2 = df2['Rubric Score'].values[0]\n",
    "                ce1 = row[colCE]\n",
    "                ce2 = df2[colCE].values[0]\n",
    "                print(f'MC Score 1: {mcScore1}, Rubric Score 1: {rubricScore1}')\n",
    "                print(f'MC Score 2: {mcScore2}, Rubric Score 2: {rubricScore2}')\n",
    "                print(f'CE 1: {ce1}, CE 2: {ce2}')\n",
    "                if mcScore1 == mcScore2 and rubricScore1 == rubricScore2 and ce1 == ce2:\n",
    "                    print('Both MC score and Rubric score are the same')\n",
    "                    df.at[i, 'Tooth Number'] = '24'\n",
    "                    df.at[df2.index[0], 'Tooth Number'] = '11'\n",
    "                    print(f'Filling {i} with 24 and {df2.index[0]} with 11')\n",
    "                elif ce1 == 'Yes':\n",
    "                    df3 = df_[(df_[colId] == studentId) & (df_[colCE] == 'Yes')]\n",
    "                    teeth = df3['Tooth Number'].values[0]\n",
    "                    print(f'Filling with {teeth}')\n",
    "                    df.at[i, 'Tooth Number'] = teeth\n",
    "                    # Find other row with the same student id and item\n",
    "                    df4 =df_[(df_[colId] == studentId) & (df_['Item'] == item)] \n",
    "                    df.at[df4.index[0], 'Tooth Number'] = teeth\n",
    "\n",
    "                continue\n",
    "            \n",
    "            # get opposite tooth number\n",
    "            toothnumberfill = '24' if toothnumber2 == '11' else '11'\n",
    "            print(f'Filling with {toothnumberfill}')\n",
    "            df.at[i, 'Tooth Number'] = toothnumberfill\n",
    "            pass\n",
    "\n",
    "print(f'None list: {set(noneList)}')\n",
    "mcScore = df['MC Score'].copy()\n",
    "df.to_excel(f'{folder}/{filename2} marks filled.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create item (teeth) column\n",
    "df = pd.read_excel(f'{folder}/{filename2} marks.xlsx')\n",
    "idcounts = df[colId].value_counts()\n",
    "display(idcounts)\n",
    "df['Tooth Number'] = df['Tooth Number'].astype('Int64').astype(str)\n",
    "df['Item (Teeth)'] = df['Item'] + ' (' + df['Tooth Number'] + ')'\n",
    "display(df.head())\n",
    "df['MC Score'] = (df['MC Score']*100).apply(lambda x: round(x, 2)).astype(str)\n",
    "# create a pivot table with item as columns and MC Score as values with Student ID as index\n",
    "pivotDf2 = df.pivot_table(index=[colId], columns='Item (Teeth)', values='MC Score', aggfunc= lambda x: ', '.join(x))\n",
    "df.drop(columns=['Item (Teeth)'], inplace=True)\n",
    "pivotDf2 = pivotDf2.reset_index()\n",
    "\n",
    "df['MC Score'] = df['MC Score'].astype(float)\n",
    "\n",
    "# different sheets for 24 and 11 teeth\n",
    "print(df['Tooth Number'].unique())\n",
    "df11 = df[df['Tooth Number'] == '11']\n",
    "df24 = df[df['Tooth Number'] == '24']\n",
    "dfNone = df[~df['Tooth Number'].isin(['24', '11'])]\n",
    "display(df11)\n",
    "# create pivot tables for 11 and 24 teeth\n",
    "aggFunc1 = lambda x: ', '.join(str(v) for v in x)\n",
    "aggFunc = 'first'\n",
    "pivotDf11 = df11.pivot_table(index=[colId], columns='Item', values='MC Score', aggfunc= aggFunc)[teethItem['11']]\n",
    "pivotDf24 = df24.pivot_table(index=[colId], columns='Item', values='MC Score', aggfunc= aggFunc)[teethItem['24']]\n",
    "pivotDfNone = dfNone.pivot_table(index=[colId], columns='Item', values='MC Score', aggfunc= aggFunc1)\n",
    "# Add a column for CE and CE Reason where CE is aggregated as Yes if any of the CE is Yes\n",
    "aggDict = {'Rubric Score': 'max', colCE: lambda x: 'Yes' if 'Yes' in x.values else 'No', colCEReason: 'first'}\n",
    "df11CE = df11.groupby(colId).agg(aggDict)\n",
    "df24CE = df24.groupby(colId).agg(aggDict)\n",
    "dfNoneCE = dfNone.groupby(colId).agg(aggDict)\n",
    "# Join to pivot tables on Student ID\n",
    "pivotDf11 = pivotDf11.join(df11CE)\n",
    "pivotDf24 = pivotDf24.join(df24CE)\n",
    "pivotDfNone = pivotDfNone.join(dfNoneCE)\n",
    "pivotDf11 = pivotDf11.reset_index()\n",
    "pivotDf24 = pivotDf24.reset_index()\n",
    "pivotDfNone = pivotDfNone.reset_index()\n",
    "# create dictionary of weights for each item\n",
    "weights = { '11': {\n",
    "    '415_SIM ACCESS': 0.4,\n",
    "    '415_SIM WORK LENGTH': 0.2,\n",
    "    '417_SIM CONE FIT': 0.2,\n",
    "    '417_SIM ROOT FLG': 0.2,\n",
    "    },\n",
    "    '24': {\n",
    "    '415_SIM ACCESS': 0.4,\n",
    "    '415_SIM WORK LENGTH': 0.1,\n",
    "    '416_SIM': 0.1,\n",
    "    '417_SIM CONE FIT': 0.1,\n",
    "    '417_SIM ROOT FLG': 0.1,\n",
    "    '418_SIM CONE FIT': 0.1,\n",
    "    '418_SIM ROOT FLG': 0.1\n",
    "    }\n",
    "\n",
    "}\n",
    "# calculate the MC total score for each student\n",
    "for tooth in ['11', '24']:\n",
    "    pivotDf = pivotDf11 if tooth == '11' else pivotDf24\n",
    "    for index, row in pivotDf.iterrows():\n",
    "        total = 0\n",
    "        for item in teethItem[tooth]:\n",
    "            if item in row:\n",
    "                total += row[item] * weights[tooth][item]\n",
    "        pivotDf.at[index, 'MC Total'] = total\n",
    "    # Add the rubric scores to grand total with 5% weight\n",
    "    pivotDf['Rubric Score'] = pivotDf['Rubric Score'].astype(float)\n",
    "    pivotDf['MC Total'] = pivotDf['MC Total'].astype(float)\n",
    "    pivotDf['Grand Total'] = pivotDf['MC Total']*0.95 + pivotDf['Rubric Score']*100*0.05\n",
    "    pivotDf['Grand Total'] = pivotDf['Grand Total'].apply(lambda x: round(x, 2))\n",
    "    pivotDf.sort_values(by='Grand Total', ascending=False, inplace=True)\n",
    "# save to the marks pivot file with 11 and 24 sheets\n",
    "with pd.ExcelWriter(f'{folder}/{filename2} marks pivot 2.xlsx') as writer:\n",
    "    pivotDf2.to_excel(writer, sheet_name='All', index=False)\n",
    "    pivotDf11.to_excel(writer, sheet_name='11', index=False)\n",
    "    pivotDf24.to_excel(writer, sheet_name='24', index=False)\n",
    "    pivotDfNone.to_excel(writer, sheet_name='None', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a pivot table to get items done on dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guttmanPath = 'DDS2\\CAF+v0.1_September+23,+2024_20.08\\DDS2 Paeds marks.xlsx'\n",
    "# for item 013_LIMITED OE, fill the total score with rubric score\n",
    "df = pd.read_excel(guttmanPath)\n",
    "df['Item'] = df['Item'].str.strip()\n",
    "df.loc[df['Item'] == '013_LIMITED OE', 'Total Score'] = df.loc[df['Item'] == '013_LIMITED OE', 'Rubric Score']\n",
    "df['Total Score CE Penalty (20%)'] = df['Total Score'].apply(lambda x: x*0.8 if colCE == 'Yes' else x)\n",
    "df['Total Score CE Penalty (20%)'] = df['Total Score CE Penalty (20%)'].apply(lambda x: round(x, 2))\n",
    "df['Total Score CE Penalty (20%)'] = df.apply(\n",
    "    lambda row: 0 if row[colFinished] == 0 and pd.isna(row['Total Score CE Penalty (20%)']) else row['Total Score CE Penalty (20%)'],\n",
    "    axis=1)\n",
    "display(df[df['Item'] == '013_LIMITED OE'])\n",
    "# df.to_excel(guttmanPath, index=False)\n",
    "\n",
    "df = df[(df[colClinicType] != 'Fixed Pros') | (df[colClinicType] != 'Endo')]\n",
    "display(df['Item'].value_counts())\n",
    "folder, file, ext = getFolderandFileName(guttmanPath)\n",
    "pivotDf = df.pivot_table(index=[colId], columns='Item', values='Total Score CE Penalty (20%)', dropna=False)\n",
    "pivotDf = pivotDf.reset_index()\n",
    "# sort columns based on length of column name\n",
    "# pivotDf = pivotDf.reindex(sorted(pivotDf.columns, key=len), axis=1)\n",
    "pivotDf.to_excel(f'{folder}/{file} pivot.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDS2 Paeds completion info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyText = 'Not completed'\n",
    "from datetime import datetime\n",
    "def saveToExcel(df, savePath, sheet_name):    \n",
    "    with pd.ExcelWriter(savePath, engine='openpyxl', mode='w') as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "        # Define a format object for red color fill with XlsxWriter.\n",
    "        red_format = openpyxl.styles.PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')\n",
    "        font_color = openpyxl.styles.Font(color='CF2D06')\n",
    "        ce524_format = openpyxl.styles.PatternFill(start_color='D7BDE2', end_color='D7BDE2', fill_type='solid')  # Purple\n",
    "\n",
    "        # Apply the format based on a conditional rule (cell value == 1).\n",
    "        for idx, col in enumerate(df.columns, 1):\n",
    "            column_letter = getColumnLetter(idx)\n",
    "            for cell in worksheet[f'{column_letter}2:{column_letter}{len(df) + 1}']:\n",
    "                for c in cell:\n",
    "                    if c.value == emptyText:\n",
    "                        c.fill = red_format\n",
    "                        c.font = font_color\n",
    "\n",
    "guttmanPath = 'DDS2\\CAF+v0.1_September+23,+2024_20.08\\CAF v0.1_September 23, 2024_20.08 split.xlsx'\n",
    "\n",
    "workbook, folder, filename = loadWorkbook(guttmanPath)\n",
    "requiredCodes = [532, 525, 578, 414, 524, 586, 579, 386, 656, 587, 161, 121, '013']\n",
    "# convert codes to string\n",
    "requiredCodes = [str(code) for code in requiredCodes]\n",
    "completedDf = pd.DataFrame(columns=[colId, colDate, 'Item'])\n",
    "idnameDict = {}\n",
    "for sheet in workbook.sheetnames:\n",
    "    code = sheet.split('_')[0]\n",
    "    if not code in requiredCodes:\n",
    "        print(f'{code} not in requiredCodes')\n",
    "        continue\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    df.dropna(subset=[colId], inplace=True)\n",
    "    df[colId] = df[colId].astype(int)\n",
    "    df['Student Name'] = df[colNameG] + ' ' + df[colNameF]\n",
    "    df = df[[colId, 'Student Name', colDate]]\n",
    "    df['Item'] = code\n",
    "    completedDf = pd.concat([completedDf, df])\n",
    "    for index, row in df.iterrows():\n",
    "        idnameDict[row[colId]] = row['Student Name']\n",
    "\n",
    "display(completedDf.head())\n",
    "completedDf.to_excel(f'{folder}\\{filename} completed info.xlsx', index=False)\n",
    "completedDf\n",
    "# Create a pivot table with Item as columns, Student ID and Student Namesas index, and Date as values\n",
    "pivotDf = completedDf.pivot_table(index=[colId], columns='Item', values=colDate, \n",
    "                                  aggfunc=lambda x: (',\\n '.join([''] + list(x))).strip(',\\n '))\n",
    "pivotDf.reset_index(inplace=True)\n",
    "pivotDf.fillna(emptyText, inplace=True)\n",
    "# Add Student Name column\n",
    "pivotDf['Student Name'] = pivotDf[colId].map(idnameDict)\n",
    "# Reorder columns\n",
    "pivotDf = pivotDf[[colId, 'Student Name'] + requiredCodes]\n",
    "display(pivotDf.head())\n",
    "\n",
    "# save to excel with no index and Nan cells colored FFC7CE\n",
    "savePath = f'{folder}\\Paeds completion info type 1.xlsx'\n",
    "sheet_name = 'Sheet1'\n",
    "saveToExcel(pivotDf, savePath, sheet_name)\n",
    "\n",
    "# For new type of pivot table, first merge date and item columns engulfed in brackets\n",
    "completedDf['Item Date'] = completedDf['Item'] + ' (' + completedDf[colDate] + ')'\n",
    "# aggregate the Item Date and Student ID columns to get count \n",
    "completedDf = completedDf.groupby([colId, 'Item Date']).size().reset_index(name='count')\n",
    "display(completedDf.head())\n",
    "pivotDf = completedDf.pivot_table(index=[colId], columns='Item Date', values='count', \n",
    "                                  aggfunc=lambda x: x)\n",
    "pivotDf.reset_index(inplace=True)\n",
    "pivotDf.fillna(emptyText, inplace=True)\n",
    "# Add Student Name column\n",
    "pivotDf['Student Name'] = pivotDf[colId].map(idnameDict)\n",
    "# Reorder columns\n",
    "otherCodes = list(set(pivotDf.columns) - set([colId, 'Student Name']))\n",
    "# Function to extract the date from the 'Item Date' column and convert it to a datetime object for sorting\n",
    "def extractDate(itemDateStr):\n",
    "    # Find the date in the format '(YYYY-MM-DD)'\n",
    "    dateStr = re.search(r'\\((.*?)\\)', itemDateStr)\n",
    "    if dateStr:\n",
    "        return datetime.strptime(dateStr.group(1), '%d/%m/%Y')\n",
    "    return datetime.min  # Return a minimum date if the format is not found\n",
    "\n",
    "# Sort otherCodes based on the extracted date from 'Item Date'\n",
    "# otherCodesSorted = sorted(otherCodes, key=lambda col: extractDate(col))\n",
    "\n",
    "# Sort based on the item\n",
    "otherCodesSorted = sorted(otherCodes, key=lambda col: col.split()[0])\n",
    "# Reorder the DataFrame columns\n",
    "orderedCols = [colId, 'Student Name'] + otherCodesSorted\n",
    "pivotDf = pivotDf[orderedCols]\n",
    "\n",
    "pivotDf = pivotDf[orderedCols]\n",
    "display(pivotDf.head())\n",
    "savePath2 = f'{folder}\\Paeds completion info sorted item.xlsx'\n",
    "sheet_name = 'Sheet1'\n",
    "saveToExcel(pivotDf, savePath2, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guttman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'DDS2\\CAF+v0.1_September+23,+2024_20.08\\DDS2 Paeds.xlsx'\n",
    "savepath = 'DDS2\\CAF+v0.1_September+23,+2024_20.08\\DDS2 Paeds filtered.xlsx'\n",
    "guttmancreator = CreateGuttman(savepath, workbookpath)\n",
    "splitDfPath = 'DDS2\\CAF+v0.1_September+23,+2024_20.08\\DDS2 Paeds split.xlsx'\n",
    "guttmancreator.createGuttman(splitDfPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get number of items done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guttmanpath = 'FullSpreadsheets\\\\CAF+v0.1_September+15,+2024_23.24\\\\Fixed Pros DENT90120\\\\DENT90120 Fixed Pros guttman.xlsx'\n",
    "# folder, filename, ext = getFolderandFileName(guttmanpath)\n",
    "workbook, folder, filename = loadWorkbook(guttmanpath)\n",
    "requiredItems = [541, 542, 543, 544, 545 ,551, 552, 553, 554, 555, 556, 572, 577, 611, 613, 615, 618,\n",
    "                 625, 627, 631, 643, 651, 655]\n",
    "lengthDf = pd.DataFrame(columns=['Item', '# of Forms'])\n",
    "studentItemDf = pd.DataFrame(columns=['Item', 'Student ID'])\n",
    "for sheet in workbook.sheetnames:\n",
    "    code = sheet.split('_')[0]\n",
    "    try:\n",
    "        if not int(code) in requiredItems:\n",
    "            print(f'{sheet} not in requiredItems')\n",
    "            continue\n",
    "    except ValueError:\n",
    "        print(f'{sheet} not in requiredItems')\n",
    "        continue\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    # remove last row\n",
    "    df = df.iloc[:-1]\n",
    "    df[colId] = df[colId].astype(int)\n",
    "    lengthDf = pd.concat([lengthDf, pd.DataFrame({'Item': [code], '# of Forms': [df.shape[0]]})])\n",
    "    studentItemDf = pd.concat([studentItemDf, pd.DataFrame({'Item': [code]*df.shape[0], 'Student ID': df['Student ID']})])\n",
    "\n",
    "# Sort the dataframe by # of students\n",
    "lengthDf = lengthDf.sort_values('# of Forms', ascending=False)\n",
    "lengthDf.to_csv(f'{folder}/Number of forms per Item.csv', index=False)\n",
    "# plot a bar graph\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.barplot(x='Item', y='# of Forms', data=lengthDf)\n",
    "plt.title('Number of forms per Item')\n",
    "plt.savefig(f'{folder}/Number of forms per Item.png')\n",
    "plt.show()\n",
    "\n",
    "# student item df, aggregate over student id and add a column with count of items\n",
    "originalStudentItemDf = studentItemDf.copy()\n",
    "studentItemDfCount = originalStudentItemDf.groupby(['Student ID', 'Item']).size().reset_index(name='Count')\n",
    "display(studentItemDfCount.head())\n",
    "# For each Item, create a bar graph of student and Count\n",
    "uniqueItems = studentItemDfCount['Item'].unique()\n",
    "for item in uniqueItems:\n",
    "    df = studentItemDfCount[studentItemDfCount['Item'] ==item]\n",
    "    df.sort_values('Count', ascending=False, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    display(df.head())\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.barplot(x=colId, y='Count', data=df, order=df[colId])\n",
    "    plt.title(f'Number of Items for {item} per Student')\n",
    "    plt.xticks(rotation=90)\n",
    "    # y ticks only integers\n",
    "    plt.yticks(np.arange(0, df['Count'].max()+1, 1))\n",
    "    savefolder = f'{folder}/Student Counts'\n",
    "    os.makedirs(savefolder, exist_ok=True)\n",
    "    plt.savefig(f'{savefolder}/{item}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Get an overall count of items per student\n",
    "studentCount = studentItemDfCount.groupby('Student ID').sum().reset_index()\n",
    "studentCount.rename(columns={'Count': 'Total Count'}, inplace=True)\n",
    "studentCount.sort_values('Total Count', ascending=False, inplace=True)\n",
    "display(studentCount.head())\n",
    "plt.figure(figsize=(35, 10))\n",
    "sns.barplot(x='Student ID', y='Total Count', data=studentCount, order=studentCount['Student ID'])\n",
    "plt.title('Total Number of Items per Student')  \n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig(f'{folder}/Total Count.png')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom marks for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(dfGuttman, mcCols, colCE=None, colCEReason=None, colComments: list = None, colSupervisor=None):\n",
    "    print(\"\\nAggregating data...\")\n",
    "    aggFuncs = {col: 'first' for col in dfGuttman.columns if col not in mcCols + rubricQues}\n",
    "    aggFuncs.update({col: custom_agg for col in mcCols})\n",
    "    aggFuncs.update({col: 'max' for col in rubricQues})\n",
    "    matching_columns = [col for col in dfGuttman.columns if any(pattern in col for pattern in newRubricQuesPatterns)]\n",
    "    aggFuncs.update({col: 'max' for col in matching_columns})\n",
    "    if colCE is not None:\n",
    "        aggFuncs.update({colCE: lambda x: 'Yes' if 'Yes' in x.values else 'No'})\n",
    "    if colCEReason is not None:\n",
    "        aggFuncs.update({colCEReason: lambda x: ', '.join(x.values).strip(' ,')})\n",
    "    if colComments is not None:\n",
    "        for col in colComments:\n",
    "            aggFuncs.update({col: lambda x: '\\n\\n '.join(x.values).strip(' \\n')})\n",
    "    if colSupervisor is not None:\n",
    "        aggFuncs.update({colSupervisor: lambda x: ', '.join(x.values).strip(' ,')})\n",
    "    dfTemp = dfGuttman.groupby([colId], as_index=False).agg(aggFuncs)  # aggregate the data\n",
    "    return dfTemp\n",
    "\n",
    "def getSupervisorPairs(dfMarks, dfBest, folder, file):\n",
    "    df = dfMarks.copy()\n",
    "    df.sort_values(by=colSupervisor, inplace=True)\n",
    "\n",
    "    # Create a new DataFrame to store the differences and supervisor pair information\n",
    "    comparison_data = []\n",
    "\n",
    "    # Group by 'Student ID' to find pairs of rows for the same student\n",
    "    grouped = df.groupby('Student ID')\n",
    "\n",
    "    for student_id, group in grouped:\n",
    "        if len(group) == 2:\n",
    "            supervisor1 = group.iloc[0][colSupervisor]\n",
    "            supervisor2 = group.iloc[1][colSupervisor] \n",
    "            # yes_diff = group.iloc[0]['Yes'] - group.iloc[1]['Yes']\n",
    "            mc_score_diff = group.iloc[0]['MC Score'] - group.iloc[1]['MC Score']\n",
    "            rubric_weighted_score_diff = group.iloc[0]['Rubric Score'] - group.iloc[1]['Rubric Score']\n",
    "            total_score_diff = group.iloc[0]['Total'] - group.iloc[1]['Total']\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Student ID': student_id,\n",
    "                'Supervisor Pair': f\"[{supervisor1}, {supervisor2}]\",\n",
    "                # 'Yes Difference': yes_diff,\n",
    "                'MC Score Difference': mc_score_diff,\n",
    "                'Rubric Score Difference': rubric_weighted_score_diff,\n",
    "                'Total Score Difference': total_score_diff\n",
    "            })\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    # add the Supervisor Pair column to the best df, using the Student ID as the matching key\n",
    "\n",
    "    if dfBest is not None:\n",
    "        dfBest = dfBest.merge(comparison_df[['Student ID', 'Supervisor Pair']], on='Student ID', how='left')\n",
    "\n",
    "\n",
    "    # Sort the DataFrame by 'Total Score Difference' in descending order\n",
    "    comparison_df_sorted = comparison_df.sort_values(by='Total Score Difference', ascending=False)\n",
    "    comparison_df_sorted['Student ID'] = comparison_df_sorted['Student ID'].astype(int)\n",
    "\n",
    "    # Set the color palette\n",
    "    unique_supervisor_pairs = comparison_df_sorted['Supervisor Pair'].unique()\n",
    "    color_palette = plt.cm.get_cmap('tab10', len(unique_supervisor_pairs))\n",
    "    color_dict = {pair: color_palette(i) for i, pair in enumerate(unique_supervisor_pairs)}\n",
    "\n",
    "\n",
    "    # Redefining the plot function to include text for zero values\n",
    "    def plot_integer_bar_chart(df, y_column, title):\n",
    "        sorted_df = df.sort_values(by=y_column, ascending=False)\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        bars = plt.bar(sorted_df['Student ID'].astype(str), sorted_df[y_column], color=[color_dict[pair] for pair in sorted_df['Supervisor Pair']])\n",
    "        \n",
    "        # Add text \"No difference\" where the bar height is zero\n",
    "        for bar, pair in zip(bars, sorted_df['Supervisor Pair']):\n",
    "            if bar.get_height() == 0:\n",
    "                plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.0, 'No difference', ha='center', va='bottom', color=color_dict[pair], rotation=90)\n",
    "        \n",
    "        plt.xlabel('Student ID')\n",
    "        plt.ylabel(y_column)\n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=90, ha='center')\n",
    "        # show the zero line\n",
    "        plt.axhline(0, color='black', linewidth=0.5)\n",
    "        # Create a legend\n",
    "        handles = [Rectangle((0, 0), 1, 1, color=color_dict[pair]) for pair in unique_supervisor_pairs]\n",
    "        plt.legend(handles, unique_supervisor_pairs, title=\"Supervisor Pairs\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        plt.savefig(f'{folder}/{file} {y_column}.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    # Plotting the bar charts with integer Student ID and 90-degree label rotation\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Total Score Difference', 'Total Score Difference by Student ID')\n",
    "    # plot_integer_bar_chart(comparison_df_sorted, 'Yes Difference', 'Yes Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'MC Score Difference', 'MC Score Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Rubric Score Difference', 'Rubric Score Difference by Student ID')\n",
    "\n",
    "    # Show counts of each pair\n",
    "    pair_counts = comparison_df_sorted['Supervisor Pair'].value_counts().reset_index()\n",
    "    pair_counts.columns = ['Supervisor Pair', 'Count']\n",
    "    # display(pair_counts)\n",
    "    return pair_counts, comparison_df_sorted, dfBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOH1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini CEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH1\\Mini-CEX_BOH1Students_October10\\Mini-CEX Prototype - BOH1 - Students_October 10, 2024_00.06.xlsx'\n",
    "workbookpath = 'BOH1\\Mini-CEXPrototypeBOH1Students_October+20,+2024\\Mini-CEX Prototype - BOH1 - Students_October 20, 2024_16.46.xlsx'\n",
    "df = pd.read_excel(workbookpath)\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = df[1:]\n",
    "print(df.columns)\n",
    "mcCols = [col for col in df.columns if 'MC' in col]\n",
    "df[colId] = df[colId].astype(int, errors = 'ignore')\n",
    "df[colComments] = df[colComments].fillna(' ').astype(str)\n",
    "df[colDate] = pd.to_datetime(df[colDate], errors='coerce').dt.date\n",
    "studentList = getStudentList()\n",
    "\n",
    "df = df[df[colId].isin(studentList)]\n",
    "\n",
    "rubricQues = variableUtils.rubricQues.copy()\n",
    "rubricQues.remove('CS')\n",
    "df = convertRubricScale(df, rubricQues)\n",
    "display(df.head())\n",
    "rubricW = {'PS': 0.1, 'TS': .1, 'ES': .1}\n",
    "rubricDenom = {'PS': 3, 'TS': 4, 'ES': 4}\n",
    "rubricValues = {'rubricW': rubricW, 'rubricDenom': rubricDenom, 'rubricQues': rubricQues}\n",
    "dfGuttman = convertToGuttman(df, colId, colDate, rubricQues, workbookpath, 'Sheet1', None, mcCols, [], rubricValues)\n",
    "# display(df.head())\n",
    "mcCols = findMCColumns(df, '414')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOH2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment 3 Pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSupervisorPairs(dfOriginal, dfBest):\n",
    "    df = dfOriginal.copy()\n",
    "    df.sort_values(by=colSupervisor, inplace=True)\n",
    "\n",
    "    # Create a new DataFrame to store the differences and supervisor pair information\n",
    "    comparison_data = []\n",
    "\n",
    "    # Group by 'Student ID' to find pairs of rows for the same student\n",
    "    grouped = df.groupby('Student ID')\n",
    "\n",
    "    for student_id, group in grouped:\n",
    "        if len(group) == 2:\n",
    "            supervisor1 = group.iloc[0][colSupervisor]\n",
    "            supervisor2 = group.iloc[1][colSupervisor] \n",
    "            yes_diff = group.iloc[0]['Yes'] - group.iloc[1]['Yes']\n",
    "            mc_score_diff = group.iloc[0]['MC Score'] - group.iloc[1]['MC Score']\n",
    "            rubric_weighted_score_diff = group.iloc[0]['Rubric Weighted Score'] - group.iloc[1]['Rubric Weighted Score']\n",
    "            total_score_diff = group.iloc[0]['Total Score'] - group.iloc[1]['Total Score']\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Student ID': student_id,\n",
    "                'Supervisor Pair': f\"[{supervisor1}, {supervisor2}]\",\n",
    "                'Yes Difference': yes_diff,\n",
    "                'MC Score Difference': mc_score_diff,\n",
    "                'Rubric Weighted Score Difference': rubric_weighted_score_diff,\n",
    "                'Total Score Difference': total_score_diff\n",
    "            })\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Sort the DataFrame by 'Total Score Difference' in descending order\n",
    "    comparison_df_sorted = comparison_df.sort_values(by='Total Score Difference', ascending=False)\n",
    "    comparison_df_sorted['Student ID'] = comparison_df_sorted['Student ID'].astype(int)\n",
    "\n",
    "    # Set the color palette\n",
    "    unique_supervisor_pairs = comparison_df_sorted['Supervisor Pair'].unique()\n",
    "    color_palette = plt.cm.get_cmap('tab10', len(unique_supervisor_pairs))\n",
    "    color_dict = {pair: color_palette(i) for i, pair in enumerate(unique_supervisor_pairs)}\n",
    "\n",
    "\n",
    "    # Redefining the plot function to include text for zero values\n",
    "    def plot_integer_bar_chart(df, y_column, title):\n",
    "        sorted_df = df.sort_values(by=y_column, ascending=False)\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        bars = plt.bar(sorted_df['Student ID'].astype(str), sorted_df[y_column], color=[color_dict[pair] for pair in sorted_df['Supervisor Pair']])\n",
    "        \n",
    "        # Add text \"No difference\" where the bar height is zero\n",
    "        for bar, pair in zip(bars, sorted_df['Supervisor Pair']):\n",
    "            if bar.get_height() == 0:\n",
    "                plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.0, 'No difference', ha='center', va='bottom', color=color_dict[pair], rotation=90)\n",
    "        \n",
    "        plt.xlabel('Student ID')\n",
    "        plt.ylabel(y_column)\n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=90, ha='center')\n",
    "        # show the zero line\n",
    "        plt.axhline(0, color='black', linewidth=0.5)\n",
    "        # Create a legend\n",
    "        handles = [Rectangle((0, 0), 1, 1, color=color_dict[pair]) for pair in unique_supervisor_pairs]\n",
    "        plt.legend(handles, unique_supervisor_pairs, title=\"Supervisor Pairs\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{folder}/{file} {y_column}.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    # Plotting the bar charts with integer Student ID and 90-degree label rotation\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Total Score Difference', 'Total Score Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Yes Difference', 'Yes Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'MC Score Difference', 'MC Score Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Rubric Weighted Score Difference', 'Rubric Weighted Score Difference by Student ID')\n",
    "\n",
    "    # Show counts of each pair\n",
    "    pair_counts = comparison_df_sorted['Supervisor Pair'].value_counts().reset_index()\n",
    "    pair_counts.columns = ['Supervisor Pair', 'Count']\n",
    "    display(pair_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 524 578 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH2\\Assessment 2\\BOH2 Sim Assessment data 578\\BOH2 Sim Assessment data 524_578 Complete.xlsx'\n",
    "\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "workbook, _, _ = loadWorkbook(workbookpath)\n",
    "# df = pd.read_excel(workbookpath)\n",
    "for sheet in workbook.sheetnames:\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    \n",
    "    df = df[1:]\n",
    "    mcCols = findMCColumns(df)\n",
    "\n",
    "    df[colId] = df[colId].astype(int, errors = 'ignore')\n",
    "    print(df[colId].value_counts())\n",
    "    df[colCEReason] = df[colCEReason].fillna(' ')\n",
    "    df[colCEReason] = df[colCEReason].astype(str)\n",
    "    df[colDate] = pd.to_datetime(df[colDate], errors='coerce')\n",
    "    df[colComments] = df[colComments].fillna(' ').astype(str)\n",
    "    # display(df.head())\n",
    "    studentList = getStudentList()\n",
    "    df = df[df[colId].isin(studentList)]\n",
    "    rubricQues = variableUtils.rubricQues.copy()\n",
    "    rubricQues.remove('CS')\n",
    "    df = convertRubricScale(df, rubricQues)\n",
    "\n",
    "    # get list of students whose date is in Oct\n",
    "    studentListAug = df[df[colDate].dt.month == 10][colId].unique()\n",
    "    # print(studentListAug)\n",
    "    # remove the rows with students in studentListAug and dates in August\n",
    "    df = df[~((df[colId].isin(studentListAug)) & (df[colDate].dt.month == 8))]\n",
    "    df[colDate] = df[colDate].dt.date\n",
    "    print(df[colId].value_counts())\n",
    "    rubricW = {'PS': 0.05, 'TS': .1, 'ES': .1}\n",
    "    rubricDenom = {'PS': 2, 'TS': 3, 'ES': 4}\n",
    "    rubricValues = {'rubricW': rubricW, 'rubricDenom': rubricDenom, 'rubricQues': rubricQues}\n",
    "\n",
    "    dfGuttman = convertToGuttman(df, colId, colDate, rubricQues, workbookpath, sheet, colCE, mcCols, [colComments], rubricValues)\n",
    "\n",
    "    dfTemp = aggregator(dfGuttman, mcCols, colCE, colCEReason, [colComments], colSupervisor)\n",
    "\n",
    "    dfBest = convertToGuttman(dfTemp, colId, colDate, rubricQues, f'{folder}/{file} best.xlsx', sheet, colCE, mcCols, [colComments], rubricValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 414 Pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH2\\ORAL20005\\ORAL20005 Sim Clinic Assessment 3_September 3, 2024_23.23.xlsx'\n",
    "workbookpath = 'BOH2\\BOH2_Assessment 3\\ORAL20005 Sim Clinic Assessment 3_October 2, 2024_18.csv'\n",
    "df = pd.read_excel(workbookpath)\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df = renameColumns(df)\n",
    "print(df.columns)\n",
    "df[colId] = df[colId].astype(int, errors = 'ignore')\n",
    "df[colCEReason] = df[colCEReason].fillna(' ')\n",
    "df[colCEReason] = df[colCEReason].astype(str)\n",
    "df[colComments] = df[colComments].fillna(' ').astype(str)\n",
    "df[colDate] = pd.to_datetime(df[colDate], errors='coerce').dt.date\n",
    "studentList = getStudentList()\n",
    "\n",
    "df = df[df[colId].isin(studentList)]\n",
    "# get list of students whose date is in Oct\n",
    "studentListAug = df[df[colDate].dt.month == 10][colId].unique()\n",
    "\n",
    "# print(studentListAug)\n",
    "# remove the rows with students in studentListAug and dates in August\n",
    "df = df[~((df[colId].isin(studentListAug)) & (df[colDate].dt.month == 8))]\n",
    "df[colDate] = df[colDate].dt.date\n",
    "rubricQues = variableUtils.rubricQues.copy()\n",
    "rubricQues.remove('CS')\n",
    "df = convertRubricScale(df, rubricQues)\n",
    "display(df.head())\n",
    "dfGuttman = convertToGuttman(df, colId, colDate, rubricQues, workbookpath, '414', colCE)\n",
    "# display(df.head())\n",
    "mcCols = findMCColumns(df, '414')\n",
    "\n",
    "dfTemp = aggregator(dfGuttman, mcCols, colCE, colCEReason, [colComments])\n",
    "\n",
    "dfBest = convertToGuttman(dfTemp, colId, colDate, rubricQues, f'{folder}/{file} best.xlsx', 'Sheet1', colCE, mcCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBlank = 'Not Filled'\n",
    "otherCols = [colComplex, colClinicType, colDate, colSupervisor, colFinished, colCE, colCEReason]\n",
    "labelRubric = 'Rubric Weighted Score'\n",
    "dfTemplate = pd.DataFrame(columns=[colId, 'Yes', 'No', 'Not Reviewed', labelBlank, 'Total MC items'] + rubricQues + ['MC Score', labelRubric] + otherCols +['Item', 'Total Score'])\n",
    "notReviewedW = 0.5\n",
    "rubricW = {'PS': 0.1, 'CS': 0.0, 'TS': 0.1, 'ES': 0.1} # This is simulation thus professionalism and communication are reduced weighted\n",
    "rubricDenom = {'PS': 2, 'CS': 0, 'TS': 3, 'ES': 4}\n",
    "mcScoreW = 0.8\n",
    "rubricScoreW = 0.2\n",
    "\n",
    "# plot a bar chart of average scores\n",
    "def plotAverageScores(df):\n",
    "    average_scores = df.groupby(colSupervisor)['Total Score'].mean().reset_index()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=colSupervisor, y='Total Score', data=average_scores)\n",
    "    plt.title(f'Average Scores for examiners')\n",
    "    plt.xlabel('Examiner')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f'{folder}/Average Scores.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = getPairCounts(df)\n",
    "pairs_df.to_excel(f'{folder}/{file} pairs.xlsx', index=False)\n",
    "mcColumns = 0\n",
    "def getTotals(df, key, savepath=None):\n",
    "    print(key)\n",
    "    code = key.split('_')[0]\n",
    "    df[colId] = df[colId].astype('Int64', errors='ignore')\n",
    "    # df = df[df[colFinished] == 'True']\n",
    "\n",
    "    mcColumns = findMCColumns(df)\n",
    "    print(mcColumns)\n",
    "    print(df[colId].value_counts())\n",
    "    display(df[mcColumns].head())\n",
    "\n",
    "    countsDf = dfTemplate.copy()\n",
    "    countsDf[colId] = df[colId]\n",
    "    countsDf['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['Total MC items'] = len(mcColumns)\n",
    "    \n",
    "    # The same for df\n",
    "    df['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    df['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    df['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    df[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    df['Total MC items'] = len(mcColumns)\n",
    "    # display(countsDf.head())\n",
    "    \n",
    "    for q in rubricQues:\n",
    "        countsDf[q] = df[q]\n",
    "    for col in otherCols:\n",
    "        if col in df.columns:\n",
    "            countsDf[col] = df[col]\n",
    "\n",
    "    countsDf['MC Score'] = (countsDf['Yes'] + notReviewedW*countsDf['Not Reviewed']) / (countsDf['Yes'] + countsDf['No'] + notReviewedW*countsDf['Not Reviewed'])\n",
    "    countsDf['MC Score'] = countsDf['MC Score'].apply(lambda x: round(x, 2))\n",
    "    df['MC Score'] = countsDf['MC Score']\n",
    "    \n",
    "    display(countsDf.head())\n",
    "    \n",
    "    # display(countsDf[rubricQues])\n",
    "    countsDf[labelRubric] = countsDf.apply(lambda row: sum(row[ques] * rubricW[ques] / rubricDenom[ques] for ques in rubricQues), axis=1)/0.3\n",
    "    countsDf[labelRubric] = countsDf[labelRubric].apply(lambda x: round(x, 2))\n",
    "    df[labelRubric] = countsDf[labelRubric]\n",
    "    \n",
    "    # countsDf['ES Weighted Score'] = countsDf['ES']/ rubricDenom['ES']\n",
    "    # countsDf['ES Weighted Score'] = countsDf['ES Weighted Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf['Total Score'] = (mcScoreW*countsDf['MC Score'] + rubricScoreW*countsDf[labelRubric])*100\n",
    "    countsDf['Total Score'] = countsDf['Total Score'].apply(lambda x: round(x, 2))\n",
    "    df['Total Score'] = countsDf['Total Score']\n",
    "\n",
    "    # Add 20% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.8 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf['Total Score CE Penalty (20%)'].apply(lambda x: round(x, 2))\n",
    "    df['Total Score CE Penalty (20%)'] = countsDf['Total Score CE Penalty (20%)']\n",
    "\n",
    "    # Add 10% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.90 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf['Total Score CE Penalty (10%)'].apply(lambda x: round(x, 2))\n",
    "    df['Total Score CE Penalty (10%)'] = countsDf['Total Score CE Penalty (10%)']\n",
    "\n",
    "    countsDf['Item'] = key\n",
    "    \n",
    "    \n",
    "    # get counts of each CE Name\n",
    "    counts = df[colSupervisor].value_counts().reset_index()\n",
    "    counts.columns = [colSupervisor, 'Count']\n",
    "    display(counts)\n",
    "\n",
    "    countsDf.to_excel(savepath, index=False)\n",
    "    return countsDf, mcColumns\n",
    "\n",
    "bestMarksPath = f'{folder}/{file} best marks.xlsx'\n",
    "countsDf, mcColumns = getTotals(dfBest, '414', bestMarksPath)\n",
    "# plotAverageScores(countsDf)\n",
    "# if a column is not in dfBest and in countsDf, then add it to dfBest\n",
    "for col in countsDf.columns:\n",
    "    if col not in dfBest.columns:\n",
    "        dfBest[col] = countsDf[col]\n",
    "\n",
    "\n",
    "\n",
    "marksPath = f'{folder}/{file} marks.xlsx'\n",
    "countsDf2, _ = getTotals(dfGuttman, '414', marksPath)\n",
    "plotAverageScores(countsDf2)\n",
    "\n",
    "\n",
    "_, dfBest = getSupervisorPairs(countsDf2, dfBest, folder, file)\n",
    "\n",
    "saveDf(dfBest, f'{folder}/{file} best.xlsx', 'Sheet1', len(mcColumns) + 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMCReferenceTable( mcRefdf, header):\n",
    "        \n",
    "        if mcRefdf is None:\n",
    "            return Paragraph(\"No marking checklist reference found\", subsubheadingStyle)\n",
    "        \n",
    "        largeFontStyle = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=13, alignment=0)\n",
    "\n",
    "        # Create a table with MC and Full Text columns\n",
    "        data = [mcRefdf.columns.to_list()] + mcRefdf.values.tolist()\n",
    "        for i in range(1, len(data)):\n",
    "            data[i][1] = Paragraph(data[i][1], largeFontStyle)\n",
    "            data[i][0] = Paragraph(data[i][0], largeFontStyle)\n",
    "        table = Table(data, colWidths=[1.5 * inch, 9 * inch])\n",
    "\n",
    "        # Set the style for the table text as large font\n",
    "        \n",
    "\n",
    "        table_style = TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#236DB0')),  # Header row\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "            ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "            ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "            ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "            ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, -1), 12),  # Increase bottom padding\n",
    "            ('TOPPADDING', (0, 0), (-1, -1), 12),  # Increase top padding\n",
    "        ])\n",
    "        table.setStyle(table_style)\n",
    "        mergedElement = KeepTogether([header, Spacer(1, 12), table])\n",
    "        return mergedElement\n",
    "        # self.elements.append(table)\n",
    "        # self.elements.append(PageBreak())\n",
    "def createTable(df, title, colRatio:list, tableWidth = 0.9, customTextCols = [], tableTextStyle = tableTextStyle, topPadding = 12, bottomPadding = 12, cellHighlight = False, headerColor = '#9C27B0'):\n",
    "        \n",
    "        if df.empty:\n",
    "            table = Paragraph(\"No data found\", subsubheadingStyle)\n",
    "        else:\n",
    "            data = [df.columns.to_list()] + df.values.tolist()\n",
    "            \n",
    "            # Convert the custom text columns to paragraphs\n",
    "            for i in range(1, len(data)):\n",
    "                for j in customTextCols:\n",
    "                    data[i][j] = Paragraph(str(data[i][j]), tableTextStyle)\n",
    "            \n",
    "            if colRatio is not None:\n",
    "                colWidths = [ratio/sum(colRatio) * pageSize[0] * tableWidth for ratio in colRatio]\n",
    "            else:\n",
    "                colWidths = [1 for i in range(len(df.columns))] # Equal column widths\n",
    "            # print(f'Column widths: {colWidths}')\n",
    "            table = Table(data, colWidths=colWidths)\n",
    "            \n",
    "            table_style = TableStyle([\n",
    "                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor(headerColor)),  # Header row\n",
    "                ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "                ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "                ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "                ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "                ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "                ('BOTTOMPADDING', (0, 0), (-1, -1), bottomPadding),  # Increase bottom padding\n",
    "                ('TOPPADDING', (0, 0), (-1, -1), topPadding),  # Increase top padding\n",
    "            ])\n",
    "            table.setStyle(table_style)\n",
    "\n",
    "        mergedElement = KeepTogether([Paragraph(title, subsubheadingStyle), Spacer(1, 12), table, Spacer(1, 12)])\n",
    "\n",
    "        # Add red colour where cell values are No\n",
    "        if not cellHighlight:\n",
    "            return\n",
    "        for i in range(1, len(data)):\n",
    "            for j in range(len(data[i])):\n",
    "                if data[i][j] == 'No':\n",
    "                    table.setStyle(TableStyle([('TEXTCOLOR', (j, i), (j, i), colors.red)]))\n",
    "                if data[i][j] == 'Yes':\n",
    "                    table.setStyle(TableStyle([('TEXTCOLOR', (j, i), (j, i), colors.green)]))\n",
    "        return mergedElement\n",
    "\n",
    "filepath = 'BOH2\\ORAL20005 Sim Clinic Assessment 3_August 19, 2024_21.csv'\n",
    "df = pd.read_csv(filepath, encoding='ISO-8859-1')\n",
    "folder, file, ext = getFolderandFileName(filepath)\n",
    "df.columns = [f'MC{col.split(\"_\")[-1]}' if 'Pulpot' in col else col for col in df.columns]\n",
    "nameDict = {col: df.iloc[0][col].split('- Supervisor -')[-1] for col in df.columns}\n",
    "#  only take MC columns\n",
    "nameDict = {key: value for key, value in nameDict.items() if 'MC' in key}\n",
    "mcrefDf = pd.DataFrame(nameDict.items(), columns=['MC', 'Full Text'])\n",
    "print(nameDict)\n",
    "df = df[1:]\n",
    "# replace the column names with MC(d)\n",
    "# remove test@me.com row from colId\n",
    "df = df[df[colId] != 'test@me.com']\n",
    "df[colId] = df[colId].astype(int)\n",
    "studentList = getStudentList()\n",
    "df = df[df[colId].isin(studentList)]\n",
    "# display(df.head())\n",
    "mcCols = [col for col in df.columns if 'MC' in col]\n",
    "df = df[[colId, colNameG, colNameF, 'Examiners'] + mcCols ]\n",
    "df.sort_values(colId, inplace=True)\n",
    "display(df.head())\n",
    "print(df[colId].value_counts())\n",
    "df.replace({'Not Reviewed': 'NA'}, inplace=True)\n",
    "doc = SimpleDocTemplate(f'{folder}/{file} table.pdf', pagesize=landscape(A3))\n",
    "elements = []\n",
    "i=0\n",
    "for id in df[colId].unique():\n",
    "    i+=1\n",
    "    tableDf = df[df[colId] == id]\n",
    "    name = tableDf[colNameG].values[0] + ' ' + tableDf[colNameF].values[0]\n",
    "    tableDf = tableDf.drop(columns=[colId, colNameG, colNameF])\n",
    "    # drop the row with all mc values as NA\n",
    "    tableDf = tableDf.dropna(subset=mcCols, how='all') \n",
    "    table = createTable(tableDf, f'{id} ({name})', [3] + [1]*len(mcCols), 0.9, [0], tableTextStyle, 12, 12, True)\n",
    "    elements.append(table)\n",
    "    if i % 4 == 0:\n",
    "        elements.append(PageBreak())\n",
    "mcrefTable = addMCReferenceTable(mcrefDf, Paragraph('Marking Checklist Reference', subheadingStyle))\n",
    "elements.insert(0, mcrefTable)\n",
    "elements.insert(1, PageBreak())\n",
    "doc.build(elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOH3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH3\\\\25-08-2004\\\\BOH3 Viva Voce Assessment 2024_August 25, 2024_03.48.xlsx'\n",
    "\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df =pd.read_excel(workbookpath, sheet_name='Sheet0')\n",
    "df = df[1:]\n",
    "# for i, col in enumerate(df.columns):\n",
    "#     print(i, col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcCols = df.columns.to_list()[23:80] + df.columns.to_list()[81:107]\n",
    "print(mcCols)\n",
    "# Fill the nan values with No\n",
    "df[mcCols] = df[mcCols].fillna('No')\n",
    "# Create a dictionary to hold the total scores for each section\n",
    "section_scores = {}\n",
    "section_cols ={}\n",
    "notnancols = []\n",
    "nancols = []\n",
    "def calculateSectionScore(new_df, section_scores):\n",
    "    nulldf = pd.DataFrame(columns=['Col', colId, colSupervisorChoice])\n",
    "    # Identify sections and calculate the sum of columns for each section\n",
    "    for col in new_df.columns:\n",
    "        if col.startswith('Q'):\n",
    "            section = col.split('.')[0]  # Get the section name (e.g., Q1, Q2)\n",
    "            if section not in section_scores:\n",
    "                section_cols[section] = [col]\n",
    "                # Initialize with the column values, filling NaNs with 0\n",
    "                section_scores[section] = new_df[col].fillna(0)\n",
    "            else:\n",
    "                # Add the column values, filling NaNs with 0\n",
    "                section_scores[section] += new_df[col].fillna(0)\n",
    "                section_cols[section].append(colnamedict[col])\n",
    "    \n",
    "\n",
    "    # Add new columns to the DataFrame for each section's total score, sorting the keys first\n",
    "    for key in sorted(section_scores.keys()):\n",
    "        new_df[f'{key}_Total'] = section_scores[key]\n",
    "    \n",
    "    # for key in sorted(section_cols.keys()):\n",
    "    #     new_df[f'{key}_Not_Nan'] = new_df[section_cols[key]].notna().sum(axis=1)\n",
    "    #     notnancols.append(f'{key}_Not_Nan')\n",
    "\n",
    "    # for key in sorted(section_cols.keys()):\n",
    "    #     new_df[f'{key}_Nan'] = new_df[section_cols[key]].isna().sum(axis=1)\n",
    "    #     nancols.append(f'{key}_Nan')\n",
    "    \n",
    "    # # For Na values, print(col, colId, colSupervisorChoice)\n",
    "    # for i, row in new_df.iterrows():\n",
    "    #     for key, cols in section_cols.items():\n",
    "    #         for col in cols:\n",
    "    #             if pd.isna(row[col]):\n",
    "    #                 print(col, row[colId], row[colSupervisorChoice])\n",
    "    #                 newrow = pd.DataFrame([[col, row[colId], row[colSupervisorChoice]]], columns=['Col', colId, colSupervisorChoice])\n",
    "    #                 nulldf = pd.concat([nulldf, newrow], ignore_index=True)\n",
    "    # nulldf.to_excel(f'{folder}/{file} nulls.xlsx', index=False)\n",
    "    return new_df\n",
    "\n",
    "# List the columns for sections 1-5 and 6-7\n",
    "sections_1_5_columns = [\n",
    "    'Q1.#1_1', 'Q1.#1_2', 'Q1.#1_3', 'Q1.#1_4', 'Q1.#1_5', 'Q1.#1_6', 'Q1.#1_7', 'Q1.#1_8',\n",
    "    'Q2.#1_1', 'Q2.#1_2', 'Q2.#1_3', 'Q2.#1_4', 'Q2.#1_5', 'Q2.#1_6', 'Q2.#1_7', 'Q2.#1_8', 'Q2.#1_9', 'Q2.#1_10',\n",
    "    'Q3.#1_1', 'Q3.#1_2', 'Q3.#1_3', 'Q3.#1_4', 'Q3.#1_5', 'Q3.#1_6', 'Q3.#1_7', 'Q3.#1_8', 'Q3.#1_9',\n",
    "    'Q4.#1_1', 'Q4.#1_2', 'Q4.#1_3', 'Q4.#1_4', 'Q4.#1_5', 'Q4.#1_6', 'Q4.#1_7', 'Q4.#1_8', 'Q4.#1_9', 'Q4.#1_10', 'Q4.#1_11', 'Q4.#1_12',\n",
    "    'Q5.#1_1', 'Q5.#1_2', 'Q5.#1_3', 'Q5.#1_4', 'Q5.#1_5', 'Q5.#1_6', 'Q5.#1_7', 'Q5.#1_8', 'Q5.#1_9', 'Q5.#1_10', 'Q5.#1_11', 'Q5.#1_12', 'Q5.#1_13',\n",
    "    'Q5.#1_14', 'Q5.#1_15', 'Q5.#1_16', 'Q5.#1_17', 'Q5.#1_18'\n",
    "]\n",
    "\n",
    "sections_6_7_columns = [\n",
    "    'Q6.#1_1', 'Q6.#1_2', 'Q6.#1_3', 'Q6.#1_4', 'Q6.#1_5', 'Q6.#1_6', 'Q6.#1_7', 'Q6.#1_8', 'Q6.#1_9', 'Q6.#1_10', 'Q6.#1_11', 'Q6.#1_12', 'Q6.#1_13',\n",
    "    'Q7.#1_1', 'Q7.#1_2', 'Q7.#1_3', 'Q7.#1_4', 'Q7.#1_5', 'Q7.#1_6', 'Q7.#1_7', 'Q7.#1_8', 'Q7.#1_9', 'Q7.#1_10', 'Q7.#1_11', 'Q7.#1_12', 'Q7.#1_13'\n",
    "]\n",
    "\n",
    "# Calculate the maximum possible scores for sections 1-5 and 6-7\n",
    "max_score_1_5 = len(sections_1_5_columns)\n",
    "max_score_6_7 = len(sections_6_7_columns)\n",
    "rubricQues = variableUtils.rubricQues.copy()\n",
    "rubricQues.remove('TS')\n",
    "print(rubricQues)\n",
    "df = convertRubricScale(df, rubricQues)\n",
    "colComments = ['Comments for this section 1', 'Comments for this section 2']\n",
    "for col in colComments:\n",
    "    df[col] = df[col].fillna(' ')\n",
    "dfGuttman = convertToGuttman(df, colId, colDate, rubricQues, workbookpath, 'Sheet1', colCE, mcCols, colComments)\n",
    "dfTemp = aggregator(dfGuttman, mcCols, None, None, colComments)\n",
    "dfBest = convertToGuttman(dfTemp, colId, colDate, rubricQues, f'{folder}/{file} best.xlsx', 'Sheet1', colCE, mcCols, colComments)\n",
    "calculateSectionScore(dfGuttman, {})\n",
    "saveDf(dfGuttman, f'{folder}/{file} guttman.xlsx', 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfGuttman['1_5_Total'] = dfGuttman[['Q1_Total', 'Q2_Total', 'Q3_Total', 'Q4_Total', 'Q5_Total']].sum(axis=1)\n",
    "dfGuttman['6_7_Total'] = dfGuttman[['Q6_Total', 'Q7_Total']].sum(axis=1)\n",
    "dfGuttman['1_5_Normalized'] = dfGuttman['1_5_Total'] / max_score_1_5\n",
    "dfGuttman['6_7_Normalized'] = dfGuttman['6_7_Total'] / max_score_6_7\n",
    "dfGuttman['Rubric Weighted Score'] = (dfGuttman['PS']/2*0.05 + dfGuttman['CS']/4*0.1 + dfGuttman['ES']/4*0.1)/0.25\n",
    "saveDf(dfGuttman, f'{folder}/{file} guttman.xlsx', 'Sheet1', len(mcCols) + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a average df with average for each student id\n",
    "def aggregator(dfGuttman, mcCols, colCE=None, colCEReason=None, colComments: list = None):\n",
    "    print(\"\\nAggregating data...\")\n",
    "    aggFuncs = {col: 'first' for col in dfGuttman.columns if col not in mcCols + rubricQues}\n",
    "    aggFuncs.update({col: custom_agg for col in mcCols})\n",
    "    aggFuncs.update({col: 'max' for col in rubricQues})\n",
    "    matching_columns = [col for col in dfGuttman.columns if any(pattern in col for pattern in newRubricQuesPatterns)]\n",
    "    aggFuncs.update({col: 'max' for col in matching_columns})\n",
    "    if colCE is not None:\n",
    "        aggFuncs.update({colCE: lambda x: 'Yes' if 'Yes' in x.values else 'No'})\n",
    "    if colCEReason is not None:\n",
    "        aggFuncs.update({colCEReason: lambda x: ', '.join(x.values).strip(' ,')})\n",
    "    if colComments is not None:\n",
    "        for col in colComments:\n",
    "            aggFuncs.update({col: lambda x: '\\n\\n '.join(x.values).strip(' \\n')})\n",
    "    aggFuncs.update({'1_5_Normalized': 'mean', '6_7_Normalized': 'mean', 'Rubric Weighted Score': 'mean'})\n",
    "    dfTemp = dfGuttman.groupby([colId], as_index=False).agg(aggFuncs)  # aggregate the data\n",
    "    dfTemp = dfTemp.reindex(columns=dfGuttman.columns, fill_value=None)  # reindex the columns\n",
    "    return dfTemp\n",
    "\n",
    "dfTemp = aggregator(dfGuttman, mcCols, None, None, colComments)\n",
    "dfTemp[\"Total Score\"] = (dfTemp['1_5_Normalized']*0.5 + dfTemp['6_7_Normalized']*0.15 + dfTemp['Rubric Weighted Score']*0.35).apply(lambda x: round(x*100, 2))\n",
    "dfTemp[\"1_5_Normalized\"] = dfTemp[\"1_5_Normalized\"].apply(lambda x: round(x, 2))\n",
    "dfTemp[\"6_7_Normalized\"] = dfTemp[\"6_7_Normalized\"].apply(lambda x: round(x, 2))\n",
    "dfTemp.sort_values(by='Total Score', ascending=False, inplace=True)\n",
    "saveDf(dfTemp, f'{folder}/{file} average.xlsx', 'Sheet1', len(mcCols) + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBlank = 'Not Filled'\n",
    "otherCols = [colDate, colSupervisorChoice]\n",
    "labelRubric = 'Rubric Weighted Score'\n",
    "dfTemplate = pd.DataFrame(columns=[colId, 'Yes', 'No', 'Not Reviewed', labelBlank, 'Total MC items'] + rubricQues + ['MC Score', labelRubric] + otherCols +['Total Score'])\n",
    "notReviewedW = 0.5\n",
    "rubricW = {'PS': 0.1, 'CS': 0.1, 'TS': 0.0, 'ES': 0.1} # This is simulation thus professionalism and communication are reduced weighted\n",
    "rubricDenom = {'PS': 2, 'CS': 4, 'TS': 0, 'ES': 4}\n",
    "mcScoreW = 0.65\n",
    "rubricScoreW = 0.35\n",
    "\n",
    "# plot a bar chart of average scores\n",
    "def plotAverageScores(df):\n",
    "    average_scores = df.groupby(colSupervisorChoice)['Total Score'].mean().reset_index()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='CE Name', y='Total Score', data=average_scores)\n",
    "    plt.title(f'Average Scores for examiners')\n",
    "    plt.xlabel('Examiner')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f'{folder}/Average Scores.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = getPairCounts(df)\n",
    "pairs_df.to_excel(f'{folder}/{file} pairs.xlsx', index=False)\n",
    "\n",
    "def getTotals(df, key):\n",
    "    print(key)\n",
    "    code = key.split('_')[0]\n",
    "    df[colId] = df[colId].astype('Int64', errors='ignore')\n",
    "    # df = df[df[colFinished] == 'True']\n",
    "\n",
    "    mcColumns = [col for col in df.columns if '#' in col]\n",
    "    print(mcColumns)\n",
    "    print(df[colId].value_counts())\n",
    "    display(df[mcColumns].head())\n",
    "\n",
    "    countsDf = dfTemplate.copy()\n",
    "    countsDf[colId] = df[colId]\n",
    "    countsDf['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['Total MC items'] = len(mcColumns)\n",
    "    \n",
    "    for q in rubricQues:\n",
    "        countsDf[q] = df[q]\n",
    "    for col in otherCols:\n",
    "        if col in df.columns:\n",
    "            countsDf[col] = df[col]\n",
    "\n",
    "    countsDf['MC Score'] = (countsDf['Yes'] + notReviewedW*countsDf['Not Reviewed']) / (countsDf['Yes'] + countsDf['No'] + notReviewedW*countsDf['Not Reviewed'])\n",
    "    countsDf['MC Score'] = countsDf['MC Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    display(countsDf.head())\n",
    "    \n",
    "    # display(countsDf[rubricQues])\n",
    "    countsDf[labelRubric] = countsDf.apply(lambda row: sum(row[ques] * rubricW[ques] / rubricDenom[ques] for ques in rubricQues), axis=1)/0.3\n",
    "    countsDf[labelRubric] = countsDf[labelRubric].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    # countsDf['ES Weighted Score'] = countsDf['ES']/ rubricDenom['ES']\n",
    "    # countsDf['ES Weighted Score'] = countsDf['ES Weighted Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf['Total Score'] = (mcScoreW*countsDf['MC Score'] + rubricScoreW*countsDf[labelRubric])*100\n",
    "    countsDf['Total Score'] = countsDf['Total Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    # get counts of each CE Name\n",
    "    counts = df['CE Name'].value_counts().reset_index()\n",
    "    counts.columns = ['CE Name', 'Count']\n",
    "    display(counts)\n",
    "\n",
    "    countsDf.to_excel(f'{folder}/{file} marks.xlsx', index=False, sheet_name=key)\n",
    "    return countsDf\n",
    "\n",
    "countsDf = getTotals(dfBest, 'Sheet1')\n",
    "# plotAverageScores(countsDf)\n",
    "# if a column is not in dfBest and in countsDf, then add it to dfBest\n",
    "for col in countsDf.columns:\n",
    "    if col not in dfBest.columns:\n",
    "        dfBest[col] = countsDf[col]\n",
    "\n",
    "saveDf(dfBest, f'{folder}/{file} best.xlsx', 'Sheet1')\n",
    "\n",
    "countsDf2 = getTotals(dfGuttman, 'Sheet2')\n",
    "plotAverageScores(countsDf2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the uploaded Excel file\n",
    "new_file_path = 'BOH3\\\\25-08-2004/BOH3 Viva Voce Assessment 2024_August 25, 2024_03.48 best guttman.xlsx'\n",
    "new_data = pd.read_excel(new_file_path, sheet_name=None)\n",
    "\n",
    "# Load the data from the first sheet\n",
    "new_df = new_data['Sheet1']\n",
    "\n",
    "# Display the first few rows to understand its structure and identify columns\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns related to each section (Q1, Q2, etc.) and calculate scores for each section\n",
    "# We'll create new columns to store the sum of scores for each section\n",
    "\n",
    "# Create a dictionary to hold the total scores for each section\n",
    "section_scores = {}\n",
    "\n",
    "# Identify sections and calculate the sum of columns for each section\n",
    "for col in new_df.columns:\n",
    "    if col.startswith('Q'):\n",
    "        section = col.split('.')[0]  # Get the section name (e.g., Q1, Q2)\n",
    "        if section not in section_scores:\n",
    "            section_scores[section] = new_df[col]\n",
    "        else:\n",
    "            section_scores[section] += new_df[col]\n",
    "\n",
    "# Add new columns to the DataFrame for each section's total score\n",
    "for section, scores in section_scores.items():\n",
    "    new_df[f'{section}_Total'] = scores\n",
    "\n",
    "# Display the new columns with section totals\n",
    "new_df[[f'{section}_Total' for section in section_scores.keys()]]\n",
    "# Save the updated DataFrame to a new Excel file\n",
    "new_df.to_excel(new_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOH1 Sim perio assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookpath = 'BOH1\\BOH1 Periodontics Sim Assessment_August 19, 2024_22.25.xlsx'\n",
    "folder, file, ext = getFolderandFileName(workbookpath)\n",
    "df = pd.read_excel(workbookpath, sheet_name='Sheet0')\n",
    "df = df[1:]\n",
    "studentList = getStudentList()\n",
    "df[colId] = df[colId].astype(int)\n",
    "df = df[df[colId].isin(studentList)]\n",
    "display(df.head())\n",
    "df[colCEReason] = df[colCEReason].fillna(' ')\n",
    "df[colCEReason] = df[colCEReason].astype(str)\n",
    "rubricQues = variableUtils.rubricQues.copy()\n",
    "rubricQues.remove('CS')\n",
    "rubricQues.remove('TS')\n",
    "print(rubricQues)\n",
    "mcCols221 = findMCColumns(df, '221')\n",
    "mcCols222Site = findMCColumns(df, '222', None, 'SITE SPECIFICS')\n",
    "mcCols222Univerals = findMCColumns(df, '222', None, 'UNIVERSALS')\n",
    "print(mcCols221)\n",
    "print(mcCols222Site)\n",
    "print(mcCols222Univerals)\n",
    "mcCols = mcCols221 + mcCols222Site + mcCols222Univerals\n",
    "df = convertRubricScale(df, rubricQues)\n",
    "dfGuttman = convertToGuttman(df, colId, colDate, rubricQues, workbookpath, 'Sheet1', colCE, mcCols)\n",
    "dfTemp = aggregator(dfGuttman, mcCols, colCE, colCEReason)\n",
    "dfBest = convertToGuttman(dfTemp, colId, colDate, rubricQues, f'{folder}/{file} best.xlsx', 'Sheet1', colCE, mcCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBlank = 'Not Filled'\n",
    "otherCols = [colComplex, colClinicType, colDate, colSupervisorChoice, colFinished, colCE, colCEReason]\n",
    "labelRubric = 'Rubric Weighted Score'\n",
    "dfTemplate = pd.DataFrame(columns=[colId, 'Yes', 'No', 'Not Reviewed', labelBlank, 'Total MC items'] + rubricQues + ['MC Score', labelRubric] + otherCols +['Item', 'Total Score'])\n",
    "notReviewedW = 0.5\n",
    "rubricW = {'PS': 0.15, 'CS': 0.0, 'TS': 0.0, 'ES': 0.15} # This is simulation thus professionalism and communication are reduced weighted\n",
    "rubricDenom = {'PS': 2, 'CS': 4, 'TS': 0, 'ES': 4}\n",
    "mcScoreW = 0.65\n",
    "rubricScoreW = 0.35\n",
    "\n",
    "# plot a bar chart of average scores\n",
    "def plotAverageScores(df):\n",
    "    df = df[df[colFinished] == 'True']\n",
    "    average_scores = df.groupby(colSupervisorChoice)['Total Score'].mean().reset_index()\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='CE Name', y='Total Score', data=average_scores)\n",
    "    plt.title(f'Average Scores for examiners')\n",
    "    plt.xlabel('Examiner')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(f'{folder}/Average Scores.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = getPairCounts(df)\n",
    "pairs_df.to_excel(f'{folder}/{file} pairs.xlsx', index=False)\n",
    "\n",
    "def getTotals(df, key):\n",
    "    print(key)\n",
    "    code = key.split('_')[0]\n",
    "    df[colId] = df[colId].astype('Int64', errors='ignore')\n",
    "    # df = df[df[colFinished] == 'True']\n",
    "    mcColumns = mcCols\n",
    "    print(mcColumns)\n",
    "    print(df[colId].value_counts())\n",
    "    display(df[mcColumns].head())\n",
    "\n",
    "    countsDf = dfTemplate.copy()\n",
    "    countsDf[colId] = df[colId]\n",
    "    countsDf['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['Total MC items'] = len(mcColumns)\n",
    "\n",
    "    countsDf['221 Yes'] = df[mcCols221].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['221 No'] = df[mcCols221].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['221 Not Reviewed'] = df[mcCols221].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf['221 Not Filled'] = df[mcCols221].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['221 Total MC items'] = len(mcCols221)\n",
    "    \n",
    "    countsDf['222 Site Yes'] = df[mcCols222Site].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['222 Site No'] = df[mcCols222Site].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['222 Site Not Reviewed'] = df[mcCols222Site].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf['222 Site Not Filled'] = df[mcCols222Site].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['222 Total Site items'] = len(mcCols222Site)\n",
    "\n",
    "    countsDf['222 Universals Yes'] = df[mcCols222Univerals].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['222 Universals No'] = df[mcCols222Univerals].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['222 Universals Not Reviewed'] = df[mcCols222Univerals].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf['222 Universals Not Filled'] = df[mcCols222Univerals].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['222 Total Universals items'] = len(mcCols222Univerals)\n",
    "    \n",
    "    for q in rubricQues:\n",
    "        countsDf[q] = df[q]\n",
    "    for col in otherCols:\n",
    "        if col in df.columns:\n",
    "            countsDf[col] = df[col]\n",
    "\n",
    "    countsDf['MC Score'] = (countsDf['Yes'] + notReviewedW*countsDf['Not Reviewed']) / (countsDf['Yes'] + countsDf['No'] + notReviewedW*countsDf['Not Reviewed'])\n",
    "    countsDf['MC Score'] = countsDf['MC Score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    countsDf['221 MC Score'] = (countsDf['221 Yes'] + notReviewedW*countsDf['221 Not Reviewed']) / (countsDf['221 Yes'] + countsDf['221 No'] + notReviewedW*countsDf['221 Not Reviewed'])\n",
    "    countsDf['221 MC Score'] = countsDf['221 MC Score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    countsDf['222 Site MC Score'] = (countsDf['222 Site Yes'] + notReviewedW*countsDf['222 Site Not Reviewed']) / (countsDf['222 Site Yes'] + countsDf['222 Site No'] + notReviewedW*countsDf['222 Site Not Reviewed'])\n",
    "    countsDf['222 Site MC Score'] = countsDf['222 Site MC Score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    countsDf['222 Universals MC Score'] = (countsDf['222 Universals Yes'] + notReviewedW*countsDf['222 Universals Not Reviewed']) / (countsDf['222 Universals Yes'] + countsDf['222 Universals No'] + notReviewedW*countsDf['222 Universals Not Reviewed'])\n",
    "    countsDf['222 Universals MC Score'] = countsDf['222 Universals MC Score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    \n",
    "    \n",
    "    display(countsDf.head())\n",
    "    \n",
    "    # display(countsDf[rubricQues])\n",
    "    countsDf[labelRubric] = countsDf.apply(lambda row: sum(row[ques] * rubricW[ques] / rubricDenom[ques] for ques in rubricQues), axis=1)/0.3\n",
    "    countsDf[labelRubric] = countsDf[labelRubric].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    # countsDf['ES Weighted Score'] = countsDf['ES']/ rubricDenom['ES']\n",
    "    # countsDf['ES Weighted Score'] = countsDf['ES Weighted Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf['Total Score'] = (mcScoreW*countsDf['MC Score'] + rubricScoreW*countsDf[labelRubric])*100\n",
    "    countsDf['Total Score'] = countsDf['Total Score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Add 20% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.8 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf['Total Score CE Penalty (20%)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Add 10% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.90 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf['Total Score CE Penalty (10%)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    countsDf['Item'] = key\n",
    "    \n",
    "    \n",
    "    # get counts of each CE Name\n",
    "    counts = df['CE Name'].value_counts().reset_index()\n",
    "    counts.columns = ['CE Name', 'Count']\n",
    "    display(counts)\n",
    "\n",
    "    countsDf.to_excel(f'{folder}/{file} marks.xlsx', index=False)\n",
    "    return countsDf\n",
    "\n",
    "countsDf = getTotals(dfBest, 'Sheet1')\n",
    "# plotAverageScores(countsDf)\n",
    "# if a column is not in dfBest and in countsDf, then add it to dfBest\n",
    "for col in countsDf.columns:\n",
    "    if col not in dfBest.columns:\n",
    "        dfBest[col] = countsDf[col]\n",
    "\n",
    "saveDf(dfBest, f'{folder}/{file} best.xlsx', 'Sheet1')\n",
    "\n",
    "countsDf2 = getTotals(dfGuttman, 'Sheet1')\n",
    "plotAverageScores(countsDf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the pairwise difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Utils import getFolderandFileName\n",
    "\n",
    "# Load the uploaded Excel file\n",
    "file_path = \"BOH3\\\\25-08-2004\\BOH3 Viva Voce Assessment 2024_August 25, 2024_03.48 marks.xlsx\"\n",
    "folder, file, ext = getFolderandFileName(file_path)\n",
    "df = pd.read_excel(file_path)\n",
    "def getSupervisorPairs(dfOriginal, dfBest):\n",
    "    df = dfOriginal.copy()\n",
    "    df.sort_values(by='CE Name', inplace=True)\n",
    "\n",
    "    # Create a new DataFrame to store the differences and supervisor pair information\n",
    "    comparison_data = []\n",
    "\n",
    "    # Group by 'Student ID' to find pairs of rows for the same student\n",
    "    grouped = df.groupby('Student ID')\n",
    "\n",
    "    for student_id, group in grouped:\n",
    "        if len(group) == 2:\n",
    "            supervisor1 = group.iloc[0]['CE Name']\n",
    "            supervisor2 = group.iloc[1]['CE Name'] \n",
    "            yes_diff = group.iloc[0]['Yes'] - group.iloc[1]['Yes']\n",
    "            mc_score_diff = group.iloc[0]['MC Score'] - group.iloc[1]['MC Score']\n",
    "            rubric_weighted_score_diff = group.iloc[0]['Rubric Weighted Score'] - group.iloc[1]['Rubric Weighted Score']\n",
    "            total_score_diff = group.iloc[0]['Total Score'] - group.iloc[1]['Total Score']\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Student ID': student_id,\n",
    "                'Supervisor Pair': f\"[{supervisor1}, {supervisor2}]\",\n",
    "                'Yes Difference': yes_diff,\n",
    "                'MC Score Difference': mc_score_diff,\n",
    "                'Rubric Weighted Score Difference': rubric_weighted_score_diff,\n",
    "                'Total Score Difference': total_score_diff\n",
    "            })\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Sort the DataFrame by 'Total Score Difference' in descending order\n",
    "    comparison_df_sorted = comparison_df.sort_values(by='Total Score Difference', ascending=False)\n",
    "    comparison_df_sorted['Student ID'] = comparison_df_sorted['Student ID'].astype(int)\n",
    "\n",
    "    # Set the color palette\n",
    "    unique_supervisor_pairs = comparison_df_sorted['Supervisor Pair'].unique()\n",
    "    color_palette = plt.cm.get_cmap('tab10', len(unique_supervisor_pairs))\n",
    "    color_dict = {pair: color_palette(i) for i, pair in enumerate(unique_supervisor_pairs)}\n",
    "\n",
    "\n",
    "    # Redefining the plot function to include text for zero values\n",
    "    def plot_integer_bar_chart(df, y_column, title):\n",
    "        sorted_df = df.sort_values(by=y_column, ascending=False)\n",
    "        plt.figure(figsize=(18, 6))\n",
    "        bars = plt.bar(sorted_df['Student ID'].astype(str), sorted_df[y_column], color=[color_dict[pair] for pair in sorted_df['Supervisor Pair']])\n",
    "        \n",
    "        # Add text \"No difference\" where the bar height is zero\n",
    "        for bar, pair in zip(bars, sorted_df['Supervisor Pair']):\n",
    "            if bar.get_height() == 0:\n",
    "                plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.0, 'No difference', ha='center', va='bottom', color=color_dict[pair], rotation=90)\n",
    "        \n",
    "        plt.xlabel('Student ID')\n",
    "        plt.ylabel(y_column)\n",
    "        plt.title(title)\n",
    "        plt.xticks(rotation=90, ha='center')\n",
    "        # show the zero line\n",
    "        plt.axhline(0, color='black', linewidth=0.5)\n",
    "        # Create a legend\n",
    "        handles = [Rectangle((0, 0), 1, 1, color=color_dict[pair]) for pair in unique_supervisor_pairs]\n",
    "        plt.legend(handles, unique_supervisor_pairs, title=\"Supervisor Pairs\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{folder}/{file} {y_column}.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    # Plotting the bar charts with integer Student ID and 90-degree label rotation\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Total Score Difference', 'Total Score Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Yes Difference', 'Yes Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'MC Score Difference', 'MC Score Difference by Student ID')\n",
    "    plot_integer_bar_chart(comparison_df_sorted, 'Rubric Weighted Score Difference', 'Rubric Weighted Score Difference by Student ID')\n",
    "\n",
    "    # Show counts of each pair\n",
    "    pair_counts = comparison_df_sorted['Supervisor Pair'].value_counts().reset_index()\n",
    "    pair_counts.columns = ['Supervisor Pair', 'Count']\n",
    "    display(pair_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For filling the missing supervisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookPath = 'FullSpreadsheets\\CAF+v0.1_December+5,+2024\\CAF v0.1_December 5, 2024.csv'\n",
    "workbookPath2 = 'data\\To anon\\CAF v0.1_September 16, 2024_16.36 filled CE.csv'\n",
    "folder, file, ext = getFolderandFileName(workbookPath2)\n",
    "def readfile(workbookPath2):\n",
    "    folder, file, ext = getFolderandFileName(workbookPath2)\n",
    "    if ext == '.csv':\n",
    "        df2 = pd.read_csv(workbookPath2)\n",
    "    elif ext == '.xlsx':\n",
    "        df2 = pd.read_excel(workbookPath2)\n",
    "    return df2\n",
    "df2 = readfile(workbookPath2)\n",
    "# df = pd.read_csv(workbookPath)\n",
    "df2['CE Name'].value_counts(dropna=False)\n",
    "df1 = pd.read_csv(workbookPath)\n",
    "df1['CE Name'].value_counts(dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder, file, ext = getFolderandFileName(workbookPath)\n",
    "print(f'Loaded {file} from {folder}')\n",
    "# match colResponseId values of df1 and df2 and fill the empty values in colSupervisorChoice in df1 with the values of Q65 in df2\n",
    "for i, row in df1.iterrows():\n",
    "    if pd.isna(row[colSupervisorChoice] or row[colSupervisorChoice] == ''):\n",
    "        matching_row = df2[df2[colResponseId] == row[colResponseId]]\n",
    "        if not matching_row.empty:\n",
    "            print(f\"Found matching row, filling value for {row[colResponseId]} with {matching_row['CE Name'].values[0]}\")\n",
    "            df1.at[i, colSupervisorChoice] = matching_row['CE Name'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1[colSupervisorChoice].value_counts(dropna=False))\n",
    "folder, file, ext = getFolderandFileName(workbookPath)\n",
    "# df1.to_csv(f'{folder}/{file} filled CE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookPath3 = 'data/For Kunal - Choic text CAF v0.1_April 11, 2024_23.09.xlsx'\n",
    "df3 = readfile(workbookPath3)\n",
    "df3['Q65'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df1.iterrows():\n",
    "    if pd.isna(row[colSupervisorChoice]) or (row[colSupervisorChoice] == ''):\n",
    "        matching_row = df3[df3[colResponseId] == row[colResponseId]]\n",
    "        if not matching_row.empty:\n",
    "            print(f\"Found matching row, filling value for {row[colResponseId]} with {matching_row['Q65'].values[0]}\")\n",
    "            df1.at[i, colSupervisorChoice] = matching_row['Q65'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[colSupervisorChoice].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(f'{folder}/{file} filled CE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDfPath = 'FullSpreadsheets\\CAF+v0.1_August+18,+2024\\CAF v0.1_August 18, 2024_19.04 split.xlsx'\n",
    "existingGuttmanPath = 'FullSpreadsheets\\CAF+v0.1_August+18,+2024\\CAF v0.1_August 18, 2024_19.04 guttman.xlsx'\n",
    "existingGuttmanPath = None\n",
    "# guttmancreator.createGuttman(splitDfPath, existingGuttmanPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"Column Rename Dictionary.json\") as json_file:\n",
    "    dict = json.load(json_file)\n",
    "    for i, key in enumerate(dict.keys()):\n",
    "        print(i, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookPath = 'DDS3\\\\Fix Pros\\\\CAF v0.1_August 5, 2024_20.46.xlsx'\n",
    "workbook, folder, file = loadWorkbook(workbookPath)\n",
    "df = loadDfFromSheet(workbook, 'Sheet0')\n",
    "createRenameDict(df)\n",
    "for i, col in enumerate(df.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking which students completed what"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workbookPath = 'DDS2\\\\532 SIM July 29\\\\532 SIM July 29 2024.xlsx'\n",
    "# studentListPath = '2024 MDS Student List_v10.xlsx'\n",
    "# checkAttendence(workbookPath, studentListPath, 'DDS2 (2024)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Creating the Guttman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workbookPath = 'DDS3\\\\Fix Pros\\\\CAF v0.1_August 5, 2024_20.46.xlsx'\n",
    "# datacleaner = DataCleaning(workbookPath)\n",
    "# savepath  = datacleaner.filterOneSheet()\n",
    "# workbookPath = 'DDS2\\\\DENT90115\\\\All Sim Aug 5\\\\DENT90115 All Sim.xlsx'\n",
    "workbookPath = 'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50.xlsx'\n",
    "savePath =  'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50 filtered.xlsx'\n",
    "# savePath = 'DDS2\\\\DENT90115\\\\All Sim Aug 5\\\\DENT90115 All Sim filtered.xlsx'\n",
    "# workbook, folder, filename = loadWorkbook(workbookPath)\n",
    "# df = loadDfFromSheet(workbook, 'Sheet0')\n",
    "# df, renameDict = createRenameDict(df)\n",
    "# printDuplicateValues(renameDict)\n",
    "# check what are duplicate items in renameDict.values\n",
    "# for i, key in enumerate(renameDict.keys()):\n",
    "#     print(i, key, renameDict[key])\n",
    "# df, renameDict = renameColumnsHeader(df, renameDict={}, renameFile = None)\n",
    "\n",
    "# savePath = None\n",
    "# savePath = 'DDS3\\\\Fix Pros\\\\CAF v0.1_August 5, 2024_20.46 filtered.xlsx'\n",
    "guttmancreator = CreateGuttman(savePath, workbookPath)\n",
    "# selectionTupleList = [(colRole, 'Operator')]\n",
    "# guttmancreator.createGuttmanforOneCode([], '532_SIM')\n",
    "\n",
    "# This one if you have already have filtered the data\n",
    "# savePath = 'DDS3/CAF v0.1_July 30, 2024_21.47 filtered.xlsx'\n",
    "# workbookPath = 'DDS3/CAF v0.1_July 30, 2024_21.47.xlsx'\n",
    "# guttmancreator = CreateGuttman(savePath, workbookPath)\n",
    "# selectionTupleList = [(colRole, 'Operator')]\n",
    "# guttmancreator.createGuttman()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get student MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookPath = 'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50.xlsx'\n",
    "df = pd.read_excel(workbookPath, sheet_name='Sheet0')\n",
    "df, renameDictCode = renameColumnsHeader(df)\n",
    "print(renameDictCode)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Column Rename Dictionary.json\", \"w\") as outfile:\n",
    "    json.dump(renameDictCode, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codeCols = [col for col in df.columns if '_supervisor' in col]\n",
    "# create a dictionary of code columns with the first row value\n",
    "MCreferenceDict = {}\n",
    "for col in codeCols:\n",
    "    textlabel = df[col].iloc[0]\n",
    "    textlabel2 = (textlabel.split(' - ')[-1]).strip()\n",
    "    print(col, textlabel, textlabel2)\n",
    "    MCreferenceDict[col] = textlabel2\n",
    "MCreferenceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MC Reference Dictionary.json\", \"w\") as outfile:\n",
    "    json.dump(MCreferenceDict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDfPath = 'FullSpreadsheets\\\\CAF+v0.1_August+6,+2024\\\\CAF v0.1_August 6, 2024_00.50 split.xlsx'\n",
    "guttmancreator.createGuttman(splitDfPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have only one code in the sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookPath = 'FullSpreadsheets\\\\532 SIM\\\\532 SIM Aug 2.xlsx'\n",
    "cleaner = DataCleaning(workbookPath)\n",
    "savePath = cleaner.filterOneSheet()\n",
    "workbook, folder, filename = loadWorkbook(savePath)\n",
    "df = loadDfFromSheet(workbook, 'Sheet1')\n",
    "df = mergeColumns(df, [([colSupervisorChoice, colSupervisorOther], colSupervisor)])\n",
    "df = convertRubricScale(df, rubricQues)\n",
    "convertToGuttman(df, colId, colDate, rubricQues, savePath, '532_SIM', colCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookPath = 'DDS2\\\\DDS2 532 SIM- July 29.xlsx'\n",
    "workbookPath = 'DDS2\\\\DENT90115\\\\All Sim Aug 2\\\\CAF v0.1_August 1, 2024_16.06.xlsx'\n",
    "# workbook, folder, filename = loadWorkbook(workbookPath)\n",
    "# df = loadDfFromSheet(workbook, 'Sheet0')\n",
    "# createRenameDict(df)\n",
    "cleaner = DataCleaning(workbookPath)\n",
    "savePath = cleaner.filterOneSheet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePath = 'DDS2\\\\DENT90115\\\\Fixed Pros Sim Aug 2 filtered.xlsx'\n",
    "workbookPath = 'DDS2\\DENT90115\\\\Fixed Pros Sim Aug 2.xlsx'\n",
    "\n",
    "folder, fileName, ext = getFolderandFileName(savePath)\n",
    "workbook, folder, fileName = loadWorkbook(savePath)\n",
    "df_ = loadDfFromSheet(workbook, sheetName='Sheet1') # load the first sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name all columns appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_.copy()\n",
    "df = mergeColumns(df, serviceColMerge) # merge columns and the supervisor columns\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['416_MC11_supervisor (CLINIC)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[colId] = df[colId].astype('Int64')\n",
    "df[colDate] = pd.to_datetime(df[colDate]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def drop_empty_supervisor_id_rows(df):\n",
    "#     # Replace empty strings with NaN to ensure they are treated as missing values\n",
    "#     df['Supervisor signature - Id'].replace('', pd.NA, inplace=True)\n",
    "#     # Drop rows where 'Supervisor signature - Id' is NaN\n",
    "#     df.dropna(subset=['Supervisor signature - Id'], inplace=True)\n",
    "#     return df\n",
    "\n",
    "# def find_mc_columns(df, code=None, role=None):\n",
    "#     # Regex pattern to match 'MC' followed by a digit, specific code, and role\n",
    "#     if code is None and role is None:\n",
    "#         pattern = r'MC\\d+'\n",
    "#     elif code is None:\n",
    "#         pattern = rf'MC\\d+_{role}'\n",
    "#     elif role is None:\n",
    "#         pattern = rf'{code}_MC\\d+'\n",
    "#     else:\n",
    "#         pattern = rf'{code}_MC\\d+_{role}'\n",
    "    \n",
    "#     # Filter columns using the regex pattern\n",
    "#     matched_columns = [col for col in df.columns if re.search(pattern, col)]\n",
    "    \n",
    "#     return matched_columns\n",
    "\n",
    "# mc_columns = find_mc_columns(df)\n",
    "# pprint(mc_columns)\n",
    "\n",
    "# def extract_restorative_codes(service_str, location):\n",
    "#     # print(service_str)\n",
    "#     if pd.isna(service_str):\n",
    "#         return []\n",
    "    \n",
    "#     if location == 'Simulation':\n",
    "#         location = 'SIM'\n",
    "#     else:\n",
    "#         location = 'CLINIC'\n",
    "#     # Extract only codes\n",
    "#     code = re.findall(r'\\b(\\d+)\\b', service_str)\n",
    "#     codes = [(c, location) for c in code if len(c) > 2]\n",
    "#     return codes\n",
    "\n",
    "# def extractGeneralServiceCode(serviceStr):\n",
    "#     if pd.isna(serviceStr):\n",
    "#         return []\n",
    "    \n",
    "#     # Regular expression to extract the code and location\n",
    "#     pattern = r'(\\b[A-Z]+\\b).*?\\((.*?)\\)'\n",
    "#     matches = re.findall(pattern, serviceStr)\n",
    "    \n",
    "#     return matches\n",
    "\n",
    "\n",
    "# def split_df_by_codes(df):\n",
    "#     code_dict = {}\n",
    "#     # Iterate over each row in the DataFrame\n",
    "#     for idx, row in df.iterrows():\n",
    "#         # Get codes from 'Restorative Services'\n",
    "#         # print(idx)\n",
    "#         allCodes = []\n",
    "#         for col in serviceCols:\n",
    "#             allCodes += extract_restorative_codes(row[col], row[colClinicChoice])\n",
    "        \n",
    "#         general_codes = extractGeneralServiceCode(row[colServiceGeneral])\n",
    "#         allCodes += general_codes\n",
    "\n",
    "#         # diagnostic_codes = extract_restorative_codes(row['Diagnostic Services'], row['Clinic Location - Selected Choice'])\n",
    "#         # restorative_codes = extract_restorative_codes(row['Restorative Services'], row['Clinic Location - Selected Choice'])\n",
    "#         # # print(restorative_codes)\n",
    "#         # preventive_codes = extract_restorative_codes(row['Preventive, Prophylactic and Bleaching Services'], row['Clinic Location - Selected Choice'])\n",
    "#         # # print(row['Preventive, Prophylactic and Bleaching Services'], preventive_codes)\n",
    "#         # periodontal_codes = extract_restorative_codes(row['Periodontics'], row['Clinic Location - Selected Choice'])\n",
    "#         # endodontic_codes = extract_restorative_codes(row['Endodontics'], row['Clinic Location - Selected Choice'])\n",
    "#         # # Handle 'General Services', assume only 'LA' as a code right now\n",
    "#         # general_codes = [('LA', None)] if 'LA' in str(row['General Services']) else []\n",
    "\n",
    "#         # # Combine and process all codes\n",
    "#         # all_codes = diagnostic_codes + restorative_codes + preventive_codes + general_codes + periodontal_codes + endodontic_codes \n",
    "#         print(allCodes)\n",
    "#         for code_tuple in allCodes:\n",
    "#             code = code_tuple[0]\n",
    "#             modifier = code_tuple[1] if len(code_tuple) > 1 else None\n",
    "#             key = f\"{code}_{modifier}\" if modifier else code  # Create a key like '533_CLINIC' or 'LA'\n",
    "\n",
    "#             if key not in code_dict:\n",
    "#                 code_dict[key] = []\n",
    "#             code_dict[key].append(idx)\n",
    "    \n",
    "    \n",
    "#     # pprint(code_dict)\n",
    "\n",
    "    \n",
    "#     # Create a DataFrame for each code\n",
    "#     # Filtering columns for each specific code\n",
    "#     for key in code_dict:\n",
    "#         code, modifier = key.split('_') if '_' in key else (key, None)\n",
    "#         # print(code, modifier)\n",
    "#         # if code!='011':\n",
    "#         #     continue\n",
    "#         relevant_columns = []\n",
    "#         for col in mc_columns:\n",
    "#             if code in col:\n",
    "#                 print(f'Code found in {col}')\n",
    "#                 # if '(SIM)' in col or '(CLINIC)' in col or '(Infiltration)' in col or '(Block)' in col: # check for modifier only if SIM or CLINIC is present\n",
    "#                 if '(' in col:\n",
    "#                     print(f'Modifier found in {col}')\n",
    "#                     if modifier in col:\n",
    "#                         relevant_columns.append(colnamedict[col])\n",
    "#                 else:\n",
    "#                     relevant_columns.append(colnamedict[col])\n",
    "#         # relevant_columns = [col for col in mc_columns if code in col and \n",
    "#         #                     ((f\"({modifier})\" in col) or (not modifier and '(' not in col))]\n",
    "#         # Add non-MC, non-subject-specific columns\n",
    "#         general_columns = [col for col in df.columns if col not in mc_columns and col not in rubricQues]\n",
    "#         # Combine relevant subject columns and general columns\n",
    "#         selected_columns = beforeCols + relevant_columns + rubricQues + afterCols\n",
    "#         # Create a DataFrame for each code using selected columns\n",
    "#         code_dict[key] = df.loc[code_dict[key], selected_columns].copy()\n",
    "    \n",
    "#     code_dict['All'] = df[beforeCols + mc_columns + rubricQues + afterCols]\n",
    "\n",
    "#     for key, dftest in code_dict.items():\n",
    "#         for col in rubricQues:\n",
    "#             dftest[col] = dftest[col].str.extract(r'Lvl (\\d+)')[0]\n",
    "#             dftest[col] = pd.to_numeric(dftest[col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "#     return code_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data per code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_columns = findMCColumns(df)\n",
    "pprint(mc_columns)\n",
    "\n",
    "x= df.copy()\n",
    "x = getDfbyColumnValue(x, colRole, 'Operator')\n",
    "codesDf, rubricQues = splitDfByCodes(x, serviceCols, colClinicChoice, colServiceGeneral, beforeCols, mc_columns, rubricQues, afterCols)\n",
    "pprint(codesDf.keys())\n",
    "codesDf.pop('All')\n",
    "pprint(rubricQues)\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, x in codesDf.items():\n",
    "    # if key != 'LA_Infiltration':\n",
    "    #     continue\n",
    "    print('\\n', key)\n",
    "    x.columns = x.columns.str.strip()\n",
    "    # for col in x.columns:\n",
    "    #     print(col)\n",
    "    \n",
    "    convertToGuttman(x, colId, colDate, rubricQues, workbookPath, key, colCE) # convert to guttman format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Age summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming df is your DataFrame and colSubject and colAge are your column names\n",
    "# colSubject = 'Subject'\n",
    "# colAge = 'Patient Age (Please provide age in numbers only)'\n",
    "\n",
    "# # Filter the DataFrame by subjects\n",
    "# oral30002 = df[df[colSubject] == 'ORAL30002']\n",
    "# oral20005 = df[df[colSubject] == 'ORAL20005']\n",
    "\n",
    "# # Define age categories\n",
    "# def categorize_age(age):\n",
    "#     if age <= 6:\n",
    "#         return '0-6'\n",
    "#     elif age <= 12:\n",
    "#         return '7-12'\n",
    "#     elif age <= 18:\n",
    "#         return '13-18'\n",
    "#     else:\n",
    "#         return '18+'\n",
    "\n",
    "# # Apply the categorization\n",
    "# oral30002['Age Category'] = oral30002[colAge].apply(categorize_age)\n",
    "# oral20005['Age Category'] = oral20005[colAge].apply(categorize_age)\n",
    "\n",
    "# # Count the ages in each category\n",
    "# age_counts_oral30002 = oral30002['Age Category'].value_counts().reindex(['0-6', '7-12', '13-18', '18+'], fill_value=0)\n",
    "# age_counts_oral20005 = oral20005['Age Category'].value_counts().reindex(['0-6', '7-12', '13-18', '18+'], fill_value=0)\n",
    "\n",
    "\n",
    "# # Define custom bins for the histogram\n",
    "# bins = [i for i in range(0, 100, 5)]\n",
    "\n",
    "# # Plot the histograms for age distribution\n",
    "# fig2, axes2 = plt.subplots(nrows=1, ncols=2, figsize=(14, 7))\n",
    "\n",
    "# # Histogram for ORAL30002\n",
    "# oral30002[colAge].plot(kind='hist', bins=bins, ax=axes2[0], color='skyblue', edgecolor='black')\n",
    "# axes2[0].set_title('Age distribution for ORAL30002')\n",
    "# axes2[0].set_xlabel('Age')\n",
    "# axes2[0].set_xticks(bins)\n",
    "# axes2[0].set_ylabel('Frequency')\n",
    "\n",
    "# # Histogram for ORAL20005\n",
    "# oral20005[colAge].plot(kind='hist', bins=bins, ax=axes2[1], color='salmon', edgecolor='black')\n",
    "# axes2[1].set_title('Age distribution for ORAL20005')\n",
    "# axes2[1].set_xlabel('Age')\n",
    "# axes2[1].set_xticks(bins)\n",
    "# axes2[1].set_ylabel('Frequency')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# studentIds = df[colId].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the total NA, missing and Importance etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the workbook path\n",
    "workbookPath = 'FullSpreadsheets/CAF+v0.1_August+6,+2024/CAF v0.1_August 6, 2024_00.50 guttman.xlsx'\n",
    "savefolder, file = os.path.split(workbookPath)\n",
    "workbook = openpyxl.load_workbook(workbookPath, data_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each sheet\n",
    "for sheet_name in workbook.sheetnames:\n",
    "    irtFolder = 'FullSpreadsheets\\\\IRT'\n",
    "    os.makedirs(irtFolder, exist_ok=True)\n",
    "    print(f\"Processing sheet: {sheet_name}\")\n",
    "    code = sheet_name.split('_')[0]\n",
    "    if code!='524' and code!='532':\n",
    "        continue\n",
    "    role = sheet_name.split('_')[1]\n",
    "    # Load the sheet into a DataFrame\n",
    "    df = pd.read_excel(workbookPath, sheet_name=sheet_name, keep_default_na=False)\n",
    "    cohorts = df[colCohort].unique()\n",
    "    for cohort in cohorts:\n",
    "        getImportance(df, code, role, irtFolder, cohort)\n",
    "    getImportance(df, code, role, irtFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "\n",
    "# Define the file path and load the workbook\n",
    "workbook_path = 'DDS2\\\\DENT90115\\\\All Sim Aug 5\\\\DENT90115 All Sim guttman.xlsx'\n",
    "savefolder, file = os.path.split(workbook_path)\n",
    "workbook = openpyxl.load_workbook(workbook_path, data_only=True)\n",
    "\n",
    "# Define the columns and their corresponding labels\n",
    "columns_labels = {\n",
    "    'PS': 'Professionalism',\n",
    "    'CS': 'Communication',\n",
    "    'TS': 'Time Management',\n",
    "    'ES': 'Entrustment'\n",
    "}\n",
    "\n",
    "# Process each sheet\n",
    "for sheet_name in workbook.sheetnames:\n",
    "\n",
    "    folderPath = f'{savefolder}/rubric plots'\n",
    "    os.makedirs(folderPath, exist_ok=True)\n",
    "    print(f\"Processing sheet: {sheet_name}\")\n",
    "    code = sheet_name.split('_')[0]\n",
    "    role = sheet_name.split('_')[1]\n",
    " \n",
    "    # Load the sheet into a DataFrame without interpreting NA as NaN\n",
    "    df = pd.read_excel(workbook_path, sheet_name=sheet_name, keep_default_na=False)\n",
    "    \n",
    "    # Remove rows with NaN in 'Student ID'\n",
    "    df = df.dropna(subset=['Student ID'])\n",
    "    df = df[df['Student ID'] != '']\n",
    "    df['Student ID'] = df['Student ID'].astype('Int64').astype(str)\n",
    "    \n",
    "    # Create a DataFrame to store the counts for each student\n",
    "    counts_df = pd.DataFrame(index=df.index, columns=list(columns_labels.keys()))\n",
    "\n",
    "    # Count the values for each student in the specific columns\n",
    "    for col in columns_labels.keys():\n",
    "        counts_df[col] = df[col]\n",
    "\n",
    "    counts_df['Student ID'] = df['Student ID']\n",
    "\n",
    "    # Plot the grouped bar chart\n",
    "\n",
    "    if len(counts_df) < 8:\n",
    "        fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    elif len(counts_df)< 16:\n",
    "        fig, ax = plt.subplots(figsize=(32, 8))\n",
    "\n",
    "    elif len(counts_df)< 32:\n",
    "        fig, ax = plt.subplots(figsize=(64, 8))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(84, 8))\n",
    "    \n",
    "    bar_width = 0.2\n",
    "    x = range(len(counts_df))\n",
    "\n",
    "    for i, (col, label) in enumerate(columns_labels.items()):\n",
    "        ax.bar([pos + i * bar_width for pos in x], counts_df[col], width=bar_width, label=label, edgecolor='black')\n",
    "\n",
    "    ax.set_xlabel('Student ID')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(f'Rubric Chart for {code} ({role})')\n",
    "    ax.set_xticks([pos + bar_width for pos in x])\n",
    "    ax.set_xticklabels(counts_df['Student ID'], rotation=90)\n",
    "    ax.legend(title='Categories')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "    plt.savefig(f'{folderPath}/{sheet_name}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort wise Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "from variableUtils import *\n",
    "from Utils import *\n",
    "from ClassUtils import *\n",
    "from pprint import pprint\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookPath = 'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50.xlsx'\n",
    "savePath =  'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50 filtered.xlsx'\n",
    "guttmanPath = 'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50 guttman.xlsx'\n",
    "workbook, folder, file = loadWorkbook(guttmanPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data for each student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentidname_dict = {}\n",
    "unique_ids = df['Student ID'].unique()\n",
    "for id in unique_ids:\n",
    "    studentidname_dict[id] = df[df['Student ID'] == id][colNameF].values[0] + ' ' + df[df['Student ID'] == id][colNameG].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectSet = set()\n",
    "def splitByStudent(df):\n",
    "    student_dict = {}\n",
    "    unique_ids = df[colId].unique()  # Get all unique student IDs\n",
    "    # remove na\n",
    "    unique_ids = unique_ids[~pd.isna(unique_ids)]\n",
    "    for student_id in unique_ids:\n",
    "        # print(f'\\n{student_id}')\n",
    "        # if student_id != 1081376:\n",
    "        #     continue\n",
    "        if pd.isna(student_id):\n",
    "            continue\n",
    "        subject_dict = {}\n",
    "        student_df = df[df[colId] == student_id]  # Filter the DataFrame for each student ID\n",
    "        # print(student_df['Preventive, Prophylactic and Bleaching Services'])\n",
    "        subjects = student_df[colSubject].unique()\n",
    "        for subject in subjects:\n",
    "            if pd.isna(subject):\n",
    "                continue\n",
    "            # print(subject)\n",
    "            subjectSet.add(subject)\n",
    "            subject_df = student_df[student_df[colSubject] == subject]\n",
    "            # subject_df = drop_empty_supervisor_id_rows(subject_df)\n",
    "            subject_df.reset_index(drop=True, inplace=True)\n",
    "            # print(subject_df['Preventive, Prophylactic and Bleaching Services'])\n",
    "            code_dict = split_df_by_codes(subject_df)\n",
    "            subject_dict[subject] = code_dict\n",
    "\n",
    "        student_dict[student_id] = subject_dict\n",
    "        # student_df = drop_empty_supervisor_id_rows(student_df)\n",
    "        student_df.reset_index(drop=True, inplace=True)  # Reset the index\n",
    "        # print('All Subjects')\n",
    "        code_dict = split_df_by_codes(student_df)  # Split the DataFrame by codes\n",
    "        # student_df = student_df[before_columns + mc_columns + rubricQues + after_columns]\n",
    "        # code_dict['All'] = student_df  # Include a key for all data\n",
    "        # print('All Subjects')\n",
    "        student_dict[student_id]['AllSubjects'] = code_dict  # Assign the filtered DataFrame to the dictionary\n",
    "    return student_dict, unique_ids\n",
    "\n",
    "# Create the dictionary\n",
    "student_dfs, unique_ids = splitByStudent(df)\n",
    "print(unique_ids)\n",
    "print(subjectSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(student_dfs.keys())\n",
    "display(student_dfs[1080466].keys())\n",
    "display(student_dfs[1080466]['DENT90120']['941_CLINIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def createRubricPlot(dftest, title):\n",
    "    rubricQues = ['PS', 'ES', 'TS', 'CS']\n",
    "    full_names = {\n",
    "        'PS': 'Professionalism',\n",
    "        'ES': 'Entrustment',\n",
    "        'TS': 'Time Management',\n",
    "        'CS': 'Communication'\n",
    "    }\n",
    "    \n",
    "    # Check for multiple entries on the same date\n",
    "    dftest['DateLabel'] = dftest['Recorded Date'].astype(str)\n",
    "    date_counts = dftest['Recorded Date'].value_counts()\n",
    "    multiple_dates = date_counts[date_counts > 1].index\n",
    "\n",
    "    for date in multiple_dates:\n",
    "        mask = dftest['Recorded Date'] == date\n",
    "        dftest.loc[mask, 'DateLabel'] = dftest.loc[mask, 'DateLabel'] + ' (' + (dftest[mask].groupby('Recorded Date').cumcount() + 1).astype(str) + ')'\n",
    "    \n",
    "    plot_data = dftest.set_index('DateLabel')[rubricQues]\n",
    "    \n",
    "    # Define a less saturated colorblind-friendly palette\n",
    "    colors = ['#56B4E9', '#E69F00', '#009E73', '#CC79A7']\n",
    "\n",
    "    max_ticks = 12\n",
    "\n",
    "    if len(plot_data) > 12 and len(plot_data) <= 16:\n",
    "        max_ticks = 8\n",
    "    num_chunks = int(np.ceil(len(plot_data) / max_ticks))\n",
    "    # print(len(plot_data))\n",
    "    # print(num_chunks)\n",
    "    subplots = []\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * max_ticks\n",
    "        end_idx = (i + 1) * max_ticks\n",
    "        chunk_data = plot_data.iloc[start_idx:end_idx]\n",
    "        # print(i+1)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        chunk_data.plot(kind='bar', ax=ax, width=0.6, color=colors)\n",
    "\n",
    "        ax.set_xlabel('Recorded Date', labelpad=15, fontsize=11)\n",
    "        ax.set_ylabel('Scores', fontsize=11)\n",
    "        ax.set_title(f'Rubric Scores for {title} - Part {i + 1}', fontsize=16)\n",
    "        ax.set_xticklabels([label for label in chunk_data.index], rotation=45, fontsize=9)\n",
    "        ax.set_yticks([1, 2, 3, 4])\n",
    "        ax.set_ylim(0, 9)\n",
    "        ax.legend(labels=[full_names[label] for label in rubricQues], title='Skills')\n",
    "        ax.grid(True, linestyle='--', linewidth=0.25, alpha=0.5)\n",
    "\n",
    "        # Extracting codes for each date\n",
    "        date_codes = {}\n",
    "        for idx, row in dftest.iterrows():\n",
    "            date_label = row['DateLabel']\n",
    "            allCodes = []\n",
    "            for col in serviceCols:\n",
    "                if col == colServiceGeneral:\n",
    "                    continue\n",
    "                allCodes += extract_restorative_codes(row[col], row[colClinicChoice])\n",
    "            allCodes = [f'{code} {location}' for code, location in allCodes]\n",
    "            general_codes = ['LA'] if 'LA' in str(row[colServiceGeneral]) else []\n",
    "            all_codes = allCodes + general_codes\n",
    "            codes_str = '\\n'.join([code for code in all_codes])\n",
    "            date_codes[date_label] = codes_str\n",
    "\n",
    "        # Displaying codes for each date, vertically aligned\n",
    "        for date_label, codes_str in date_codes.items():\n",
    "            if date_label in chunk_data.index:\n",
    "                date_index = chunk_data.index.get_loc(date_label)\n",
    "                max_height = chunk_data.loc[date_label].max()\n",
    "                num_codes = len(codes_str.split('\\n'))\n",
    "                y_position = max_height + (num_codes * 0.2)  # Adjust vertical position based on the number of codes\n",
    "                ax.annotate(codes_str, \n",
    "                            (date_index, y_position), \n",
    "                            ha='center', va='bottom', \n",
    "                            fontsize=9, color='black')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        subplots.append(fig)\n",
    "\n",
    "    return subplots, num_chunks\n",
    "# Assuming the functions 'extract_restorative_codes' and 'dftest' dataframe are already defined elsewhere.\n",
    "\n",
    "\n",
    "id = 1220151\n",
    "print(id)\n",
    "for subject in student_dfs[id].keys():\n",
    "    if subject == 'AllSubjects':\n",
    "        continue\n",
    "    for code in student_dfs[id][subject].keys():\n",
    "        if code != 'All':\n",
    "            continue\n",
    "        dftest = student_dfs[id][subject][code]\n",
    "        subplots, numChunks = createRubricPlot(dftest, f'{subject}')\n",
    "        print(numChunks)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = student_dfs[1383423]['DENT90115']\n",
    "subplots, numChunks = createRubricPlot(dftest['All'], 'All Subjects')\n",
    "plt.show()\n",
    "dftest['All']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For MC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in one graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMCscores(sdf):\n",
    "    columnsToTake = ['Recorded Date', 'MC total', 'MC total possible', 'MC score proportion', 'Code']\n",
    "    sdfCombined = None\n",
    "    for key, dftest2 in sdf.items():\n",
    "        if key == 'All' or key == 'MC':\n",
    "            continue\n",
    "        dftest2.replace({'Yes': 1, 'No': 0, 'Not Assessed': np.nan, 'Not Reviewed': np.nan}, inplace=True)\n",
    "        mc_columns_test = find_mc_columns(dftest2)\n",
    "        # only take supervisor columns\n",
    "        mc_columns_test = [col for col in mc_columns_test if 'supervisor' in col]\n",
    "        print(mc_columns_test)\n",
    "        dftest2['MC total'] = dftest2[mc_columns_test].sum(axis=1, skipna=True)\n",
    "        dftest2['MC total possible'] = dftest2[mc_columns_test].count(axis=1)\n",
    "        dftest2['MC score proportion'] = np.where(dftest2['MC total possible'] > 0,\n",
    "                                                dftest2['MC total'] / dftest2['MC total possible'],\n",
    "                                                np.nan)\n",
    "        dftest2['Code'] = [key for i in range(len(dftest2))]\n",
    "\n",
    "        if sdfCombined is None:\n",
    "            sdfCombined = dftest2[columnsToTake]\n",
    "        else:\n",
    "            sdfCombined = pd.concat([sdfCombined, dftest2[columnsToTake]])\n",
    "    return sdfCombined\n",
    "\n",
    "# sdf['MC'] = sdfCombined\n",
    "# dftest2 = sdfCombined\n",
    "# dftest2\n",
    "for id in unique_ids:\n",
    "    for subject in student_dfs[id].keys():\n",
    "        if subject == 'AllSubjects':\n",
    "            continue\n",
    "        sdf = student_dfs[id][subject]\n",
    "        sdfCombined = getMCscores(sdf)\n",
    "        sdf['MC'] = sdfCombined\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create different plots for each code\n",
    "def createMCPlotCodes(df, title):\n",
    "    # Filter out codes where all 'MC score proportion' values are NaN\n",
    "    valid_codes = [code for code in df['Code'].unique() if df[df['Code'] == code]['MC score proportion'].notna().any()]\n",
    "    if len(valid_codes) == 0:\n",
    "        return None, None\n",
    "    n_cols = 2\n",
    "    n_rows = int(np.ceil(len(valid_codes) / n_cols))\n",
    "    fig_width = 20\n",
    "    fig_height = 8 * n_rows\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height), squeeze=False)\n",
    "    \n",
    "    # Flatten axes for easy iteration\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    bar_width = 1  # Set a fixed bar width\n",
    "    gap_between_dates = 1.0  # Set a fixed gap between dates\n",
    "    fontsize = 11\n",
    "    completedColor = '#5D3A9B'\n",
    "    remainingColor = '#E66100'\n",
    "\n",
    "    all_positions = []\n",
    "\n",
    "    # Determine global x limits\n",
    "    for idx, code in enumerate(valid_codes):\n",
    "        code_df = df[df['Code'] == code].sort_values(by='Recorded Date')\n",
    "        dates = code_df['Recorded Date'].unique()\n",
    "        prevBarPos = None\n",
    "\n",
    "        for pos, (date, group) in enumerate(code_df.groupby('Recorded Date')):\n",
    "            nBars = len(group)\n",
    "            if prevBarPos is None:\n",
    "                base_pos = 0\n",
    "            else:\n",
    "                base_pos = prevBarPos + gap_between_dates\n",
    "            prevBarPos = base_pos + gap_between_dates\n",
    "            all_positions.append(base_pos)\n",
    "    \n",
    "    global_xmin = min(all_positions) - gap_between_dates\n",
    "    global_xmax = max(all_positions) + gap_between_dates\n",
    "\n",
    "    for idx, code in enumerate(valid_codes):\n",
    "        ax = axes[idx]\n",
    "        code_df = df[df['Code'] == code].sort_values(by='Recorded Date')\n",
    "        dates = []\n",
    "        prevBarPos = None\n",
    "        positions = []\n",
    "\n",
    "        for pos, (date, group) in enumerate(code_df.groupby('Recorded Date')):\n",
    "            nBars = len(group)\n",
    "            if prevBarPos is None:\n",
    "                base_pos = 0\n",
    "            else:\n",
    "                base_pos = prevBarPos + gap_between_dates\n",
    "            prevBarPos = base_pos + gap_between_dates\n",
    "            bar_offset = -((nBars - 1) / 2) * bar_width\n",
    "\n",
    "            for i, (_, row) in enumerate(group.iterrows()):\n",
    "                completed = row['MC score proportion']\n",
    "                bar_pos = base_pos + bar_offset + i * bar_width\n",
    "                if not pd.isna(completed):\n",
    "                    remaining = 1 - completed\n",
    "                    ax.bar(bar_pos, completed, color=completedColor, width=bar_width, edgecolor='black', linewidth=1, alpha=0.8)\n",
    "                    ax.bar(bar_pos, remaining, bottom=completed, color=remainingColor, width=bar_width, edgecolor='black', linewidth=1, alpha=0.7)\n",
    "                    ax.text(bar_pos, completed / 2 if completed != 0 else 0.2, f'{completed:.0%}  ({int(row[\"MC total\"])}/{row[\"MC total possible\"]})', ha='center', va='center', fontsize=fontsize, color='white', rotation=90)\n",
    "                    positions.append(base_pos)\n",
    "                    dates.append(date)\n",
    "\n",
    "        completed_patch = plt.Line2D([0], [0], color=completedColor, lw=6, label='Satisfactorily Completed')\n",
    "        remaining_patch = plt.Line2D([0], [0], color=remainingColor, lw=6, label='Not Satisfactorily Completed')\n",
    "        ax.legend(handles=[completed_patch, remaining_patch], loc='upper right')\n",
    "\n",
    "        ax.set_ylabel('Proportion of Completed Tasks', fontsize=fontsize)\n",
    "        ax.set_title(f'Checklist marks for {code}', fontsize=16)\n",
    "        ax.set_xticks(positions)\n",
    "        ax.set_xticklabels([date.strftime('%d-%m-%Y') for date in dates], rotation=60)\n",
    "        ax.set_ylim(0, 1.5)\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Set the consistent x limits\n",
    "        halfwidth = (global_xmax - global_xmin) / 2\n",
    "        center_position = positions[len(positions) // 2] if len(positions) % 2 == 1 else (positions[len(positions) // 2 - 1] + positions[len(positions) // 2]) / 2\n",
    "        ax.set_xlim(center_position - halfwidth, center_position + halfwidth)\n",
    "        if len(positions)<=2:\n",
    "            ax.set_xlim(-5, 5)\n",
    "        plt.margins(x=0.05)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # Remove unused axes\n",
    "    for idx in range(len(valid_codes), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    fig.suptitle(title, fontsize=20, y=0.95)\n",
    "    plt.subplots_adjust(top=0.9, hspace=0.8, wspace=0.2)\n",
    "    return axes, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "def createMCPlot(sdf, title, cmap = 'hsv'):\n",
    "    df = sdf['MC']\n",
    "    # remove rows with na MC score proportion\n",
    "    df = df.dropna(subset=['MC score proportion'])\n",
    "    if len(df) == 0:\n",
    "        return None, None, None, None\n",
    "    df = df.sort_values(by='Recorded Date')\n",
    "    dates = df['Recorded Date'].unique()\n",
    "\n",
    "    # Dynamic figure size based on the number of dates\n",
    "    min_fig_width = 15\n",
    "    max_fig_width = 25\n",
    "    fig_height = 8\n",
    "\n",
    "    # Calculate figure width\n",
    "    fig_width = min(max_fig_width, max(min_fig_width, len(dates) * 0.75))\n",
    "    fig_width = 13\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    # Plot the stacked bar chart\n",
    "    bar_width = 1\n",
    "    # print(bar_width)\n",
    "    gap_between_dates = 0.75\n",
    "    positions = np.arange(len(dates)) * (bar_width + gap_between_dates)\n",
    "    # print(positions)\n",
    "    # Create a mapping from dates to positions\n",
    "    date_position_map = {date: pos for pos, date in zip(positions, dates)}\n",
    "\n",
    "    # This is for coloring the edges of the bars based on the code\n",
    "    unique_codes = sdf['MC']['Code'].unique() # get the codes\n",
    "    cmap = plt.get_cmap(cmap)  # You can choose any other colormap\n",
    "    code_colors = {code: cmap(i / len(unique_codes)) for i, code in enumerate(unique_codes)}\n",
    "    fontsize = 11\n",
    "    def addCodeText(ax, bar_pos, codeText, color='black'):\n",
    "        ax.text(bar_pos, 1.03, codeText, ha='center', va='bottom', fontsize=fontsize, color=color, rotation=45)\n",
    "\n",
    "    completedColor = '#5D3A9B'\n",
    "    remainingColor = '#E66100'\n",
    "    prevBarPos = None\n",
    "    positions =[]\n",
    "    dateLabel =[]\n",
    "    for pos, (date, group) in enumerate(df.groupby('Recorded Date')):\n",
    "        # base_pos = date_position_map[date]\n",
    "        # get index of date in dates\n",
    "        nBars = len(group)\n",
    "        if prevBarPos is None:\n",
    "            base_pos = 0\n",
    "        else:\n",
    "            preceding_width = (nBars * bar_width)/2\n",
    "            base_pos = prevBarPos + gap_between_dates + preceding_width\n",
    "        # prevBarPos = base_pos + (nBars * bar_width)/2\n",
    "        positions.append(base_pos)\n",
    "        dateLabel.append(date)\n",
    "        prevBarPos = base_pos + (nBars * bar_width)/2\n",
    "        bar_offset = -((len(group) - 1) / 2) * bar_width  # Center the bars for each date\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            completed = row['MC score proportion']\n",
    "            bar_pos = base_pos + bar_offset + i * bar_width\n",
    "            codeText = f'{row[\"Code\"].split(\"_\")[0]}'\n",
    "            edge_color = code_colors[row[\"Code\"]]\n",
    "            if pd.isna(completed):\n",
    "                # ax.text(bar_pos, 0.5, 'Not Assessed', ha='center', va='center', fontsize=fontsize, color='black', rotation=90)\n",
    "                # addCodeText(ax, bar_pos, codeText, edge_color)  # Add code text\n",
    "                # ax.bar(bar_pos, 1, color= 'white', width=bar_width, edgecolor='white')\n",
    "                print('How could this happen?')\n",
    "                pass\n",
    "            else:\n",
    "                remaining = 1 - completed\n",
    "                ax.bar(bar_pos, completed, color=completedColor, width=bar_width, edgecolor='black', linewidth = 1, alpha = 0.8)\n",
    "                # ax.bar(bar_pos, 1, width=bar_width, color=edge_color, edgecolor = 'black', linewidth = 1, alpha = 0.2)\n",
    "                ax.bar(bar_pos, remaining, bottom=completed, color=remainingColor, width=bar_width, edgecolor='black', linewidth = 1, alpha = 0.7)\n",
    "\n",
    "                ax.text(bar_pos, completed / 2 if completed!=0 else 0.2, f'{completed:.0%}  ({int(row[\"MC total\"])}/{row[\"MC total possible\"]})', ha='center', va='center', fontsize=fontsize, color='white', rotation=90)\n",
    "                # ax.text(bar_pos, 1.05, f'{int(row[\"MC total\"])}/{row[\"MC total possible\"]}', ha='center', va='center', fontsize=12, color='black')\n",
    "                addCodeText(ax, bar_pos, codeText, edge_color) # Add code text\n",
    "\n",
    "\n",
    "    # Manually add legend entries\n",
    "    completed_patch = plt.Line2D([0], [0], color=completedColor, lw=6, label='Satisfactorily Completed')\n",
    "    remaining_patch = plt.Line2D([0], [0], color= remainingColor, lw=6, label='Not Satisfactorily Completed')\n",
    "    ax.legend(handles=[completed_patch, remaining_patch], loc='upper right')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Recorded Date', fontsize=12)\n",
    "    ax.set_ylabel('Proportion of Completed Tasks', fontsize=fontsize)\n",
    "    ax.set_title(f'Checklist marks for {title}', fontsize=16)\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels([date.strftime('%d-%m-%Y') for date in dateLabel], rotation=60)\n",
    "    ax.set_ylim(0, 1.5)\n",
    "    ax.set_yticks([])\n",
    "    plt.margins(x=0.05)\n",
    "\n",
    "    if len(positions) <= 2:\n",
    "        ax.set_xlim(-2.5*len(df), 2.5*len(df))\n",
    "\n",
    "    # add text\n",
    "    plt.text(0.05, 0.95, '*Scores reflect assessed checklist items only', verticalalignment='top', horizontalalignment='left',\n",
    "            transform=ax.transAxes, color='black', fontsize=11)\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-axis labels\n",
    "\n",
    "    axes, fig2 = createMCPlotCodes(df, f'Checklist marks for {title}')\n",
    "    return ax, axes, fig, fig2\n",
    "\n",
    "colormaps = ['Dark2']\n",
    "for id in unique_ids:\n",
    "    print(id)\n",
    "    for subject in student_dfs[id].keys():\n",
    "        if subject == 'AllSubjects':\n",
    "            continue\n",
    "        print(subject)\n",
    "        sdf = student_dfs[id][subject]\n",
    "        if sdf['MC'] is None:\n",
    "            continue\n",
    "        for cmap in colormaps:\n",
    "            print(cmap)\n",
    "            ax, axes, fig, fig2 = createMCPlot(sdf, f'{subject} - {id}', cmap)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        # ax = createMCPlot(sdf, f'{subject}')\n",
    "        # plt.show()\n",
    "        # plt.close()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = student_dfs[1081787]['DENT90115']\n",
    "createMCPlot(sdf, f'ORAL20005', cmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tmp_dir = 'FullSpreadsheets/tmp'\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "student_chunks_dict = {}\n",
    "\n",
    "def plotResults(id, subject, cmap):\n",
    "    if subject == 'AllSubjects':\n",
    "        return None\n",
    "    print(subject)\n",
    "\n",
    "    # Plot rubric for each subject\n",
    "    code = 'All'\n",
    "    dftest = student_dfs[id][subject][code]\n",
    "    if len(dftest) == 0 or dftest is None:\n",
    "        return None\n",
    "    subplots, numChunks = createRubricPlot(dftest, f'{subject} - {id}')\n",
    "    \n",
    "    savepath1 = []\n",
    "    for i, fig in enumerate(subplots):\n",
    "        savepath = f'{tmp_dir}/{id}_{subject}_rubric_{i + 1}.png'\n",
    "        fig.savefig(savepath)\n",
    "        savepath1.append(savepath)\n",
    "        plt.close(fig)\n",
    "    student_chunks_dict[id] = numChunks\n",
    "    # plt.show()\n",
    "    print(numChunks)\n",
    "    print('Plot 1 saved')\n",
    "    \n",
    "    sdf = student_dfs[id][subject]\n",
    "    if sdf['MC'] is None:\n",
    "        return savepath1, None, None\n",
    "    ax2, axes, fig, fig2 = createMCPlot(sdf, f'{subject} - {id}', cmap)\n",
    "    if ax2 is None:\n",
    "        return savepath1, None, None\n",
    "    savepath2 = f'{tmp_dir}/{id}_{subject}_mc.png'\n",
    "    fig.savefig(savepath2)\n",
    "    plt.close()\n",
    "    print('Plot 2 saved')\n",
    "\n",
    "    savepath3 = f'{tmp_dir}/{id}_{subject}_mc_codes.png'\n",
    "    if axes is None:\n",
    "        return savepath1, savepath2, None\n",
    "    fig2.savefig(savepath3)\n",
    "    plt.close()\n",
    "    print('Plot 3 saved')\n",
    "    return savepath1, savepath2, savepath3\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_chunks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donelist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "plt.close()\n",
    "for id in unique_ids:\n",
    "    counter += 1\n",
    "    print(f'\\n[{counter}/{len(unique_ids)}]')\n",
    "    if id in donelist:\n",
    "        continue\n",
    "    print(f'{id}')\n",
    "    for subject in student_dfs[id].keys():\n",
    "        plotResults(id, subject, 'Dark2')\n",
    "    donelist.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = student_dfs[1460683]['ORAL20005']\n",
    "plotResults(1460683, 'ORAL20005', 'Dark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = student_dfs[1384392]['DENT90116']['All']\n",
    "createRubricPlot(dftest, 'DENT90116')\n",
    "plt.show()\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "tmp_dir = 'FullSpreadsheets/tmp'\n",
    "\n",
    "# Assuming df is your DataFrame and colSubject and colAge are your column names\n",
    "colSubject = 'Subject'\n",
    "colAge = 'Patient Age (Please provide age in numbers only)'\n",
    "\n",
    "# Filter the DataFrame by subjects\n",
    "oral30002 = df[df[colSubject] == 'ORAL30002']\n",
    "oral20005 = df[df[colSubject] == 'ORAL20005']\n",
    "\n",
    "# Function to format summary statistics\n",
    "def format_summary_statistics(stats):\n",
    "    formatted_stats = {\n",
    "        'count': f'{stats[\"count\"]:.0f}',\n",
    "        'mean': f'{stats[\"mean\"]:.0f}',\n",
    "        'std': f'{stats[\"std\"]:.2f}',\n",
    "        'min': f'{stats[\"min\"]:.0f}',\n",
    "        'max': f'{stats[\"max\"]:.0f}'\n",
    "    }\n",
    "    summary_text = \"\\n\".join([f'{key}: {value}' for key, value in formatted_stats.items()])\n",
    "    return summary_text\n",
    "\n",
    "# Function to create summary statistics and histograms for a DataFrame\n",
    "def create_summary_and_histogram(df, subject_name):\n",
    "        unique_ids = df['Student ID'].unique()\n",
    "        for student_id in unique_ids:\n",
    "            student_df = df[df['Student ID'] == student_id]\n",
    "            student_name = studentidname_dict.get(student_id, \"Unknown\")\n",
    "\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(8.27, 11.69))  # A4 size\n",
    "\n",
    "            # Summary statistics\n",
    "            summary_stats = student_df[colAge].describe()\n",
    "            summary_text = format_summary_statistics(summary_stats)\n",
    "            \n",
    "            axes[0].text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center')\n",
    "            axes[0].axis('off')\n",
    "            axes[0].set_title('Summary Statistics for Patient Ages', fontsize=14)\n",
    "\n",
    "            # Histogram\n",
    "            bins = [i for i in range(0, 100, 5)]\n",
    "            student_df[colAge].plot(kind='hist', bins=bins, ax=axes[1], color='skyblue', edgecolor='black')\n",
    "            axes[1].set_title(f'Age Histogram for {subject_name}', fontsize=14)\n",
    "            axes[1].set_xlabel('Age')\n",
    "            axes[1].set_xticks(bins)\n",
    "            axes[1].set_ylabel('Frequency')\n",
    "\n",
    "            # Add title to the figure\n",
    "            fig.suptitle(f'Student ID: {student_id}\\nName: {student_name}', fontsize=16, y=1.05)\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "            plt.savefig(f'{tmp_dir}/{student_id}_{subject_name}_age_summary.png')\n",
    "            plt.close(fig)\n",
    "\n",
    "# Create the summaries and histograms and save them to PDF\n",
    "create_summary_and_histogram(oral30002, 'ORAL30002')\n",
    "create_summary_and_histogram(oral20005, 'ORAL20005')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "donelist = []\n",
    "\n",
    "# Assuming the existence of these variables from your context\n",
    "# unique_ids, student_dfs, createRubricPlot, createMCPlot, colormaps, studentidname_dict\n",
    "cmap = 'Dark2'\n",
    "tmp_dir = 'FullSpreadsheets/tmp'\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "saveFolder = 'FullSpreadsheets/studentReport'\n",
    "os.makedirs(saveFolder, exist_ok=True)\n",
    "figsize = (8.27, 11.69)  # A4 size\n",
    "counter = 0\n",
    "for student_id in unique_ids:\n",
    "    # if student_id != 1463086:\n",
    "    #     continue\n",
    "    counter += 1\n",
    "    print(f'\\n[{counter}/{len(unique_ids)}]')\n",
    "    student_name = studentidname_dict.get(student_id, \"Unknown\")\n",
    "    pdf_title = f\"{student_id}_{student_name}.pdf\"\n",
    "    print(student_id)\n",
    "    if student_id in donelist:\n",
    "        continue\n",
    "    for subject in student_dfs[student_id].keys():\n",
    "        os.makedirs(f'{saveFolder}/{subject}', exist_ok=True)\n",
    "        with PdfPages(f'{saveFolder}/{subject}/{pdf_title}') as pdf:\n",
    "            if subject == 'AllSubjects':\n",
    "                continue\n",
    "\n",
    "            # print(nSubplots)\n",
    "            for i in range(0, 10, 2):  # Iterate in steps of 2 to handle pairs of images\n",
    "                savepath1 = f'{tmp_dir}/{student_id}_{subject}_rubric_{i+1}.png'\n",
    "                savepath2 = f'{tmp_dir}/{student_id}_{subject}_rubric_{i+2}.png'\n",
    "\n",
    "                if os.path.exists(savepath1) or os.path.exists(savepath2):\n",
    "                    if os.path.exists(savepath1) and os.path.exists(savepath2):\n",
    "                        fig, axes = plt.subplots(nrows=2, ncols=1, figsize=figsize)  # Two figures in one page\n",
    "                        images = [savepath1, savepath2]\n",
    "                    else:\n",
    "                        fig, axes = plt.subplots(nrows=1, ncols=1, figsize=figsize)  # One figure in one page\n",
    "                        images = [savepath1] if os.path.exists(savepath1) else [savepath2]\n",
    "                        axes = [axes]\n",
    "\n",
    "                    for ax, img_path in zip(axes, images):\n",
    "                        rubricplot = plt.imread(img_path)\n",
    "                        ax.imshow(rubricplot)\n",
    "                        ax.axis('off')\n",
    "\n",
    "                    fig.subplots_adjust(top=0.85, bottom=0.05, left=0.05, right=0.95)\n",
    "                    if i == 0:\n",
    "                        fig.text(0.05, 0.88, '*For Simulation the max possible score for Professionalism and Communication is 2',\n",
    "                                 verticalalignment='top', horizontalalignment='left', color='black', fontsize=10)\n",
    "                        fig.suptitle(f'{subject} - {student_name}', fontsize=28, y=0.95)\n",
    "\n",
    "                    pdf.savefig(fig)\n",
    "                    plt.close(fig)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            # second figure\n",
    "            savepath2 = f'{tmp_dir}/{student_id}_{subject}_mc.png'\n",
    "            if os.path.exists(savepath2):\n",
    "                mcplot = plt.imread(savepath2)\n",
    "                fig1, axes1 = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "                axes1.imshow(mcplot)\n",
    "                axes1.axis('off')\n",
    "                fig1.tight_layout()\n",
    "                pdf.savefig(fig1)\n",
    "                plt.close(fig1)\n",
    "\n",
    "            # third figure\n",
    "            # savepath3 = f'{tmp_dir}/{student_id}_{subject}_mc_codes.png'\n",
    "            # if os.path.exists(savepath3):\n",
    "            #     mcplotcodes = plt.imread(savepath3)\n",
    "            #     fig2, axes2 = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "            #     axes2.imshow(mcplotcodes)\n",
    "            #     axes2.axis('off')\n",
    "            #     fig2.tight_layout()\n",
    "            #     pdf.savefig(fig2)\n",
    "            #     plt.close(fig2)\n",
    "\n",
    "            savepath4 = f'{tmp_dir}/{student_id}_{subject}_age_summary.png'\n",
    "            if os.path.exists(savepath4):\n",
    "                ageplot = plt.imread(savepath4)\n",
    "                fig3, axes3 = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n",
    "                axes3.imshow(ageplot)\n",
    "                axes3.axis('off')\n",
    "                fig3.tight_layout()\n",
    "                pdf.savefig(fig3)\n",
    "                plt.close(fig3)\n",
    "        donelist.append(student_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
