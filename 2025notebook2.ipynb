{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "from variableUtils import *\n",
    "import variableUtils\n",
    "from Utils import *\n",
    "from ClassUtils import *\n",
    "from pprint import pprint\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from reportlab.lib.pagesizes import letter, landscape, A4, A3\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, PageBreak, Paragraph, Spacer, Image\n",
    "from reportlab.lib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reportlab.platypus import Paragraph, Spacer, KeepTogether, KeepInFrame\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "import io\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import FormulaRule\n",
    "import PIL\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(sns.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfilepath = '2025\\Michael\\\\assessment-data.json'\n",
    "folder, file, ext = getFolderandFileName(jsonfilepath)\n",
    "with open(jsonfilepath) as f:\n",
    "    data = json.load(f)\n",
    "# display(data)\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a structured DataFrame per date\n",
    "data_dict = {}\n",
    "df_dict = {}\n",
    "\n",
    "for entry in data[\"result\"]:\n",
    "    date = entry[\"date\"]\n",
    "    flattened_entry = {\n",
    "        \"student_name\": entry[\"student_name\"],\n",
    "        \"supervisor_name\": entry[\"supervisor_name\"],\n",
    "        \"cohort\": entry[\"cohort\"],\n",
    "        \"subject\": entry[\"subject\"],\n",
    "        \"type\": entry[\"type\"],\n",
    "        **entry[\"student_data\"],\n",
    "        **entry[\"supervisor_data\"]\n",
    "    }\n",
    "    \n",
    "    if date not in data_dict:\n",
    "        data_dict[date] = []\n",
    "    \n",
    "    data_dict[date].append(flattened_entry)\n",
    "\n",
    "# Create and display separate DataFrames per date\n",
    "for date, records in data_dict.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    df_dict[date] = df\n",
    "    # df.to_excel(f\"{folder}\\{date}.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display one item of data_dict\n",
    "key0 = list(data_dict.keys())[0]\n",
    "print(json.dumps(data_dict[key0], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Setting for Aditi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# Reload necessary libraries after execution state reset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reload the Preparation and Restoration scores\n",
    "file_path = \"/mnt/data/Cleaned_Transposed_Workshopping_Checklist.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Load data\n",
    "prep_df = xls.parse(\"Preparation\")\n",
    "rest_df = xls.parse(\"Restoration\")\n",
    "\n",
    "# Reload the importance ranking and difficulty tables\n",
    "prep_data = {\n",
    "    \"Item\": [\n",
    "        \"DEJ is caries-free *\",\n",
    "        \"Principles of selective caries removal on pulpal surfaces satisfied *\",\n",
    "        \"Sufficient and uniform layer of carious dentine remaining, limited to pulpal surfaces only\",\n",
    "        \"Conservative in the mesio-distal dimension\",\n",
    "        \"Conservative in the bucco-lingual dimension\",\n",
    "        \"Depth not overextended nor less than 1.5mm\",\n",
    "        \"Avoids excessive loss or weakening of tooth structure or compromising pulp space *\",\n",
    "        \"Gingival contact cleared *\",\n",
    "        \"Cavosurface margins free from irregularities and small areas of undermined enamel\",\n",
    "        \"Free from large areas of unsupported enamel or large fractures*\",\n",
    "        \"Internal surfaces smooth and rounded without minor roughness\",\n",
    "        \"Internal surfaces smooth and rounded without obvious irregularities and/or gouges\",\n",
    "        \"No or minimal scuffs/ scratches/ surface loss\",\n",
    "        \"Avoids small damages to adjacent tooth and/or surrounding surfaces requiring tooth modification\",\n",
    "        \"Avoids large damages to adjacent tooth and/or surrounding surfaces requiring restoration *\"\n",
    "    ],\n",
    "    \"Difficulty\": [\n",
    "        \"HARD\", \"HARD\", \"HARD\", \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\",\n",
    "        \"HARD\", \"HARD\", \"HARD\", \"HARD\", \"MODERATE\", \"MODERATE\", \"MODERATE\"\n",
    "    ],\n",
    "    \"Importance Ranking\": [10, 10, 6, 7, 7, 7, 10, 10, 4, 10, 2, 5, 2, 7, 10]\n",
    "}\n",
    "\n",
    "rest_data = {\n",
    "    \"Item\": [\n",
    "        \"Smooth and well-polished\",\n",
    "        \"Sub-surface porosities or voids absent\",\n",
    "        \"Large porosities or voids absent*\",\n",
    "        \"Smooth junction\",\n",
    "        \"Free of minor excess/deficiency only detectable by dental explorer\",\n",
    "        \"Free of major excess that warrants additional finishing and polishing\",\n",
    "        \"No open margins *\",\n",
    "        \"No overhangs that warrant significant finishing and polishing*\",\n",
    "        \"Tooth anatomy recreated\",\n",
    "        \"Contour not bulky (including marginal ridge)\",\n",
    "        \"Contour not deficient (including marginal ridge)\",\n",
    "        \"Establishes anatomical contact area *\",\n",
    "        \"No or minimal scuffs/ scratches/ surface loss\",\n",
    "        \"Avoids surface damage 2mm beyond restoration\",\n",
    "        \"Avoids damage to adjacent tooth and/or surrounding surfaces requiring restorative correction *\"\n",
    "    ],\n",
    "    \"Difficulty\": [\n",
    "        \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\",\n",
    "        \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\", \"MODERATE\", \"HARD\", \"HARD\", \"HARD\"\n",
    "    ],\n",
    "    \"Importance Ranking\": [2, 7, 10, 8, 8, 8, 10, 10, 2, 5, 7, 10, 2, 5, 10]\n",
    "}\n",
    "\n",
    "prep_criteria_df = pd.DataFrame(prep_data)\n",
    "rest_criteria_df = pd.DataFrame(rest_data)\n",
    "\n",
    "# Add total score columns\n",
    "prep_df[\"Total Score\"] = prep_df.iloc[:, 2:].sum(axis=1)\n",
    "rest_df[\"Total Score\"] = rest_df.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "# Maximum possible scores\n",
    "max_prep_score = prep_df.iloc[:, 2:-1].shape[1]\n",
    "max_rest_score = rest_df.iloc[:, 2:-1].shape[1]\n",
    "\n",
    "# **Method 1: Fixed Percentage Threshold**\n",
    "pass_threshold = 0.7  # 70% cutoff\n",
    "\n",
    "prep_df[\"Fixed Pass\"] = prep_df[\"Total Score\"] >= (max_prep_score * pass_threshold)\n",
    "rest_df[\"Fixed Pass\"] = rest_df[\"Total Score\"] >= (max_rest_score * pass_threshold)\n",
    "\n",
    "# **Method 2: Weighted Scoring Based on Importance Ranking**\n",
    "weighted_prep_scores = prep_df.iloc[:, 2:-2] * prep_criteria_df[\"Importance Ranking\"].values\n",
    "weighted_rest_scores = rest_df.iloc[:, 2:-2] * rest_criteria_df[\"Importance Ranking\"].values\n",
    "\n",
    "prep_df[\"Weighted Score\"] = weighted_prep_scores.sum(axis=1)\n",
    "rest_df[\"Weighted Score\"] = weighted_rest_scores.sum(axis=1)\n",
    "\n",
    "max_weighted_prep_score = prep_criteria_df[\"Importance Ranking\"].sum()\n",
    "max_weighted_rest_score = rest_criteria_df[\"Importance Ranking\"].sum()\n",
    "\n",
    "prep_df[\"Weighted Pass\"] = prep_df[\"Weighted Score\"] >= (max_weighted_prep_score * pass_threshold)\n",
    "rest_df[\"Weighted Pass\"] = rest_df[\"Weighted Score\"] >= (max_weighted_rest_score * pass_threshold)\n",
    "\n",
    "# **Method 3: Difficulty-Adjusted Scoring**\n",
    "hard_criteria_prep = prep_criteria_df[prep_criteria_df[\"Difficulty\"] == \"HARD\"].index + 2\n",
    "hard_criteria_rest = rest_criteria_df[rest_criteria_df[\"Difficulty\"] == \"HARD\"].index + 2\n",
    "\n",
    "prep_df[\"Hard Criteria Score\"] = prep_df.iloc[:, hard_criteria_prep].sum(axis=1)\n",
    "rest_df[\"Hard Criteria Score\"] = rest_df.iloc[:, hard_criteria_rest].sum(axis=1)\n",
    "\n",
    "hard_pass_threshold = 0.6  # 60% of HARD criteria must be correct\n",
    "\n",
    "prep_df[\"Hard Criteria Pass\"] = prep_df[\"Hard Criteria Score\"] >= (len(hard_criteria_prep) * hard_pass_threshold)\n",
    "rest_df[\"Hard Criteria Pass\"] = rest_df[\"Hard Criteria Score\"] >= (len(hard_criteria_rest) * hard_pass_threshold)\n",
    "\n",
    "# Save results for visualization\n",
    "combined_pass_fail_df = prep_df[[\"Student\", \"Examiner\", \"Total Score\", \"Fixed Pass\", \"Weighted Score\", \"Weighted Pass\", \"Hard Criteria Score\", \"Hard Criteria Pass\"]].merge(\n",
    "    rest_df[[\"Student\", \"Examiner\", \"Total Score\", \"Fixed Pass\", \"Weighted Score\", \"Weighted Pass\", \"Hard Criteria Score\", \"Hard Criteria Pass\"]],\n",
    "    on=[\"Student\", \"Examiner\"],\n",
    "    suffixes=(\"_Preparation\", \"_Restoration\")\n",
    ")\n",
    "\n",
    "\n",
    "# **Visualization of Pass/Fail Rates for Each Examiner**\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=\"Examiner\", hue=\"Fixed Pass_Preparation\", data=combined_pass_fail_df, palette=\"Blues\")\n",
    "plt.title(\"Pass Rate per Examiner (Fixed Threshold - Preparation)\")\n",
    "plt.xlabel(\"Examiner\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.legend(title=\"Passed\", labels=[\"Failed\", \"Passed\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=\"Examiner\", hue=\"Fixed Pass_Restoration\", data=combined_pass_fail_df, palette=\"Reds\")\n",
    "plt.title(\"Pass Rate per Examiner (Fixed Threshold - Restoration)\")\n",
    "plt.xlabel(\"Examiner\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.legend(title=\"Passed\", labels=[\"Failed\", \"Passed\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=\"Examiner\", hue=\"Weighted Pass_Preparation\", data=combined_pass_fail_df, palette=\"Blues\")\n",
    "plt.title(\"Pass Rate per Examiner (Weighted Scoring - Preparation)\")\n",
    "plt.xlabel(\"Examiner\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.legend(title=\"Passed\", labels=[\"Failed\", \"Passed\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=\"Examiner\", hue=\"Weighted Pass_Restoration\", data=combined_pass_fail_df, palette=\"Reds\")\n",
    "plt.title(\"Pass Rate per Examiner (Weighted Scoring - Restoration)\")\n",
    "plt.xlabel(\"Examiner\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.legend(title=\"Passed\", labels=[\"Failed\", \"Passed\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=\"Examiner\", hue=\"Hard Criteria Pass_Preparation\", data=combined_pass_fail_df, palette=\"Blues\")\n",
    "plt.title(\"Pass Rate per Examiner (Hard Criteria - Preparation)\")\n",
    "plt.xlabel(\"Examiner\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.legend(title=\"Passed\", labels=[\"Failed\", \"Passed\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x=\"Examiner\", hue=\"Hard Criteria Pass_Restoration\", data=combined_pass_fail_df, palette=\"Reds\")\n",
    "plt.title(\"Pass Rate per Examiner (Hard Criteria - Restoration)\")\n",
    "plt.xlabel(\"Examiner\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.legend(title=\"Passed\", labels=[\"Failed\", \"Passed\"])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
