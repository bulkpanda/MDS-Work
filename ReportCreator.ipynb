{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject wise Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install scikit-learn\n",
    "# !pip install reportlab\n",
    "# !pip install xlsxwriter\n",
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841.68, 1190.8799999999999)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "from variableUtils import *\n",
    "from Utils import *\n",
    "from ClassUtils import *\n",
    "from pprint import pprint\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from reportlab.lib.pagesizes import letter, landscape, A4, A3\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, PageBreak, Paragraph, Spacer, Image\n",
    "from reportlab.lib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reportlab.platypus import Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from io import BytesIO\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl.formatting.rule import FormulaRule\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loaded workbook: BOH2\\\\CAF+v0.1_October152024_19.01 | CAF v0.1_October 15, '\n",
      " '2024_19.01 Paeds guttman | .xlsx')\n",
      "(\"Workbook sheets: ['011_COE', '012_POE', '013_LIMITED OE', '022_I-O RAD', \"\n",
      " \"'111_CLINIC', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '121_SIM \"\n",
      " \"REMIN', '123_CLINIC', '131_CLINIC', '141_CLINIC', '161_CLINIC', '161_SIM', \"\n",
      " \"'221_CLINIC', '311_CLINIC']\")\n"
     ]
    }
   ],
   "source": [
    "workbookPath = 'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50.xlsx'\n",
    "savePath =  'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50 filtered.xlsx'\n",
    "# guttmanPath = 'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50 guttman.xlsx'\n",
    "guttmanPath = 'FullSpreadsheets\\CAF+v0.1_August+18,+2024\\CAF v0.1_August 18, 2024_19.04 guttman.xlsx'\n",
    "guttmanPath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo guttman.xlsx'\n",
    "guttmanPath = 'FullSpreadsheets\\CAF+v0.1_September+12,+2024_21.55\\CAF v0.1_September 12 August guttman.xlsx'\n",
    "guttmanPath = 'FullSpreadsheets\\CAF+v0.1_October+7,+2024_18.49\\CAF v0.1_October 7, 2024_18.49 guttman.xlsx'\n",
    "guttmanPath = 'BOH2\\CAF+v0.1_October152024_19.01\\CAF v0.1_October 15, 2024_19.01 Paeds guttman.xlsx'\n",
    "workbook, folder, file = loadWorkbook(guttmanPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo filtered.xlsx'\n",
    "# path2 = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo guttman marks.xlsx'\n",
    "# checkAttendence(path2, 'DDS2 (2024)')\n",
    "# df = pd.read_excel(path1)\n",
    "# studentsAttented = df['Student ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with Subjects and the item numbers they have\n",
    "subjectDict= {}\n",
    "for i, sheet in enumerate(workbook.sheetnames):\n",
    "    # print(sheet)\n",
    "    code = sheet.split('_')[0]\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    # df = df[~df[colId].isin([111111, 1111111, 1, 12, 123, 1234, 12345, 123456, 1234567, 12345678])]\n",
    "    sub = df[colSubject].unique()\n",
    "    # print(sub)\n",
    "    # remove None\n",
    "    sub = [s for s in sub if s]\n",
    "    for s in sub:\n",
    "        if s not in subjectDict.keys():\n",
    "            subjectDict[s] = {}\n",
    "        subdf = df[df[colSubject] == s]\n",
    "        if len(subdf) > 0:\n",
    "            subjectDict[s][sheet] = subdf\n",
    "        \n",
    "    # if i >= 4:\n",
    "    #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do for DENT90115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dent90115Dict = {}\n",
    "for i, sheet in enumerate(workbook.sheetnames):\n",
    "    code = sheet.split(' ')[0]\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    dent90115Dict[sheet] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBlank = 'Not Filled'\n",
    "otherCols = [colComplex, colClinicType, colDate, colSupervisor, colFinished, colCE, colCEReason]\n",
    "labelRubric = 'Rubric Weighted Score'\n",
    "# rubricQues.remove('TS')\n",
    "dfTemplate = pd.DataFrame(columns=[colId, 'Yes', 'No', 'Not Reviewed', labelBlank, 'Total MC items'] + rubricQues + ['MC Score', labelRubric, 'ES Weighted Score', 'Total Score'] + otherCols +['Item'])\n",
    "notReviewedW = 0.5\n",
    "rubricW = {'PS': 0.05, 'CS': 0.05, 'TS': .1, 'ES': .1} # This is simulation thus professionalism and communication are reduced weighted\n",
    "rubricDenom = {'PS': 2, 'CS': 4, 'TS': 4, 'ES': 4}\n",
    "mcScoreW = 0.8\n",
    "rubricScoreW = 0.2\n",
    "# esW = 0.05\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'BOH3\\\\25-08-2004\\BOH3 Viva Voce Assessment 2024_August 25, 2024_03.48 guttman.xlsx'\n",
    "# df_ = pd.read_excel(path, keep_default_na=False)\n",
    "# folder, filename, ext = getFolderandFileName(path)\n",
    "# dont' take last row\n",
    "df_ = df_.iloc[:-1]\n",
    "# for i, col in enumerate(df_.columns):\n",
    "#     print(i, col)\n",
    "dent90115Dict = {'414': df_}\n",
    "key0 = list(dent90115Dict.keys())[0]\n",
    "dfPaed = dfTemplate.copy()  \n",
    "\n",
    "rubricQuesNoES = rubricQues.copy()\n",
    "\n",
    "for key, df in dent90115Dict.items():\n",
    "    print(key)\n",
    "    code = key.split('_')[0]\n",
    "    df[colId] = df[colId].astype('Int64', errors='ignore')\n",
    "    df = df[df[colFinished] == 'True']\n",
    "\n",
    "    mcColumns = findMCColumns(df, code)\n",
    "    mcColumns = [col for col in df.columns if '#' in col]\n",
    "    print(mcColumns)\n",
    "    print(df[colId].value_counts())\n",
    "    aggFuncs = {col: 'first' for col in df.columns if col not in mcColumns + rubricQues}\n",
    "    aggFuncs.update({col: custom_agg for col in mcColumns})\n",
    "    aggFuncs.update({col: 'max' for col in rubricQues})\n",
    "    df = df.groupby([colId], as_index=False).agg(aggFuncs)  \n",
    "    print(df[colId].value_counts()) \n",
    "    display(df[mcColumns].head())\n",
    "\n",
    "    pairs_df = getPairCounts(df)\n",
    "    pairs_df.to_excel(f'{folder}/ pairs.xlsx', index=False)\n",
    "    countsDf = dfTemplate.copy()\n",
    "    countsDf[colId] = df[colId]\n",
    "    countsDf['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['Total MC items'] = len(mcColumns)\n",
    "    \n",
    "    for q in rubricQues:\n",
    "        countsDf[q] = df[q]\n",
    "    for col in otherCols:\n",
    "        if col in df.columns:\n",
    "            countsDf[col] = df[col]\n",
    "\n",
    "    countsDf['MC Score'] = (countsDf['Yes'] + notReviewedW*countsDf['Not Reviewed']) / (countsDf['Yes'] + countsDf['No'] + notReviewedW*countsDf['Not Reviewed'])\n",
    "    countsDf['MC Score'] = countsDf['MC Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    display(countsDf.head())\n",
    "    \n",
    "    # display(countsDf[rubricQues])\n",
    "    countsDf[labelRubric] = countsDf.apply(lambda row: sum(row[ques] * rubricW[ques] / rubricDenom[ques] for ques in rubricQuesNoES), axis=1)/0.3\n",
    "    countsDf[labelRubric] = countsDf[labelRubric].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf['ES Weighted Score'] = countsDf['ES']/ rubricDenom['ES']\n",
    "    countsDf['ES Weighted Score'] = countsDf['ES Weighted Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf['Total Score'] = (mcScoreW*countsDf['MC Score'] + rubricScoreW*countsDf[labelRubric])*100\n",
    "    countsDf['Total Score'] = countsDf['Total Score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Add 20% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.8 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf['Total Score CE Penalty (20%)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Add 10% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.90 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf['Total Score CE Penalty (10%)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # countsDf['Total Score'] = (mcScoreW*countsDf['MC Score'] + rubricScoreW*countsDf['Rubric Weighted Score'])*100\n",
    "    # countsDf['Total Score'] = countsDf['Total Score'].apply(lambda x: round(x, 2))\n",
    "    # get correlation matrix between MC and Rubric bar ES and ES\n",
    "    countsDf['Item'] = key\n",
    "    # countsDf = countsDf[countsDf[colClinicType] == 'Paeds']\n",
    "    # display(countsDf.head())\n",
    "    countsDfPaed = pd.concat([countsDfPaed, countsDf])\n",
    "    average_scores = df.groupby('CE Name')['Total Score'].mean().reset_index()\n",
    "    # get counts of each CE Name\n",
    "    counts = df['CE Name'].value_counts().reset_index()\n",
    "    counts.columns = ['CE Name', 'Count']\n",
    "    display(counts)\n",
    "\n",
    "    # plot a bar chart of average scores\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='CE Name', y='Total Score', data=average_scores)\n",
    "    plt.title(f'Average Scores for examiners')\n",
    "    plt.xlabel('Examiner')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    # for i, row in df.iterrows():\n",
    "    #     if row[colClinicType] == 'Paeds':\n",
    "    #         print(f'Paeds row found: {row[colId]} {row[colDate]} {row[colSupervisor]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(countsDfPaed.head())\n",
    "correlation_matrix = countsDfPaed[['MC Score', labelRubric, 'ES Weighted Score']].corr()\n",
    "display(correlation_matrix)\n",
    "correlation_matrix.to_csv(f'{folder}\\\\correlation_matrix.csv')\n",
    "print(countsDfPaed[colId].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution of total scores\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(countsDfPaed['Total Score'], bins=range(0, 105, 5), ax=ax)\n",
    "ax.set_title('Distribution of Total Scores')\n",
    "ax.set_xlabel('Total Score')\n",
    "ax.set_xticks(range(0, 105, 5))\n",
    "\n",
    "# ES distribution\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(countsDfPaed['ES'], bins=[0,1,2,3,4], ax=ax)\n",
    "ax.set_title('Distribution of ES Scores')\n",
    "ax.set_xlabel('ES Weighted Score')\n",
    "ax.set_xticks([0,1,2,3,4])\n",
    "\n",
    "# MC distribution\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(countsDfPaed['MC Score'], bins=np.arange(0, 1.1, 0.1), ax=ax)\n",
    "ax.set_title('Distribution of MC Scores')\n",
    "ax.set_xlabel('MC Score')\n",
    "ax.set_xticks(np.arange(0, 1.1, 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsDfPaed.to_csv(f'{folder}/{filename} marks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endo and Fixed Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endo Guttman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notReviewedW = 0.5\n",
    "labelBlank = 'Not Filled'\n",
    "labelRubric = 'Rubric Score'\n",
    "rubricW = {'PS': 0.05, 'CS': 0.05, 'TS': .1, 'ES': .1} # This is simulation thus professionalism and communication are reduced weighted\n",
    "rubricDenom = {'PS': 2, 'CS': 2, 'TS': 4, 'ES': 4}\n",
    "mcScoreW = 0.8\n",
    "rubricScoreW = 0.2\n",
    "rubricQues = ['PS', 'CS', 'TS', 'ES']\n",
    "\n",
    "for key, df in dent90115Dict.items():\n",
    "    code = key.split('_')[0]\n",
    "    if not code.startswith('4'):\n",
    "        continue\n",
    "    print(key)\n",
    "    # Filter out the dates as 14th of August\n",
    "    # df[colDate] = pd.to_datetime(df[colDate])\n",
    "    # df = df[df[colDate].dt.day == 14] # 14th of August\n",
    "    # df = df[df[colDate].dt.month == 8]   # August\n",
    "    # df[colDate] = df[colDate].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "    mcColumns = findMCColumns(df, code)\n",
    "    df[colCEReason] = df[colCEReason].fillna(' ')\n",
    "    df[colCEReason] = df[colCEReason].astype(str)\n",
    "    display(df.head())\n",
    "    df = aggregator(df, mcColumns, colCE, colCEReason)\n",
    "    display(df.head())\n",
    "    # remove these columns ICC_MC1_supervisor\tICC_MC2_supervisor\tRKC_MC1_supervisor\tCC_MC1_supervisor Patient\tComplexity\tPatient Age\tRole Diagnostics\tOMFS Sim/Clinic\tGeneral services\tRem Pros CLINIC\tPaeds specific\tPreventive, Prophylactic and Bleaching Services\tPeriodontics\tEndodontics\tRestorative Services\tFixed Prosthodontics Weighted\tWeighted_penalty_10\tWeighted_penalty_20\n",
    "    df = df.drop(columns=['ICC_MC1_supervisor', 'ICC_MC2_supervisor', 'RKC_MC1_supervisor', 'CC_MC1_supervisor', 'Patient', 'Complexity', 'Patient Age', 'Role', 'Diagnostics', 'OMFS Sim/Clinic', 'General services', 'Rem Pros CLINIC', 'Paeds specific', 'Preventive, Prophylactic and Bleaching Services', 'Periodontics', 'Endodontics',\n",
    "                           'Restorative Services', 'Fixed Prosthodontics', 'Weighted', 'Weighted_penalty_10', 'Weighted_penalty_20'], errors='ignore')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Create Guttmann for each key\n",
    "    if len(df) == 0:\n",
    "        continue\n",
    "    df['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    df['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    df['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    df[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    \n",
    "    df['MC Score'] = (df['Yes'] + notReviewedW*df['Not Reviewed']) / (df['Yes'] + df['No'] + notReviewedW*df['Not Reviewed'])\n",
    "    df['MC Score'] = df['MC Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    df[labelRubric] = df.apply(lambda row: sum(row[ques] * rubricW[ques] / rubricDenom[ques] for ques in rubricQues), axis=1)/0.3\n",
    "    df[labelRubric] = df[labelRubric].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    df['Total Score'] = (mcScoreW*df['MC Score'] + rubricScoreW*df[labelRubric])*100\n",
    "    df['Total Score'] = df['Total Score'].apply(lambda x: round(x, 2))\n",
    "    df.sort_values('Total Score', ascending=False, inplace=True)    \n",
    "    # display(df.head())\n",
    "    saveDf(df, f'{folder}/{file} Endo.xlsx', key.replace('/', '-'), len(mcColumns) + 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBlank = 'Not Filled'\n",
    "otherCols = [colComplex, colDate, colFinished, colCE, colCEReason, colClinicType, colComments]\n",
    "labelRubric = 'Rubric Weighted Score'\n",
    "dfTemplate = pd.DataFrame(columns=[colId, 'Yes', 'No', 'Not Reviewed', labelBlank, 'Total MC items'] + rubricQues + ['MC Score', labelRubric, 'ES Weighted Score', 'Total Score', \n",
    "                                'Total Score CE Penalty (20%)', 'Total Score CE Penalty (10%)'] + otherCols +['Item'])\n",
    "notReviewedW = 0.5\n",
    "rubricW = {'PS': 0.05, 'CS': 0.05, 'TS': .1, 'ES': .1} # This is simulation thus professionalism and communication are reduced weighted\n",
    "rubricDenom = {'PS': 2, 'CS': 2, 'TS': 4, 'ES': 4}\n",
    "mcScoreW = 0.8\n",
    "rubricScoreW = 0.20\n",
    "# esW = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key0 = list(dent90115Dict.keys())[0]\n",
    "countsDfPaed = dfTemplate.copy()  \n",
    "rubricQuesNoES = rubricQues.copy()\n",
    "# rubricQuesNoES.remove('ES')\n",
    "for key, df in dent90115Dict.items():\n",
    "    print(key)\n",
    "    # check if 1383423, 1064909 and 1081787 are in the colId\n",
    "    if not 1383423 in df[colId].values:\n",
    "        print('1383423 not in the list')\n",
    "    if not 1064909 in df[colId].values:\n",
    "        print('1064909 not in the list')\n",
    "    if not 1081787 in df[colId].values:\n",
    "        print('1081787 not in the list')\n",
    "    code = key.split('_')[0]\n",
    "    # if not code.startswith('6'):\n",
    "    #     print(f'Skipping {code}\\n')\n",
    "    #     continue\n",
    "    df[colId] = df[colId].astype('Int64')\n",
    "    mcColumns = findMCColumns(df, code)\n",
    "    df = aggregator(df, mcColumns, colCE, colCEReason)\n",
    "    countsDf = dfTemplate.copy()\n",
    "    countsDf[colId] = df[colId]\n",
    "    countsDf['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "    countsDf['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "    countsDf['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "    countsDf[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "    countsDf['Total MC items'] = len(mcColumns)\n",
    "\n",
    "    for q in rubricQues:\n",
    "        countsDf[q] = df[q]\n",
    "    for col in otherCols:\n",
    "        countsDf[col] = df[col]\n",
    "\n",
    "    countsDf['MC Score'] = (countsDf['Yes'] + notReviewedW*countsDf['Not Reviewed']) / (countsDf['Yes'] + countsDf['No'] + notReviewedW*countsDf['Not Reviewed'])\n",
    "    countsDf['MC Score'] = countsDf['MC Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "\n",
    "    \n",
    "    countsDf[labelRubric] = countsDf.apply(lambda row: sum(row[ques] * rubricW[ques] / rubricDenom[ques] for ques in rubricQuesNoES), axis=1)/0.3\n",
    "    countsDf[labelRubric] = countsDf[labelRubric].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf['ES Weighted Score'] = countsDf['ES']/ rubricDenom['ES']\n",
    "    countsDf['ES Weighted Score'] = countsDf['ES Weighted Score'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf['Total Score'] = (mcScoreW*countsDf['MC Score'] + rubricScoreW*countsDf[labelRubric])*100\n",
    "    countsDf['Total Score'] = countsDf['Total Score'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Add 20% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.8 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (20%)'] = countsDf['Total Score CE Penalty (20%)'].apply(lambda x: round(x, 2))\n",
    "\n",
    "    # Add 10% penalty if critical error is yes\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf.apply(lambda row: row['Total Score'] * 0.90 if row[colCE] == 'Yes' else row['Total Score'], axis=1)\n",
    "    countsDf['Total Score CE Penalty (10%)'] = countsDf['Total Score CE Penalty (10%)'].apply(lambda x: round(x, 2))\n",
    "    \n",
    "    countsDf.sort_values('Total Score', ascending=False, inplace=True)\n",
    "\n",
    "    # countsDf['Total Score'] = (mcScoreW*countsDf['MC Score'] + rubricScoreW*countsDf['Rubric Weighted Score'])*100\n",
    "    # countsDf['Total Score'] = countsDf['Total Score'].apply(lambda x: round(x, 2))\n",
    "    # get correlation matrix between MC and Rubric bar ES and ES\n",
    "    countsDf['Item'] = key\n",
    "    \n",
    "    # display(countsDf.head())\n",
    "    countsDfPaed = pd.concat([countsDfPaed, countsDf])\n",
    "    # for i, row in df.iterrows():\n",
    "    #     if row[colClinicType] == 'Paeds':\n",
    "    #         print(f'Paeds row found: {row[colId]} {row[colDate]} {row[colSupervisor]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(countsDfPaed.head())\n",
    "correlation_matrix = countsDfPaed[['MC Score', labelRubric, 'ES Weighted Score']].corr()\n",
    "display(correlation_matrix)\n",
    "correlation_matrix.to_csv(f'{folder}\\\\correlation_matrix.csv')\n",
    "print(countsDfPaed[colId].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsDfPaed.sort_values(colId, inplace=True)\n",
    "countsDfPaed.to_excel(f'{folder}/{file} marks.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data on Student ID, take average of Total Score\n",
    "df = countsDfPaed.copy()\n",
    "df[colId] = df[colId].astype('Int64')\n",
    "aggFuncs = {col: 'first' for col in df.columns if col not in [colId, 'Item']}\n",
    "aggFuncs.update({'Total Score': 'mean', 'Total Score CE Penalty (20%)': 'mean', 'Total Score CE Penalty (10%)': 'mean'})\n",
    "df = df.groupby([colId], as_index=False).agg(aggFuncs)\n",
    "df['Total Score'] = df['Total Score'].apply(lambda x: round(x, 2))\n",
    "df['Total Score CE Penalty (20%)'] = df['Total Score CE Penalty (20%)'].apply(lambda x: round(x, 2))\n",
    "df['Total Score CE Penalty (10%)'] = df['Total Score CE Penalty (10%)'].apply(lambda x: round(x, 2))\n",
    "df = df[[colId, 'Total Score', colCE, colCEReason, 'Total Score CE Penalty (20%)', 'Total Score CE Penalty (10%)']]\n",
    "df.sort_values('Total Score', ascending=False, inplace=True)\n",
    "df.to_excel(f'{folder}/{file} marks aggregated.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ORAL20005'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ORAL20005'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['011_COE', '012_POE', '013_LIMITED OE', '022_I-O RAD', '111_CLINIC', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '121_SIM REMIN', '123_CLINIC', '131_CLINIC', '141_CLINIC', '161_CLINIC', '161_SIM', '221_CLINIC', '311_CLINIC'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(subjectDict.keys())\n",
    "for key in subjectDict.keys():\n",
    "    display(key)\n",
    "    display(subjectDict[key].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dent90115 = subjectDict['DENT90115']\n",
    "# display(dent90115.keys())\n",
    "# # create a workbook with keys as sheets\n",
    "# for key in dent90115.keys():\n",
    "#     saveDf(dent90115[key], f'{folder}/DENT90115.xlsx', key)\n",
    "\n",
    "# # merge all the sheets into one\n",
    "# df = pd.DataFrame()\n",
    "# for key in dent90115.keys():\n",
    "#     df = pd.concat([df, dent90115[key]])\n",
    "\n",
    "# saveDf(df, f'{folder}/DENT90115.xlsx', 'All')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we create report for each subject Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "011_COE 011 COE\n",
      "MC search pattern: 011_MC\\d+\n",
      "012_POE 012 POE\n",
      "MC search pattern: 012_MC\\d+\n",
      "013_LIMITED OE 013 LIMITED OE\n",
      "MC search pattern: 013_MC\\d+\n",
      "022_I-O RAD 022 I/O RAD\n",
      "MC search pattern: 022_MC\\d+\n",
      "111_CLINIC 111 CLINIC\n",
      "MC search pattern: 111_MC\\d+\n",
      "114_CLINIC 114 CLINIC\n",
      "MC search pattern: 114_MC\\d+\n",
      "115_CLINIC 115 CLINIC\n",
      "MC search pattern: 115_MC\\d+\n",
      "121_CLINIC REMIN 121 CLINIC REMIN\n",
      "MC search pattern: 121_MC\\d+\n",
      "121_SIM REMIN 121 SIM REMIN\n",
      "MC search pattern: 121_MC\\d+\n",
      "123_CLINIC 123 CLINIC\n",
      "MC search pattern: 123_MC\\d+\n",
      "131_CLINIC 131 CLINIC\n",
      "MC search pattern: 131_MC\\d+\n",
      "141_CLINIC 141 CLINIC\n",
      "MC search pattern: 141_MC\\d+\n",
      "161_CLINIC 161 CLINIC\n",
      "MC search pattern: 161_MC\\d+\n",
      "161_SIM 161 SIM\n",
      "MC search pattern: 161_MC\\d+\n",
      "221_CLINIC 221 CLINIC\n",
      "MC search pattern: 221_MC\\d+\n",
      "311_CLINIC 311 CLINIC\n",
      "MC search pattern: 311_MC\\d+\n",
      "[9.0, 7.0, 6.0, 8.0, 6.0, 7.0, 10.0, 9.0, 6.0, 8.0, 9.0, 7.0, 7.0, 9.0, 12.0, 12.0, 8.0, 9.0, 8.0, 7.0, 8.0, 6.0, 6.0, 8.0, 6.0, 6.0, 8.0, 10.0, 9.0, 8.0, 8.0, 6.0, 12.0, 9.0, 5.0, 5.0, 12.0, 8.0, 7.0, 8.0, 9.0, 10.0, 7.0, 9.0, 7.0, 9.0, 8.0, 6.0, 7.0, 9.0, 8.0, 7.0, 6.0, 7.0, 7.0, 6.0, 11.0, 9.0, 8.0, 9.0, 11.0, 8.0, 10.0, 7.0, 8.0, 5.0, 11.0, 5.0, 11.0, 10.0, 11.0, 5.0, 9.0, 11.0, 6.0, 8.0, 7.0, 5.0, 8.0, 8.0, 9.0, 8.0, 7.0, 8.0, 9.0, 7.0, 6.0, 9.0, 10.0, 9.0, 8.0, 6.0, 9.0, 7.0, 10.0, 9.0, 10.0, 11.0, 7.0, 7.0, 7.0, 7.0, 9.0, 5.0, 6.0, 8.0, 7.0, 8.0, 11.0, 7.0, 10.0, 8.0, 10.0, 9.0, 7.0, 7.0, 5.0, 5.0, 7.0, 5.0, 10.0, 8.0, 5.0, 5.0, 6.0, 10.0, 7.0, 12.0, 11.0, 6.0, 9.0, 10.0, 10.0, 5.0, 12.0, 11.0, 7.0, 6.0, 6.0, 8.0, 7.0, 7.0, 9.0, 7.0, 5.0, 6.0, 9.0, 6.0, 7.0, 7.0, 10.0, 6.0, 10.0, 10.0, 7.0, 9.0, 8.0, 6.0, 10.0, 8.0, 10.0, 7.0, 9.0, 7.0, 7.0, 11.0, 10.0, 9.0, 9.0, 7.0, 8.0, 8.0, 7.0, 8.0, 8.0, 6.0, 12.0, 9.0, 9.0, 9.0, 9.0, 10.0, 6.0, 8.0, 6.0, 8.0, 6.0, 6.0, 9.0, 7.0, 8.0, 8.0, 9.0, 5.0, 7.0, 5.0, 6.0, 9.0, 6.0, 11.0, 9.0, 9.0, 6.0, 5.0, 10.0, 5.0, 9.0, 8.0, 5.0, 5.0, 7.0, 5.0, 7.0, 5.0, 5.0, 9.0, 7.0, 5.0, 7.0, 9.0, 6.0, 8.0, 9.0, 8.0, 7.0, 6.0, 7.0, 12.0, 10.0, 7.0, 7.0, 8.0, 6.0, 7.0, 7.0, 7.0, 8.0, 7.0, 12.0, 7.0, 6.0, 7.0, 7.0, 9.0, 5.0, 10.0, 5.0, 9.0, 5.0, 5.0, 5.0, 5.0, 8.0, 6.0, 6.0, 6.0, 7.0, 8.0, 9.0, 9.0, 9.0, 5.0, 11.0, 7.0, 11.0, 6.0, 11.0, 5.0, 12.0, 11.0, 9.0, 5.0, 6.0, 10.0, 7.0, 11.0, 5.0, 5.0, 11.0, 10.0, 8.0, 5.0, 9.0, 8.0, 5.0, 10.0, 8.0, 11.0, 9.0, 10.0, 9.0, 12.0, 6.0, 9.0, 9.0, 5.0, 5.0, 10.0, 11.0, 6.0, 10.0, 7.0, 6.0, 6.0, 5.0, 5.0, 8.0, 6.0, 14.0, 11.0, 10.0, 8.0, 6.0, 11.0, 9.0, 12.0, 9.0, 5.0, 6.0, 10.0, 6.0, 6.0, 6.0, 6.0, 8.0, 6.0, 6.0, 6.0, 9.0, 6.0, 9.0, 8.0, 17.0, 9.0, 9.0, 9.0, 7.0, 5.0, 12.0, 11.0, 7.0, 12.0, 9.0, 7.0, 7.0, 5.0, 5.0, 9.0, 9.0, 9.0, 5.0, 8.0, 9.0, 6.0, 8.0, 5.0, 10.0, 6.0, 6.0, 11.0, 6.0, 12.0, 7.0, 5.0, 7.0, 5.0, 7.0, 6.0, 9.0, 7.0, 6.0, 6.0, 7.0, 9.0, 5.0, 6.0, 12.0, 10.0, 12.0, 7.0, 7.0, 7.0, 6.0, 9.0, 9.0, 10.0, 5.0, 8.0, 5.0, 6.0, 11.0, 10.0, 10.0, 11.0, 10.0, 11.0, 5.0, 6.0, 6.0, 9.0, 8.0, 9.0, 8.0, 6.0, 7.0, 10.0, 5.0, 9.0, 5.0, 6.0, 8.0, 5.0, 5.0, 5.0, 6.0, 12.0, 6.0, 11.0, 5.0, 8.0, 12.0, 11.0, 7.0, 3.0, 14.0, 5.0, 8.0, 6.0, 8.0, 5.0, 8.0, 5.0, 5.0, 8.0, 8.0, 5.0, 11.0, 15.0, 11.0, 6.0, 6.0, 9.0, 15.0, 6.0, 11.0, 7.0, 7.0, 9.0, 8.0, 6.0, 9.0, 9.0, 10.0, 6.0, 5.0, 10.0, 8.0, 9.0, 9.0, 6.0, 5.0, 5.0, 6.0, 5.0, 7.0, 6.0, 8.0, 9.0, 7.0, 6.0, 7.0, 7.0, 8.0, 12.0, 8.0, 6.0, 16.0, 6.0, 3.0, 3.0, 9.0, 7.0, 8.0, 9.0, 6.0, 7.0, 7.0, 12.0, 9.0, 8.0, 9.0, 12.0, 8.0, 11.0, 6.0, 8.0, 7.0, 8.0, 9.0, 8.0, 8.0, 12.0, 8.0, 8.0, 5.0, 7.0, 7.0, 6.0, 6.0, 8.0, 9.0, 8.0, 6.0, 10.0, 8.0, 10.0, 10.0, 9.0, 7.0, 7.0, 9.0, 5.0, 8.0, 9.0, 8.0, 9.0, 7.0, 9.0, 9.0, 7.0, 9.0, 9.0, 5.0, 11.0, 9.0, 8.0, 8.0, 5.0, 7.0, 7.0, 7.0, 8.0, 7.0, 9.0, 10.0, 9.0, 11.0, 3.0, 9.0, 9.0, 0.0, 6.0, 6.0, 8.0, 7.0, 5.0, 5.0, 6.0, 7.0, 9.0, 6.0, 7.0, 9.0, 5.0, 7.0, 6.0, 14.0, 8.0, 5.0, 7.0, 5.0, 6.0, 10.0, 10.0, 8.0, 7.0, 6.0, 8.0, 10.0, 9.0, 8.0, 10.0, 7.0, 7.0, 8.0, 10.0, 9.0, 9.0, 8.0, 6.0, 5.0, 10.0, 6.0, 10.0, 10.0, 9.0, 8.0, 8.0, 6.0, 7.0, 6.0, 6.0, 6.0, 6.0, 5.0, 9.0, 9.0, 10.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 5.0, 7.0, 5.0, 9.0, 5.0, 5.0, 6.0, 8.0, 5.0, 6.0, 7.0, 7.0, 7.0, 8.0, 5.0, 7.0, 7.0, 6.0, 5.0, 6.0, 7.0, 7.0, 5.0, 6.0, 8.0, 12.0, 12.0, 17.0, 7.0, 5.0, 11.0, 6.0, 9.0, 10.0, 8.0, 6.0, 8.0, 11.0, 6.0, 8.0, 8.0, 9.0, 6.0, 9.0, 10.0, 10.0, 9.0, 11.0, 7.0, 7.0, 9.0, 6.0, 6.0, 9.0, 12.0, 9.0, 5.0, 10.0, 5.0, 12.0, 14.0, 10.0, 9.0, 0.0, 8.0, 6.0, 8.0, 13.0, 11.0, 15.0, 6.0, 8.0, 10.0, 9.0, 7.0, 10.0, 8.0, 8.0, 7.0, 8.0, 8.0, 6.0, 8.0, 10.0, 11.0, 10.0, 8.0, 8.0, 9.0, 9.0, 10.0, 11.0, 10.0, 7.0, 9.0, 9.0, 9.0, 7.0, 5.0, 9.0, 9.0, 8.0, 9.0, 9.0, 8.0, 8.0, 8.0, 7.0, 11.0, 10.0, 10.0, 6.0, 6.0, 10.0, 9.0, 9.0, 5.0, 9.0, 7.0, 8.0, 7.0, 5.0, 10.0, 5.0, 12.0, 10.0, 9.0, 5.0, 5.0, 11.0, 9.0, 8.0, 9.0, 15.0, 9.0, 9.0, 5.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 12.0, 6.0, 10.0, 6.0, 9.0, 9.0, 6.0, 6.0, 6.0, 7.0, 11.0, 10.0, 9.0, 6.0, 8.0, 8.0, 11.0, 8.0, 10.0, 11.0, 8.0, 9.0, 9.0, 7.0, 8.0, 9.0, 10.0, 8.0, 8.0, 6.0, 8.0, 9.0, 7.0, 9.0, 8.0, 7.0, 5.0, 10.0, 8.0, 5.0, 10.0, 6.0, 6.0, 8.0, 6.0, 6.0, 8.0, 7.0, 5.0, 11.0, 8.0, 9.0, 10.0, 10.0, 7.0, 10.0, 9.0, 9.0, 7.0, 7.0, 9.0, 7.0, 7.0, 7.0, 9.0, 9.0, 6.0, 5.0, 7.0, 9.0, 6.0, 10.0, 9.0, 10.0, 5.0, 5.0, 9.0, 7.0, 7.0, 11.0, 5.0, 8.0, 7.0, 8.0, 6.0, 7.0, 6.0, 11.0, 9.0, 12.0, 5.0, 5.0, 9.0, 9.0, 7.0, 9.0, 5.0, 10.0, 5.0, 8.0, 7.0, 7.0, 6.0, 6.0, 5.0, 10.0, 6.0, 10.0, 6.0, 11.0, 7.0, 8.0, 7.0, 6.0, 10.0, 8.0, 9.0, 9.0, 8.0, 7.0, 8.0, 8.0, 8.0, 5.0, 9.0, 10.0, 8.0, 6.0, 9.0, 12.0, 8.0, 15.0, 6.0, 6.0, 8.0, 5.0, 7.0, 9.0, 7.0, 6.0, 5.0, 6.0, 9.0, 6.0, 7.0, 7.0, 8.0, 7.0, 9.0, 8.0, 7.0, 11.0, 9.0, 7.0, 7.0, 9.0, 6.0, 9.0, 6.0, 7.0, 10.0, 7.0, 7.0, 5.0, 8.0, 5.0, 7.0, 6.0, 9.0, 5.0, 8.0, 5.0, 5.0, 6.0, 5.0, 8.0, 5.0, 6.0, 9.0, 5.0, 7.0, 9.0, 9.0, 7.0, 6.0, 6.0, 7.0, 12.0, 5.0, 11.0, 11.0, 12.0, 10.0, 5.0, 8.0, 7.0, 7.0, 8.0, 6.0, 12.0, 10.0, 9.0, 5.0, 6.0, 10.0, 11.0, 12.0, 7.0, 6.0, 11.0, 6.0, 9.0, 7.0, 10.0, 6.0, 7.0, 9.0, 8.0, 9.0, 9.0, 7.0, 12.0, 5.0, 6.0, 5.0, 11.0, 9.0, 8.0, 8.0, 5.0, 9.0, 6.0, 6.0, 12.0, 5.0, 8.0, 11.0, 6.0, 6.0, 9.0, 5.0, 5.0, 7.0, 7.0, 8.0, 9.0, 6.0, 12.0, 10.0, 15.0, 10.0, 8.0, 8.0, 5.0, 6.0, 10.0, 12.0, 7.0, 5.0, 5.0, 6.0, 9.0, 15.0, 6.0, 8.0, 5.0, 10.0, 9.0, 10.0, 10.0, 9.0, 9.0, 10.0, 7.0, 6.0, 6.0, 8.0, 6.0, 10.0, 11.0, 9.0, 7.0, 7.0, 9.0, 8.0, 10.0, 6.0, 5.0, 6.0, 6.0, 1.0, 8.0, 9.0, 10.0, 9.0, 6.0, 8.0, 11.0, 9.0, 7.0, 6.0, 5.0, 6.0, 11.0, 12.0, 9.0, 9.0, 1.0, 1.0, 7.0, 9.0, 10.0, 8.0, 7.0, 7.0, 5.0, 5.0, 5.0, 7.0, 10.0, 11.0, 8.0, 10.0, 5.0, 5.0, 7.0, 8.0, 8.0, 11.0, 8.0, 8.0, 0.0, 8.0, 7.0, 9.0, 6.0, 7.0, 12.0, 0.0, 0.0, 8.0, 7.0, 11.0, 6.0, 5.0, 7.0, 0.0, 6.0, 11.0, 5.0, 10.0, 9.0, 7.0, 15.0, 5.0, 5.0, 11.0, 5.0, 6.0, 5.0, 6.0, 5.0, 5.0, 6.0, 12.0, 7.0, 6.0, 6.0, 8.0, 1.0, 5.0, 6.0, 12.0, 7.0, 1.0, 9.0, 9.0, 8.0, 12.0, 9.0, 10.0, 6.0, 9.0, 6.0, 9.0, 6.0, 11.0, 11.0, 8.0, 8.0, 8.0, 8.0, 6.0, 8.0, 6.0, 10.0, 6.0, 6.0, 8.0, 0.0, 8.0, 11.0, 7.0, 12.0, 8.0, 12.0, 9.0, 10.0, 12.0, 11.0, 11.0, 9.0, 7.0, 8.0, 8.0, 5.0, 8.0, 8.0, 9.0, 9.0, 12.0, 10.0, 8.0, 11.0, 9.0, 7.0, 11.0, 8.0, 11.0, 10.0, 6.0, 5.0, 10.0, 8.0, 9.0, 9.0, 9.0, 6.0, 7.0, 9.0, 10.0, 7.0, 8.0, 7.0, 9.0, 7.0, 10.0, 10.0, 7.0, 9.0, 5.0, 6.0, 9.0, 6.0, 7.0, 9.0, 10.0, 5.0, 6.0, 7.0, 10.0, 8.0, 5.0, 5.0, 5.0, 11.0, 5.0, 12.0, 8.0, 1.0, 7.0, 5.0, 9.0, 9.0, 7.0, 0.0, 5.0, 0.0, 9.0, 10.0, 10.0, 7.0, 6.0, 8.0, 11.0, 8.0, 7.0, 6.0, 0.0, 0.0, 11.0, 10.0, 0.0, 6.0, 8.0, 9.0, 6.0, 6.0, 6.0, 7.0, 10.0, 8.0, 6.0, 11.0, 8.0, 5.0, 7.0, 11.0, 9.0, 8.0, 8.0, 9.0, 5.0, 9.0, 8.0, 7.0, 8.0, 9.0, 5.0, 9.0, 11.0, 7.0, 7.0, 6.0, 11.0, 10.0, 8.0, 11.0, 10.0, 6.0, 9.0, 5.0, 7.0, 11.0, 9.0, 9.0, 7.0, 10.0, 5.0, 5.0, 8.0, 6.0, 9.0, 12.0, 8.0, 7.0, 7.0, 7.0, 5.0, 12.0, 7.0, 9.0, 9.0, 9.0, 11.0, 8.0, 7.0, 8.0, 11.0, 9.0, 11.0, 11.0, 7.0, 6.0, 8.0, 6.0, 6.0, 5.0, 9.0, 6.0, 8.0, 7.0, 7.0, 5.0, 5.0, 7.0, 7.0, 8.0, 6.0, 5.0, 9.0, 5.0, 10.0, 5.0, 6.0, 5.0, 9.0, 5.0, 9.0, 6.0, 5.0, 11.0, 8.0, 5.0, 9.0, 9.0, 7.0, 7.0, 6.0, 6.0, 7.0, 6.0, 11.0, 8.0, 12.0, 6.0, 9.0, 7.0, 7.0, 6.0, 12.0, 10.0, 9.0, 7.0, 6.0, 9.0, 10.0, 6.0, 7.0, 10.0, 7.0, 9.0, 8.0, 5.0, 9.0, 9.0, 7.0, 7.0, 7.0, 11.0, 11.0, 5.0, 6.0, 6.0, 5.0, 7.0, 6.0, 5.0, 10.0, 5.0, 7.0, 5.0, 5.0, 6.0, 9.0, 10.0, 8.0, 8.0, 7.0, 5.0, 5.0, 5.0, 11.0, 5.0, 9.0, 9.0, 10.0, 9.0, 10.0, 6.0, 5.0, 5.0, 6.0, 11.0, 5.0, 6.0, 7.0, 14.0, 12.0, 8.0, 15.0, 9.0, 10.0, 8.0, 5.0, 10.0, 12.0, 5.0, 8.0, 5.0, 5.0, 9.0, 6.0, 12.0, 5.0, 10.0, 3.0, 10.0, 9.0, 9.0, 1.0, 6.0, 9.0, 11.0, 6.0, 10.0, 9.0, 9.0, 14.0, 7.0, 8.0, 7.0, 8.0, 8.0, 10.0, 6.0, 8.0, 11.0, 7.0, 9.0, 9.0, 9.0, 10.0, 9.0, 16.0, 7.0, 7.0, 9.0, 9.0, 6.0, 9.0, 7.0, 8.0, 5.0, 9.0, 10.0, 6.0, 6.0, 7.0, 6.0, 9.0, 9.0, 11.0, 10.0, 12.0, 7.0, 15.0, 7.0, 10.0, 9.0, 9.0, 10.0, 5.0, 8.0, 9.0, 10.0, 8.0, 11.0, 8.0, 12.0, 7.0, 8.0, 11.0, 7.0, 5.0, 7.0, 8.0, 7.0, 5.0, 7.0, 8.0, 7.0, 11.0, 9.0, 8.0, 9.0, 5.0, 10.0, 6.0, 7.0, 5.0, 9.0, 8.0, 11.0, 6.0, 10.0, 5.0, 7.0, 7.0, 7.0, 12.0, 8.0, 11.0, 6.0, 6.0, 8.0, 8.0, 8.0, 6.0, 6.0, 9.0, 9.0, 6.0, 9.0, 9.0, 9.0, 12.0, 7.0, 10.0, 12.0, 10.0, 6.0, 7.0, 6.0, 12.0, 9.0, 9.0, 12.0, 12.0, 8.0, 8.0, 7.0, 11.0, 5.0, 10.0, 8.0, 17.0, 11.0]\n"
     ]
    }
   ],
   "source": [
    "labelYes= 'Yes'\n",
    "labelNo = 'No'\n",
    "labelNA = 'Not Reviewed'\n",
    "labelBlank = 'Left blank as part of form updates'\n",
    "# colDate = 'RecordedDate'\n",
    "with open(variableUtils.mcReferenceFile) as f:\n",
    "    mcReferenceDict = json.load(f)\n",
    "\n",
    "with open(variableUtils.othermcReferenceFile) as f:\n",
    "    othermcReferenceDict = json.load(f)\n",
    "\n",
    "otherMcRefdf = pd.DataFrame(list(othermcReferenceDict.items()), columns=['Abbreviation', 'Full Text'])\n",
    "\n",
    "def custom_agg(series):\n",
    "    unique_vals = series.dropna().unique()\n",
    "    if len(unique_vals) == 0: # All values are NA\n",
    "        return pd.NA\n",
    "    if len(unique_vals) == 1: # Only one unique value \n",
    "        return unique_vals[0]\n",
    "    else:\n",
    "        if '1' in unique_vals:\n",
    "            return '1'\n",
    "        elif '0' in unique_vals:\n",
    "            return '0'\n",
    "        else:\n",
    "            return pd.NA\n",
    "        \n",
    "def getCounts(df, col, dfCount, items):\n",
    "    roleCounts = df[col].value_counts()\n",
    "    for role, count in roleCounts.items():\n",
    "        if role not in dfCount.columns:\n",
    "            dfCount[role] = 0  # Add the new role as a column with zeros\n",
    "        dfCount.at[items, role] = count\n",
    "    # display(df[colPatient].value_counts())\n",
    "    # display(df[colRole].value_counts())\n",
    "    # display(dfCount)\n",
    "\n",
    "def getValueCounts(df, targetColumn, colId):\n",
    "    counts = df.groupby(colId)[targetColumn].value_counts().unstack(fill_value=0)\n",
    "    counts.reset_index(inplace=True)\n",
    "    # make colId the index\n",
    "    counts.set_index(colId, inplace=True)\n",
    "    return counts\n",
    "\n",
    "# create one PDF for each subject\n",
    "testSubject = 'ORAL20005'\n",
    "\n",
    "def createDfs(testSubject, subjectDict, label = None): # label is either Simulation or Clinic\n",
    "    \"\"\"\n",
    "    Create a DataFrame with the counts for each item in the subject\n",
    "    \"\"\"\n",
    "    countsDfMCDict = {}\n",
    "    countsDfStudDict = {}\n",
    "    countsDfRoleDict = {}\n",
    "    countsDfPatientDict = {}\n",
    "    countsDfRKCDict = {}                              # for other checklist items\n",
    "    itemReferenceDict = {}\n",
    "    ageList = []\n",
    "    \n",
    "    itemCountsDf = pd.DataFrame(index = subjectDict[testSubject].keys(), columns = ['Yes', 'No', 'Not Reviewed', labelBlank]) # to store the counts for each item in the subject\n",
    "    itemLenDf = pd.DataFrame(index = subjectDict[testSubject].keys(), columns = ['Length']) # to store the length of each item in the subject\n",
    "    itemRoleDf = pd.DataFrame(index = subjectDict[testSubject].keys(), columns = []) # to store the role of each item in the subject\n",
    "    itemPatientDf = pd.DataFrame(index = subjectDict[testSubject].keys(), columns = []) # to store the patient of each item in the subject\n",
    "    itemCIDf = pd.DataFrame(columns = [colId, 'Date', 'Item', 'Reason']) # to store the critical incidents of each item in the subject\n",
    "    \n",
    "    for items in subjectDict[testSubject].keys():\n",
    "        code = items.split('_')[0]\n",
    "        tag = items.split('_')[1]\n",
    "        tag = tag.replace('-', '/')\n",
    "        # select items from mcReferenceDict with {code}_MC\\d+ as key\n",
    "        print(items, code, tag)\n",
    "        respectiveMCKey = [key for key in mcReferenceDict.keys() if re.match(f'{code}_MC\\d+', key)]\n",
    "        respectiveMCKey = [key for key in respectiveMCKey if tag in key]\n",
    "        # get the dict part of mcReferenceDict based on the respectiveMCKey\n",
    "        mcRef = {key: mcReferenceDict[key] for key in respectiveMCKey}\n",
    "        # print(mcRef)\n",
    "        # Trun mcRef into a DataFrame\n",
    "        if mcRef:\n",
    "            mcRefdf = pd.DataFrame(list(mcRef.items()), columns=['Abbreviation', 'Full Text'])\n",
    "        \n",
    "            # extract MC\\d+ from Abbreviation and replace it\n",
    "            if code!= '114' and code != '115':\n",
    "                mcRefdf['MC'] = mcRefdf['Abbreviation'].str.extract(r'(MC\\d+)')\n",
    "            else:\n",
    "                mcRefdf['MC'] = mcRefdf['Abbreviation'].str.extract(r'(MC\\d+)')\n",
    "                extracted_values = mcRefdf['Abbreviation'].str.extract(r'(H/S|U/S)', expand=False)\n",
    "                # print(extracted_values)\n",
    "                # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "                mcRefdf['MC'] = mcRefdf['MC'] + ' ' + extracted_values\n",
    "            # drop the Abbreviation column\n",
    "            # print(mcRefdf.columns)\n",
    "            # Swap columns\n",
    "            mcRefdf = mcRefdf[['MC', 'Full Text']]\n",
    "            # mcRefdf.drop(columns=['Abbreviation'], inplace=True)\n",
    "            # display(mcRefdf)\n",
    "        \n",
    "        else:\n",
    "            print(mcRef)\n",
    "            mcRefdf = None\n",
    "        itemReferenceDict[items] = mcRefdf\n",
    "\n",
    "        # print(respectiveMCKey)\n",
    "        df = subjectDict[testSubject][items]\n",
    "        mcColumns = findMCColumns(df, code)        \n",
    "        calcColumns = mcColumns + rubricQues\n",
    "        # print(mcColumns)\n",
    "\n",
    "        # display(items)\n",
    "        \n",
    "        # get highest value count from colClinicChoice\n",
    "        if label is not None:\n",
    "            countsClinic = df[colClinicChoice].value_counts()\n",
    "            highestClinic = countsClinic.idxmax()\n",
    "            # print(highestClinic, label)\n",
    "            if label == 'Simulation' and label != highestClinic:\n",
    "                print('Skipping', items)\n",
    "                continue\n",
    "            elif label == 'Clinic' and highestClinic == 'Simulation':\n",
    "                print('Skipping', items)\n",
    "                continue\n",
    "\n",
    "        # print colId type\n",
    "        # display(df[colId].dtype)\n",
    "        df[colId] = df[colId].astype(int)\n",
    "        # remove test  values like 111111 or 123456 from colId float dtype\n",
    "        df = df[~df[colId].isin(invalidIDs)]\n",
    "        # display(df.head())\n",
    "\n",
    "\n",
    "        # Aggregate if tag is SIM (Take the best value for each column for each student)\n",
    "        if tag == 'SIM':\n",
    "            # Step 1: Define the aggregation functions for each group of columns\n",
    "            aggFuncs = {col: 'first' for col in df.columns if col not in mcColumns + rubricQues}\n",
    "            aggFuncs.update({col: custom_agg for col in mcColumns})\n",
    "            aggFuncs.update({col: 'max' for col in rubricQues})\n",
    "            df = df.groupby([colDate, colId], as_index=False).agg(aggFuncs)      # Step 2: Apply the combined aggregation functions\n",
    "\n",
    "\n",
    "        # Get age distribution\n",
    "        ageList += df[colAge].tolist()\n",
    "\n",
    "\n",
    "        # Create a DataFrame to store the counts for each MC column\n",
    "        countsDfMC = pd.DataFrame(index=mcColumns, columns=['Yes', 'No', 'Not Reviewed', labelBlank])\n",
    "        for col in mcColumns:\n",
    "            countsDfMC.at[col, 'Yes'] = (df[col] == 1).sum()\n",
    "            countsDfMC.at[col, 'No'] = (df[col] == 0).sum()\n",
    "            countsDfMC.at[col, 'Not Reviewed'] = (df[col] == 'NA').sum()\n",
    "            countsDfMC.at[col, labelBlank] = (df[col] == '').sum() + df[col].isna().sum()\n",
    "        \n",
    "        # sort based on MC column\n",
    "        countsDfMC['_sort_key'] = countsDfMC.index\n",
    "        # extract digit\n",
    "        countsDfMC['_sort_key'] = countsDfMC['_sort_key'].str.extract(r'MC(\\d+)').astype(int)\n",
    "        # display(countsDfMC)\n",
    "        countsDfMC.sort_values(by='_sort_key', inplace=True)\n",
    "        countsDfMC.drop(columns=['_sort_key'], inplace=True)\n",
    "        countsDfMCDict[items] = countsDfMC\n",
    "        # display(countsDfMC)\n",
    "\n",
    "        # Create a DataFrame to store the counts for each student\n",
    "        countsDfStu = pd.DataFrame(index=df.index, columns=['Yes', 'No', 'Not Reviewed', labelBlank])\n",
    "        countsDfStu['Yes'] = df[mcColumns].apply(lambda x: (x == 1).sum() + (x=='1').sum(), axis=1)\n",
    "        countsDfStu['No'] = df[mcColumns].apply(lambda x: (x == 0).sum() + (x=='0').sum(), axis=1)\n",
    "        countsDfStu['Not Reviewed'] = df[mcColumns].apply(lambda x: (x == 'NA').sum(), axis=1)\n",
    "        countsDfStu[labelBlank] = df[mcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=1)\n",
    "        countsDfStu[colId] = df[colId]\n",
    "        countsDfStu['Yes/No'] = countsDfStu['Yes'] / (countsDfStu['Yes'] + countsDfStu['No'])\n",
    "        countsDfStu = countsDfStu.groupby(colId).agg('sum')     # merge the rows on the same student ID\n",
    "        countsDfStudDict[items] = countsDfStu\n",
    "\n",
    "        # Create a DataFrame to store the counts for RKC, CC, ICC, PEC\n",
    "        # remove the _supervisor from the column names\n",
    "        df.columns = [re.sub(r'_supervisor', '', col) for col in df.columns]\n",
    "        rkcColumns = findChecklistColumns(df, checklistMap)\n",
    "        countsOtherChecklist = pd.DataFrame(index=rkcColumns, columns=['Yes', 'No', 'Not Reviewed', labelBlank])\n",
    "        countsOtherChecklist['Yes'] = df[rkcColumns].apply(lambda x: (x == 1).sum(), axis=0)\n",
    "        # display(df[rkcColumns].apply(lambda x: (x == 'Yes').sum(), axis=0))\n",
    "        countsOtherChecklist['No'] = df[rkcColumns].apply(lambda x: (x == 0).sum(), axis=0)\n",
    "        countsOtherChecklist['Not Reviewed'] = df[rkcColumns].apply(lambda x: (x == 'NA').sum(), axis=0)\n",
    "        countsOtherChecklist[labelBlank] = df[rkcColumns].apply(lambda x: (x == '').sum() + x.isna().sum() + (x=='None').sum(), axis=0)\n",
    "        countsDfRKCDict[items] = countsOtherChecklist\n",
    "        # print(items)\n",
    "        # remove rows with values in Yes, No and Not Reviewed as 0\n",
    "        # countsOtherChecklist = countsOtherChecklist[(countsOtherChecklist['Yes'] != 0) | (countsOtherChecklist['No'] != 0) | (countsOtherChecklist['Not Reviewed'] != 0)]\n",
    "\n",
    "        # print(rkcColumns)\n",
    "        # display(countsOtherChecklist)\n",
    "        \n",
    "        # Get counts of values from colRole and colPatient for each student\n",
    "        if tag != 'SIM':\n",
    "            # Create a DataFrame to store the counts for each role for each student\n",
    "            countsDfRole = getValueCounts(df, colRole, colId)\n",
    "            countsDfRoleDict[items] = countsDfRole\n",
    "            # display(countsDfRole.head())\n",
    "            # display(countsDfRole[colId].value_counts())\n",
    "\n",
    "            # Create a DataFrame to store the counts for each patient for each student\n",
    "            countsDfPatient = getValueCounts(df, colPatient, colId)\n",
    "            countsDfPatientDict[items] = countsDfPatient\n",
    "            # display(countsDfPatient.head())\n",
    "            # display(countsDfRole[colId].value_counts())\n",
    "\n",
    "        # Add the sum of the counts to the itemCountsDf\n",
    "        itemCountsDf.at[items, 'Yes'] = countsDfMC['Yes'].sum()\n",
    "        itemCountsDf.at[items, 'No'] = countsDfMC['No'].sum()\n",
    "        itemCountsDf.at[items, 'Not Reviewed'] = countsDfMC['Not Reviewed'].sum()\n",
    "        itemCountsDf.at[items, labelBlank] = countsDfMC[labelBlank].sum()\n",
    "\n",
    "        # Add the length of the item to the itemLenDf\n",
    "        itemLenDf.at[items, 'Length'] = len(df)\n",
    "\n",
    "        # Get counts of values from colPatient and colRole for entire item\n",
    "        if tag != 'SIM':\n",
    "            getCounts(df, colRole, itemRoleDf, items)\n",
    "            # remove rows with total values of less than 2\n",
    "            itemRoleDf = itemRoleDf[itemRoleDf.sum(axis=1) > 2]\n",
    "            getCounts(df, colPatient, itemPatientDf, items)\n",
    "        # display(itemRoleDf.head())\n",
    "        # display(itemPatientDf.head())\n",
    "        # break\n",
    "\n",
    "        # Get the info for critical incidents\n",
    "        criticalDf = df[df[colCE] == 'Yes']\n",
    "        # Loop through each row in the filtered DataFrame\n",
    "        rows = []\n",
    "        for index, row in criticalDf.iterrows():\n",
    "            # print(colId, row[colId])\n",
    "            newRow = {\n",
    "                colId: row[colId],\n",
    "                'Date': row[colDate],\n",
    "                'Item': items.replace('_', ' '),\n",
    "                'Reason': row[colCEReason]\n",
    "            }\n",
    "            rows.append(newRow)\n",
    "        itemCIDf = pd.concat([itemCIDf, pd.DataFrame(rows)], ignore_index=True)\n",
    "    # display(itemCIDf)\n",
    "    # collect items with 2or less rows\n",
    "    removeItems = itemLenDf[itemLenDf['Length'] <= 2].index\n",
    "    # itemLenDf = itemLenDf[itemLenDf['Length'] > 1]\n",
    "    # itemCountsDf = itemCountsDf.drop(removeItems)\n",
    "    # print(ageList)\n",
    "    return countsDfMCDict, countsDfStudDict, countsDfRoleDict, \\\n",
    "countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems \n",
    "# display(itemCountsDf)\n",
    "\n",
    "    \n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf,\\\n",
    "itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems = createDfs(testSubject, subjectDict, 'Clinic')\n",
    "print(ageList)\n",
    "# display(itemRoleDf.head())\n",
    "# display(itemPatientDf.head())\n",
    "# display(itemLenDf)\n",
    "# display(itemCountsDf)\n",
    "# print(removeItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Full Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PEC MC1</td>\n",
       "      <td>Adjusts clinician chair correctly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEC MC2</td>\n",
       "      <td>Maintains good posture, positioning of self, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICC MC1</td>\n",
       "      <td>Maintains standards infection control througho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC MC2</td>\n",
       "      <td>Handles and disposes of sharps in a safe manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RKC MC1</td>\n",
       "      <td>Maintains accurate, consistent, legible and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CC MC1</td>\n",
       "      <td>Obtains informed consent from the parent/ guar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Abbreviation                                          Full Text\n",
       "0      PEC MC1                  Adjusts clinician chair correctly\n",
       "1      PEC MC2  Maintains good posture, positioning of self, p...\n",
       "2      ICC MC1  Maintains standards infection control througho...\n",
       "3      ICC MC2    Handles and disposes of sharps in a safe manner\n",
       "4      RKC MC1  Maintains accurate, consistent, legible and co...\n",
       "5       CC MC1  Obtains informed consent from the parent/ guar..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherMcRefdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841.68, 1190.8799999999999)\n"
     ]
    }
   ],
   "source": [
    "pageSize = (11.69 * 1* inch, 8.27 * 2 * inch) # page size\n",
    "print(pageSize)\n",
    "figsize = (pageSize[0] / 100, pageSize[1] / 100)\n",
    "subplots_per_page = 2\n",
    "# Define the margins\n",
    "leftMargin = 0 * inch\n",
    "rightMargin = 0 * inch\n",
    "topMargin = 1 * inch\n",
    "bottomMargin = 0 * inch\n",
    "\n",
    "# Define the styles for the headings\n",
    "styles = getSampleStyleSheet()\n",
    "styles.add(ParagraphStyle(name='Center', alignment=1))  # Center alignment\n",
    "headingStyle = ParagraphStyle('Heading1', parent=styles['Heading1'], fontSize=32, alignment=1)  # Centered\n",
    "subheadingStyle = ParagraphStyle('Heading2', parent=styles['Heading2'], fontSize=24, alignment=1)  # Centered\n",
    "subsubheadingStyle = ParagraphStyle('Heading3', parent=styles['Heading3'], fontSize=20, alignment=1)  # Centered\n",
    "Checklistcolors = {'Yes': 'blue', 'No': 'orange', 'Not Reviewed': 'lightgrey', labelBlank: 'white'}\n",
    "# Set the colorblind-friendly palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Function to create and return a plot image as BytesIO\n",
    "def create_plot_image(fig):\n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        return buf\n",
    "\n",
    "# Function to create a single subplot\n",
    "def create_subplot(ax, subset, count=False, show_legend=False, colors = None, xticks = None):\n",
    "    # drop labelBlank column if it exists\n",
    "    if labelBlank in subset.columns:\n",
    "        subset = subset.drop(columns = [labelBlank])\n",
    "    # display(subset)\n",
    "    if count:\n",
    "        # display(subset)\n",
    "        subset.plot(kind='bar', ax=ax, edgecolor='black', color='#87CEEB', legend=False)\n",
    "    else:\n",
    "        if colors is not None:\n",
    "            subset.plot(kind='bar', stacked=True, ax=ax, edgecolor='black', color=colors, legend=show_legend)\n",
    "        else:\n",
    "            subset.plot(kind='bar', stacked=True, ax=ax, edgecolor='black', legend=show_legend)\n",
    "        # Add the legend only if show_legend is True\n",
    "        if show_legend:\n",
    "            ax.legend(title='', loc='upper right', bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Count')\n",
    "    desired_ticks = range(len(xticks))\n",
    "    # print(desired_ticks)\n",
    "    # ax.set_xticks(range(len(xticks)))\n",
    "    # ax.set_xticklabels(xticks)\n",
    "    # y ticks should be integers\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    # Show gridlines on the y-axis\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "    # Convert index to strings to avoid errors with re.sub\n",
    "    subset.index = [str(i) for i in subset.index]\n",
    "    # x tick labels, remove _ and put space\n",
    "    subset.index = [re.sub(r'_', ' ', i) for i in subset.index]\n",
    "    ax.set_xticklabels(subset.index, rotation=90, ha='center')\n",
    "\n",
    "# Function to add graphs to the document\n",
    "def addGraphs(countsDf, elements, onlyCount=False, sortColumn=None, colors = None, startingSubplots = None):\n",
    "    df = countsDf.copy()\n",
    "    # Add a column for the total count\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    # Sort the DataFrame based on the total count in descending order\n",
    "    if sortColumn is not None:\n",
    "        df = df.sort_values(by=sortColumn, ascending=False)\n",
    "    # Remove the rows with 0 total\n",
    "    df = df[df['Total'] != 0]\n",
    "    if not onlyCount and (df['Total'] == df[labelBlank]).all():\n",
    "        elements.append(Paragraph(\"No data available yet\", subsubheadingStyle))\n",
    "        return 100\n",
    "    # Drop the 'Total' column after sorting\n",
    "    df = df.drop(columns=['Total', 'Yes/No'], errors='ignore')\n",
    "\n",
    "    # Number of rows and columns for subplots\n",
    "    max_bars_per_subplot = 12\n",
    "    num_subplots = len(df) // max_bars_per_subplot + (1 if len(df) % max_bars_per_subplot > 0 else 0)\n",
    "    # subplots_per_page = 2\n",
    "    \n",
    "    # Display starting subplots number of plots on the first page\n",
    "    if startingSubplots is None:\n",
    "        startingSubplots = subplots_per_page\n",
    "        lastPageSubplots = num_subplots % subplots_per_page\n",
    "    else:\n",
    "        alreadyNumPlots = 3 - startingSubplots\n",
    "        if alreadyNumPlots + num_subplots <= 3:\n",
    "            lastPageSubplots = (alreadyNumPlots + num_subplots)\n",
    "        else:\n",
    "            lastPageSubplots = abs(num_subplots - startingSubplots) % subplots_per_page\n",
    "        startingSubplots = min(startingSubplots, num_subplots)\n",
    "\n",
    "    # figsize = (11.69, 15.54)  # A3 size in inches\n",
    "    # get the suplots being plotted on the last page\n",
    "    # lastPageSubplots = (num_subplots - startingSubplots) % subplots_per_page\n",
    "    # Loop over the DataFrame and create subplots\n",
    "    # for i in range(0, num_subplots, subplots_per_page):\n",
    "    i = 0\n",
    "    while i < num_subplots:\n",
    "        if i == 0:\n",
    "                current_subplots = startingSubplots\n",
    "        else:\n",
    "                current_subplots = subplots_per_page\n",
    "        # print(i, current_subplots, (figsize[0], figsize[1] / subplots_per_page * current_subplots))\n",
    "        fig, axes = plt.subplots(nrows=current_subplots, ncols=1, figsize=(figsize[0], figsize[1] / 3 * current_subplots))\n",
    "        if current_subplots == 1:\n",
    "            axes = [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        for j in range(current_subplots):\n",
    "            idx = i + j\n",
    "            if idx < num_subplots:\n",
    "                start_idx = idx * max_bars_per_subplot\n",
    "                end_idx = start_idx + max_bars_per_subplot\n",
    "                subset = df.iloc[start_idx:end_idx]\n",
    "                xticks = subset.index\n",
    "                # If there are fewer than max_bars_per_subplot, pad with empty rows\n",
    "                if len(subset) < max_bars_per_subplot:\n",
    "                    empty_rows = pd.DataFrame(0, index=[''] * (max_bars_per_subplot - len(subset)), columns=subset.columns)\n",
    "                    subset = pd.concat([subset, empty_rows])\n",
    "                # Show legend only for the first subplot\n",
    "                create_subplot(axes[j], subset, onlyCount, show_legend=(i == 0 and j == 0), colors=colors, xticks=xticks)\n",
    "            else:\n",
    "                axes[j].remove()\n",
    "        i+=current_subplots\n",
    "        # fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1, 1), bbox_transform=fig.transFigure)\n",
    "        plt.subplots_adjust(hspace=0.4)\n",
    "        # plt.suptitle('Counts for each item')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 1])  # Adjust layout to make room for the legend\n",
    "        plotImage = create_plot_image(fig)\n",
    "        image = Image(plotImage)\n",
    "        # print(image.drawWidth, image.drawHeight)\n",
    "        \n",
    "        # Resize image to fit within A3 page\n",
    "        max_height = pageSize[1]  # Max height for A3 in points\n",
    "        max_width = pageSize[0]  # Max width for A3 in points\n",
    "        aspect_ratio = min(max_width / image.drawWidth, max_height / image.drawHeight)\n",
    "        image.drawWidth *= aspect_ratio\n",
    "        image.drawHeight *= aspect_ratio\n",
    "        # print(image.drawWidth, image.drawHeight, aspect_ratio)\n",
    "        elements.append(image)\n",
    "        # if idx + 1 < num_subplots:\n",
    "        #     elements.append(PageBreak())\n",
    "        # elements.append(PageBreak())\n",
    "        plt.close(fig)\n",
    "    \n",
    "    if lastPageSubplots == 0:\n",
    "        lastPageSubplots = subplots_per_page\n",
    "    return lastPageSubplots\n",
    "\n",
    "def addLengthGraph(itemLenDf, elements):\n",
    "    \"\"\"\n",
    "    Add a graph for the length of each item\n",
    "    \"\"\"\n",
    "    subheading = Paragraph(\"Number of forms filled for each item\", subheadingStyle)\n",
    "    elements.append(subheading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    subplotcount = addGraphs(itemLenDf, elements, onlyCount=True, sortColumn='Length')\n",
    "    if subplotcount > (subplots_per_page - 1):\n",
    "        elements.append(PageBreak())\n",
    "        firstpagesubplots = None\n",
    "    else:\n",
    "        firstpagesubplots = subplots_per_page - subplotcount\n",
    "    print(f'After Length subplotcount: {subplotcount}')\n",
    "    return firstpagesubplots\n",
    "\n",
    "def addOverallMCGraph(itemCountsDf, elements, firstpagesubplots=None):\n",
    "    subheading = Paragraph(\" Marking Checklist Counts for each item\", subheadingStyle)\n",
    "    elements.append(subheading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    subplotcount = addGraphs(itemCountsDf, elements, onlyCount=False, sortColumn='Total', \n",
    "                             colors=Checklistcolors, startingSubplots=firstpagesubplots)\n",
    "    if subplotcount > (subplots_per_page - 1):\n",
    "        elements.append(PageBreak())\n",
    "        firstpagesubplots = None\n",
    "    else:\n",
    "        firstpagesubplots = subplots_per_page - subplotcount\n",
    "    print(f'After MC overall subplotcount: {subplotcount}')\n",
    "    return firstpagesubplots    \n",
    "    \n",
    "def addAgeHistogram(ageList, elements):\n",
    "    fig, ax = plt.subplots(figsize=(figsize[0], figsize[1]/2.2))  # A3 size in inches (landscape)\n",
    "    # want 20 bins\n",
    "    \n",
    "    bins = list(range(0, 20, 2))  # Bins from 0 to 100 with step of 5\n",
    "    # take max into account\n",
    "    # bins = list(range(0, max(ageList) + 5, max((max(ageList)+5) // 20), 1))\n",
    "    ax.hist(ageList, bins=bins, edgecolor='black')\n",
    "    ax.set_title('')\n",
    "    ax.set_xlabel('Age')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_xticks(list(bins))\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 1])  # Adjust layout to make room for the legend\n",
    "    plotImage = create_plot_image(fig)\n",
    "    image = Image(plotImage)\n",
    "    \n",
    "    # Resize image to fit within A3 page\n",
    "    max_height = pageSize[1]  # Max height for A3 in points\n",
    "    max_width = pageSize[0]  # Max width for A3 in points\n",
    "    aspect_ratio = min(max_width / image.drawWidth, max_height / image.drawHeight)\n",
    "    image.drawWidth *= aspect_ratio\n",
    "    image.drawHeight *= aspect_ratio\n",
    "    \n",
    "    elements.append(image)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def addOverallRoleGraph(itemRoleDf, elements, firstpagesubplots=None):\n",
    "    subheading = Paragraph(\"Role counts for each item\", subheadingStyle)\n",
    "    elements.append(subheading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    addGraphs(itemRoleDf, elements, False, 'Total', None)\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "def addOverallPatientGraph(itemPatientDf, elements, firstpagesubplots=None):\n",
    "    subheading = Paragraph(\"Patient counts for each item\", subheadingStyle)\n",
    "    elements.append(subheading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    addGraphs(itemPatientDf, elements, False, 'Total', None)\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "def addMCReferenceTable(mcRefdf, elements, code= None):\n",
    "    header = f\"Marking Checklist Reference for {code}\" if code is not None else \"Marking Checklist Reference\"\n",
    "    elements.append(Paragraph(header, subheadingStyle))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    if mcRefdf is None:\n",
    "        elements.append(Paragraph(\"No marking checklist reference found\", subsubheadingStyle))\n",
    "        return\n",
    "    largeFontStyle = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=13, alignment=0)\n",
    "\n",
    "    # Create a table with MC and Full Text columns\n",
    "    data = [mcRefdf.columns.to_list()] + mcRefdf.values.tolist()\n",
    "    for i in range(1, len(data)):\n",
    "        data[i][1] = Paragraph(data[i][1], largeFontStyle)\n",
    "        data[i][0] = Paragraph(data[i][0], largeFontStyle)\n",
    "    table = Table(data, colWidths=[1.5 * inch, 9 * inch])\n",
    "\n",
    "    # Set the style for the table text as large font\n",
    "    \n",
    "\n",
    "    table_style = TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#9C27B0')),  # Header row\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "        ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),  # Increase bottom padding\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 12),  # Increase top padding\n",
    "    ])\n",
    "    table.setStyle(table_style)\n",
    "    elements.append(table)\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "\n",
    "\n",
    "def addCriticalIncidents(itemCIDf, elements):\n",
    "    styles = getSampleStyleSheet()\n",
    "    # Ensure itemCIDf is not empty\n",
    "    elements.append(Paragraph(\"Critical Incidents\", subheadingStyle))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    if itemCIDf.empty:\n",
    "        elements.append(Paragraph(\"No critical incidents reported\", subsubheadingStyle))\n",
    "        return\n",
    "    \n",
    "    itemCICountDf = itemCIDf[colId].value_counts().reset_index()  # Group by the 'colId' column and count the occurrences\n",
    "    itemCICountDf.columns = [colId, '# Critical Incidents']  # Rename the columns to 'student_id' and 'count'\n",
    "    itemCICountDf.sort_values(by=colId, inplace=True)     # Sort the DataFrame by 'student_id'\n",
    "    itemCICountDf['# Critical Incidents'] = itemCICountDf['# Critical Incidents'].astype(str)\n",
    "    itemCICountDf[colId] = itemCICountDf[colId].astype(str)\n",
    "    \n",
    "    header = \"Critical Errors Count\"\n",
    "    elements.append(Paragraph(header, subheadingStyle))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    largeFontStyle1 = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=13, alignment=1)\n",
    "\n",
    "    # Create a table with MC and Full Text columns\n",
    "    data = [itemCICountDf.columns.to_list()] + itemCICountDf.values.tolist()\n",
    "    for i in range(1, len(data)):\n",
    "        data[i][1] = Paragraph(data[i][1], largeFontStyle1)\n",
    "        data[i][0] = Paragraph(data[i][0], largeFontStyle1)\n",
    "    table = Table(data, colWidths=[1.5 * inch, 3 * inch])\n",
    "\n",
    "    # Set the style for the table text as large font\n",
    "    \n",
    "\n",
    "    table_style = TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#9C27B0')),  # Header row\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "        ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),  # Increase bottom padding\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 12),  # Increase top padding\n",
    "    ])\n",
    "    table.setStyle(table_style)\n",
    "    elements.append(table)\n",
    "    # elements.append(PageBreak())\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    elements.append(Paragraph(\"Critical Incident Reasons\", subheadingStyle))\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "    itemCIDf['Date'] = pd.to_datetime(itemCIDf['Date'],format='mixed').dt.strftime('%d-%m-%Y')\n",
    "    # Group by Student ID and Date\n",
    "    # itemCIDf = itemCIDf.groupby([colId, colDate, 'Reason'])['Item'].apply(lambda x: ','.join(sorted(set(x)))).reset_index()\n",
    "    # Rearrange the columns\n",
    "    # itemCIDf = itemCIDf[[colId, colDate, 'Item', 'Reason']]\n",
    "\n",
    "    # Sort by Item and then by Date\n",
    "    itemCIDf = itemCIDf.sort_values(by=['Item', 'Date'])\n",
    "\n",
    "    # Define a style for the text\n",
    "    styles = getSampleStyleSheet()\n",
    "    normalStyle = ParagraphStyle('Normal', parent=styles['Normal'], fontSize=12, alignment=0)\n",
    "    largeFontStyle = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=14, alignment=0)\n",
    "\n",
    "    # Add the headers to the data\n",
    "    data = [itemCIDf.columns.to_list()] + itemCIDf.applymap(str).values.tolist()\n",
    "\n",
    "    # Wrap the text in the Reason column\n",
    "    for i in range(1, len(data)):\n",
    "        data[i][3] = Paragraph(data[i][3], largeFontStyle)\n",
    "        data[i][2] = Paragraph(data[i][2], largeFontStyle)\n",
    "    # Create the table with wider Reason column\n",
    "    table = Table(data, colWidths=[1.2 * inch, 1.3 * inch, 2 * inch, 6 * inch])\n",
    "\n",
    "    # Set the style for the table\n",
    "    table_style = TableStyle([\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#9C27B0')),  # Header row\n",
    "        ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "        ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),  # Increase bottom padding\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 12),  # Increase top padding\n",
    "    ])\n",
    "\n",
    "    # Apply alternating row colors based on 'Item'\n",
    "    previous_item = None\n",
    "    color = colors.whitesmoke\n",
    "    for i in range(1, len(data)):\n",
    "        current_item = data[i][2]\n",
    "        if current_item != previous_item:\n",
    "            color = colors.white if color == colors.lightskyblue else colors.lightskyblue\n",
    "            previous_item = current_item\n",
    "        table_style.add('BACKGROUND', (0, i), (-1, i), color)\n",
    "\n",
    "    table.setStyle(table_style)\n",
    "\n",
    "    # Add the table to the elements\n",
    "    elements.append(table)\n",
    "    elements.append(PageBreak())\n",
    "\n",
    "def addItemWiseMCCounts(mcDf, elements, itemdisplay, mcRefdf):\n",
    "\n",
    "    if mcDf.empty:\n",
    "        return None\n",
    "    elements.append(Paragraph(f\"Counts for each MC column for {itemdisplay} \", subsubheadingStyle))\n",
    "    elements.append(Spacer(1, 6))\n",
    "    subplotcount = addGraphs(mcDf, elements, False, None, colors=Checklistcolors)\n",
    "    if subplotcount > 99:\n",
    "        elements.append(Spacer(1, 12))\n",
    "        addMCReferenceTable(mcRefdf, elements, itemdisplay)\n",
    "        # elements.append(PageBreak())\n",
    "        return None\n",
    "    print(f'After MC subplotcount: {subplotcount}')\n",
    "    if subplotcount > (subplots_per_page - 1):\n",
    "        elements.append(PageBreak())\n",
    "        firstpagesubplots = None\n",
    "    else:\n",
    "        firstpagesubplots = subplots_per_page - subplotcount\n",
    "    \n",
    "    addMCReferenceTable(mcRefdf, elements, itemdisplay)\n",
    "    return firstpagesubplots\n",
    "\n",
    "def addItemWiseOtherChecklistCounts(mcDf, elements, itemdisplay, firstpagesubplots=None):\n",
    "\n",
    "    if mcDf.empty:\n",
    "        return None\n",
    "    elements.append(Paragraph(f\"Counts for other checklists for {itemdisplay} \", subsubheadingStyle))\n",
    "    elements.append(Spacer(1, 6))\n",
    "    subplotcount = addGraphs(mcDf, elements, False, 'Total', colors=Checklistcolors)\n",
    "    print(f'After MC subplotcount: {subplotcount}')\n",
    "    if subplotcount > (subplots_per_page - 1):\n",
    "        elements.append(PageBreak())\n",
    "        firstpagesubplots = None\n",
    "    else:\n",
    "        firstpagesubplots = 3 - subplotcount\n",
    "    return firstpagesubplots\n",
    "\n",
    "def addStudentWiseCounts(studDf, elements, itemdisplay, firstpagesubplots=None):\n",
    "    if studDf.empty:\n",
    "        return None\n",
    "    elements.append(Paragraph(f\"Counts for each student for {itemdisplay}\", subsubheadingStyle))\n",
    "    elements.append(Spacer(1, 6))\n",
    "    subplotcount = addGraphs(studDf, elements, False, 'Yes/No', colors=Checklistcolors, startingSubplots=firstpagesubplots)\n",
    "    print(f'After Stud subplotcount: {subplotcount}')\n",
    "    if subplotcount > (subplots_per_page - 1):\n",
    "        elements.append(PageBreak())\n",
    "        firstpagesubplots = None\n",
    "    else:\n",
    "        firstpagesubplots = subplots_per_page - subplotcount\n",
    "    return firstpagesubplots\n",
    "\n",
    "def addStudentWiseRoleCounts(roleDf, elements, itemdisplay, firstpagesubplots=None):\n",
    "    if roleDf.empty:\n",
    "        return None\n",
    "    elements.append(Paragraph(f\"Role counts for each student for {itemdisplay}\", subsubheadingStyle))\n",
    "    elements.append(Spacer(1, 6))\n",
    "    subplotcount = addGraphs(roleDf, elements, False, 'Total', None, startingSubplots=firstpagesubplots)\n",
    "    print(f'After Role subplotcount: {subplotcount}')\n",
    "    if subplotcount > (subplots_per_page - 1):\n",
    "        elements.append(PageBreak())\n",
    "        firstpagesubplots = None\n",
    "    else:\n",
    "        firstpagesubplots = subplots_per_page - subplotcount\n",
    "    return firstpagesubplots\n",
    "\n",
    "def addStudentWisePatientCounts(patientDf, elements, itemdisplay, firstpagesubplots=None):\n",
    "    if patientDf.empty:\n",
    "        return None\n",
    "    elements.append(Paragraph(f\"Patient counts for each student for {itemdisplay}\", subsubheadingStyle))\n",
    "    elements.append(Spacer(1, 6))\n",
    "    subplotcount = addGraphs(patientDf, elements, False, 'Total', None, startingSubplots=firstpagesubplots)\n",
    "    print(f'After Patient subplotcount: {subplotcount}')\n",
    "    if subplotcount > (subplots_per_page - 1):\n",
    "        elements.append(PageBreak())\n",
    "        firstpagesubplots = None\n",
    "    else:\n",
    "        firstpagesubplots = subplots_per_page - subplotcount\n",
    "    return firstpagesubplots\n",
    "\n",
    "    # break\n",
    "# createSubjectReport(folder, testSubject, itemLenDf, countsDfMCDict, countsDfStudDict, itemCountsDf)\n",
    "# Example usage:\n",
    "# Assuming testSubject, countsDfMCDict, countsDfStudDict, itemCountsDf are defined as per your data\n",
    "# createSubjectReport(testSubject, countsDfMCDict, countsDfStudDict, itemCountsDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubjectReport(folder, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, removeItems):\n",
    "    doc = SimpleDocTemplate(f\"{folder}/{testSubject}.pdf\", pagesize=pageSize, leftMargin=leftMargin,\n",
    "    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    elements = []\n",
    "\n",
    "    # Add the title\n",
    "    heading = Paragraph(f\"{testSubject}\", headingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "    # Add the length of each item\n",
    "    addLengthGraph(itemLenDf, elements)\n",
    "    \n",
    "    # Add the MC counts for each item\n",
    "    addOverallMCGraph(itemCountsDf, elements)\n",
    "    \n",
    "    # Add Role counts for each item\n",
    "    addOverallRoleGraph(itemRoleDf, elements)\n",
    "\n",
    "    # Add Patient counts for each item\n",
    "    addOverallPatientGraph(itemPatientDf, elements)\n",
    "\n",
    "    # Now add stuff for each item\n",
    "    heading2 = Paragraph(\"Information for each item\", headingStyle)\n",
    "    elements.append(heading2)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    items = countsDfMCDict.keys()\n",
    "    \n",
    "    for item in items:\n",
    "        itemdisplay = item.replace('_', ' ')    \n",
    "        elements.append(Paragraph(f\"{itemdisplay}\", subheadingStyle))\n",
    "        elements.append(Spacer(1, 12))\n",
    "        if item in removeItems:\n",
    "            continue\n",
    "        print(item)\n",
    "\n",
    "         # Add graphs for Counts of MC values\n",
    "        mcDf = countsDfMCDict[item]\n",
    "        mcDf.index = [re.search(r'MC\\d+', str(i)).group() if re.search(r'MC\\d+', str(i)) else i for i in mcDf.index]\n",
    "        firstpagesubplots = addItemWiseMCCounts(mcDf, elements, itemdisplay)\n",
    "\n",
    "        # Add graphs for Counts Yes/No for each student\n",
    "        studDf = countsDfStudDict[item] \n",
    "        firstpagesubplots = addStudentWiseCounts(studDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # Add the graphs for the role counts for each student\n",
    "        if item in countsDfRoleDict.keys():\n",
    "            roleDf = countsDfRoleDict[item]\n",
    "            firstpagesubplots = addStudentWiseRoleCounts(roleDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # # Add the graphs for the patient counts for each student\n",
    "        if item in countsDfPatientDict.keys():\n",
    "            patientDf = countsDfPatientDict[item]\n",
    "            firstpagesubplots = addStudentWisePatientCounts(patientDf, elements, itemdisplay, firstpagesubplots)\n",
    "    \n",
    "    elements.append(PageBreak())\n",
    "\n",
    "    # Add the critical incidents\n",
    "    addCriticalIncidents(itemCIDf, elements)\n",
    "\n",
    "    doc.build(elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORAL10005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, \n",
    "                             itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems):\n",
    "    doc = SimpleDocTemplate(f\"{folder}/{filename}.pdf\", pagesize=pageSize, leftMargin=leftMargin,\n",
    "    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    elements = []\n",
    "\n",
    "    # Add the title\n",
    "    heading = Paragraph(f\"{testSubject}\", headingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "    # Add the length of each item\n",
    "    firstpagesubplots = addLengthGraph(itemLenDf, elements)\n",
    "    # elements.append(PageBreak())\n",
    "\n",
    "    # print(ageList)\n",
    "    # heading =  Paragraph(\"Patient's Age Distribution\", subheadingStyle)\n",
    "    # elements.append(heading)\n",
    "    # elements.append(Spacer(1, 6))\n",
    "    # addAgeHistogram(ageList, elements)\n",
    "    # Add the MC counts for each item\n",
    "    # firstpagesubplots = addOverallMCGraph(itemCountsDf, elements, firstpagesubplots)\n",
    "    if firstpagesubplots is not None:\n",
    "        elements.append(PageBreak())\n",
    "    \n",
    "    # Now add stuff for each item\n",
    "    heading2 = Paragraph(\"Information for each item\", headingStyle)\n",
    "    elements.append(heading2)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    items = countsDfMCDict.keys()\n",
    "    print(removeItems)\n",
    "    for item in items:\n",
    "        code = item.split('_')[0]\n",
    "        if item in removeItems:\n",
    "            continue\n",
    "        itemdisplay = item.replace('_', ' ')    \n",
    "        elements.append(Paragraph(f\"{itemdisplay}\", subheadingStyle))\n",
    "        elements.append(Spacer(1, 12))\n",
    "        print(item)\n",
    "\n",
    "         # Add graphs for Counts of MC values\n",
    "        mcDf = countsDfMCDict[item]\n",
    "        if code!= '114' and code!='115':\n",
    "            mcDf.index = [re.search(r'MC\\d+', str(i)).group() if re.search(r'MC\\d+', str(i)) else i for i in mcDf.index]\n",
    "        else:\n",
    "            mcDf['newIndex'] = mcDf.index\n",
    "            mcDf['newIndex'] = mcDf['newIndex'].str.extract(r'(MC\\d+)')\n",
    "\n",
    "            display(mcDf)\n",
    "            extracted_values = mcDf.index.str.extract(r'(H/S|U/S)', expand=False)\n",
    "                # print(extracted_values)\n",
    "                # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "            mcDf['newIndex'] = mcDf['newIndex'] + ' ' + extracted_values\n",
    "            mcDf.set_index('newIndex', inplace=True)\n",
    "            \n",
    "        firstpagesubplots = addItemWiseMCCounts(mcDf, elements, itemdisplay, itemReferenceDict[item])\n",
    "\n",
    "        # Add graphs for Counts Yes/No for each student\n",
    "        # studDf = countsDfStudDict[item] \n",
    "        # firstpagesubplots = addStudentWiseCounts(studDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # # Add the graphs for the role counts for each student\n",
    "        # if item in countsDfRoleDict.keys():\n",
    "        #     roleDf = countsDfRoleDict[item]\n",
    "        #     firstpagesubplots = addStudentWiseRoleCounts(roleDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # # # Add the graphs for the patient counts for each student\n",
    "        # if item in countsDfPatientDict.keys():\n",
    "        #     patientDf = countsDfPatientDict[item]\n",
    "        #     firstpagesubplots = addStudentWisePatientCounts(patientDf, elements, itemdisplay, firstpagesubplots)\n",
    "        # if firstpagesubplots is not None:\n",
    "        #     elements.append(PageBreak())\n",
    "\n",
    "    # Add the critical incidents\n",
    "    addCriticalIncidents(itemCIDf, elements)\n",
    "\n",
    "    doc.build(elements)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'ORAL10005'\n",
    "label = 'Simulation'\n",
    "filename = f'{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, subjectDict, label)\n",
    "createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'ORAL10005'\n",
    "label = 'Clinic'\n",
    "filename = f'{testSubject}_{label}'\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, subjectDict, label)\n",
    "createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORAL20005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testSubject = 'ORAL20005'\n",
    "label = 'Simulation'\n",
    "filename = f'{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems   = createDfs(testSubject, subjectDict, label)\n",
    "createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubjectReport20005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict,\n",
    "                              countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems):\n",
    "    doc = SimpleDocTemplate(f\"{folder}/{filename}.pdf\", pagesize=pageSize, leftMargin=leftMargin,\n",
    "    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    elements = []\n",
    "\n",
    "    # Add the title\n",
    "    heading = Paragraph(f\"{testSubject}\", headingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "    # Add the length of each item\n",
    "    firstpagesubplots = addLengthGraph(itemLenDf, elements)\n",
    "    \n",
    "    heading =  Paragraph(\"Patient's Age Distribution\", subheadingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 6))\n",
    "    ageDf = pd.read_excel('BOH2\\CAF+v0.1_October152024_19.01\\CAF v0.1_October 15, 2024_19.01 Paeds filtered.xlsx')\n",
    "    ageList = ageDf[colAge].tolist()\n",
    "    print(ageList)\n",
    "    addAgeHistogram(ageList, elements)\n",
    "    elements.append(PageBreak())\n",
    "    # Add the MC counts for each item\n",
    "    # firstpagesubplots = addOverallMCGraph(itemCountsDf, elements, firstpagesubplots)\n",
    "    if firstpagesubplots is not None:\n",
    "        elements.append(PageBreak())\n",
    "    \n",
    "    \n",
    "    # Add Role counts for each item\n",
    "    # addOverallRoleGraph(itemRoleDf, elements)\n",
    "    # Now add stuff for each item\n",
    "    heading2 = Paragraph(\"Information for each item\", headingStyle)\n",
    "    elements.append(heading2)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    items = countsDfMCDict.keys()\n",
    "    print(removeItems)\n",
    "    for item in items:\n",
    "\n",
    "        if item in removeItems:\n",
    "            continue\n",
    "        itemdisplay = item.replace('_', ' ')    \n",
    "        elements.append(Paragraph(f\"{itemdisplay}\", subheadingStyle))\n",
    "        elements.append(Spacer(1, 12))\n",
    "        print(item)\n",
    "\n",
    "        # Add graphs for Counts of MC values\n",
    "        mcDf = countsDfMCDict[item]\n",
    "        if code!= '114' and code!='115':\n",
    "            mcDf.index = [re.search(r'MC\\d+', str(i)).group() if re.search(r'MC\\d+', str(i)) else i for i in mcDf.index]\n",
    "        else:\n",
    "            mcDf['newIndex'] = mcDf.index\n",
    "            mcDf['newIndex'] = mcDf['newIndex'].str.extract(r'(MC\\d+)')\n",
    "\n",
    "            display(mcDf)\n",
    "            extracted_values = mcDf.index.str.extract(r'(H/S|U/S)', expand=False)\n",
    "                # print(extracted_values)\n",
    "                # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "            mcDf['newIndex'] = mcDf['newIndex'] + ' ' + extracted_values\n",
    "            mcDf.set_index('newIndex', inplace=True)\n",
    "        firstpagesubplots = addItemWiseMCCounts(mcDf, elements, itemdisplay, itemReferenceDict[item])\n",
    "\n",
    "        # Add graphs for other checklist counts\n",
    "        rkcDf = countsDfRKCDict[item]\n",
    "        firstpagesubplots = addItemWiseOtherChecklistCounts(rkcDf, elements, itemdisplay, firstpagesubplots)\n",
    "        addMCReferenceTable(otherMcRefdf, elements)\n",
    "        firstpagesubplots = None\n",
    "        # Add graphs for Counts Yes/No for each student\n",
    "        # studDf = countsDfStudDict[item] \n",
    "        # firstpagesubplots = addStudentWiseCounts(studDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # # Add the graphs for the role counts for each student\n",
    "        # if item in countsDfRoleDict.keys():\n",
    "        #     roleDf = countsDfRoleDict[item]\n",
    "        #     firstpagesubplots = addStudentWiseRoleCounts(roleDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # # # Add the graphs for the patient counts for each student\n",
    "        # if item in countsDfPatientDict.keys():\n",
    "        #     patientDf = countsDfPatientDict[item]\n",
    "        #     firstpagesubplots = addStudentWisePatientCounts(patientDf, elements, itemdisplay, firstpagesubplots)\n",
    "        if firstpagesubplots is not None:\n",
    "            elements.append(PageBreak())\n",
    "\n",
    "    # Add the critical incidents\n",
    "    addCriticalIncidents(itemCIDf, elements)\n",
    "\n",
    "    doc.build(elements)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DENT90115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubjectReportSim(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, \n",
    "                             itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems):\n",
    "    doc = SimpleDocTemplate(f\"{folder}/{filename}.pdf\", pagesize=pageSize, leftMargin=leftMargin,\n",
    "    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "    elements = []\n",
    "\n",
    "    # Add the title\n",
    "    heading = Paragraph(f\"{testSubject}\", headingStyle)\n",
    "    elements.append(heading)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "    # Add the length of each item\n",
    "    firstpagesubplots = addLengthGraph(itemLenDf, elements)\n",
    "    # elements.append(PageBreak())\n",
    "\n",
    "    # print(ageList)\n",
    "    # heading =  Paragraph(\"Patient's Age Distribution\", subheadingStyle)\n",
    "    # elements.append(heading)\n",
    "    # elements.append(Spacer(1, 6))\n",
    "    # addAgeHistogram(ageList, elements)\n",
    "    # Add the MC counts for each item\n",
    "    # firstpagesubplots = addOverallMCGraph(itemCountsDf, elements, firstpagesubplots)\n",
    "    if firstpagesubplots is not None:\n",
    "        elements.append(PageBreak())\n",
    "    \n",
    "    # Now add stuff for each item\n",
    "    heading2 = Paragraph(\"Information for each item\", headingStyle)\n",
    "    elements.append(heading2)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    items = countsDfMCDict.keys()\n",
    "    print(removeItems)\n",
    "    for item in items:\n",
    "        code = item.split('_')[0]\n",
    "        if item in removeItems:\n",
    "            continue\n",
    "        itemdisplay = item.replace('_', ' ')    \n",
    "        elements.append(Paragraph(f\"{itemdisplay}\", subheadingStyle))\n",
    "        elements.append(Spacer(1, 12))\n",
    "        print(item)\n",
    "\n",
    "         # Add graphs for Counts of MC values\n",
    "        mcDf = countsDfMCDict[item]\n",
    "        if code!= '114' and code!='115':\n",
    "            mcDf.index = [re.search(r'MC\\d+', str(i)).group() if re.search(r'MC\\d+', str(i)) else i for i in mcDf.index]\n",
    "        else:\n",
    "            mcDf['newIndex'] = mcDf.index\n",
    "            mcDf['newIndex'] = mcDf['newIndex'].str.extract(r'(MC\\d+)')\n",
    "\n",
    "            display(mcDf)\n",
    "            extracted_values = mcDf.index.str.extract(r'(H/S|U/S)', expand=False)\n",
    "                # print(extracted_values)\n",
    "                # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "            mcDf['newIndex'] = mcDf['newIndex'] + ' ' + extracted_values\n",
    "            mcDf.set_index('newIndex', inplace=True)\n",
    "            \n",
    "        firstpagesubplots = addItemWiseMCCounts(mcDf, elements, itemdisplay, itemReferenceDict[item])\n",
    "\n",
    "        # Add graphs for Counts Yes/No for each student\n",
    "        # studDf = countsDfStudDict[item] \n",
    "        # firstpagesubplots = addStudentWiseCounts(studDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # # Add the graphs for the role counts for each student\n",
    "        # if item in countsDfRoleDict.keys():\n",
    "        #     roleDf = countsDfRoleDict[item]\n",
    "        #     firstpagesubplots = addStudentWiseRoleCounts(roleDf, elements, itemdisplay, firstpagesubplots)\n",
    "\n",
    "        # # # Add the graphs for the patient counts for each student\n",
    "        # if item in countsDfPatientDict.keys():\n",
    "        #     patientDf = countsDfPatientDict[item]\n",
    "        #     firstpagesubplots = addStudentWisePatientCounts(patientDf, elements, itemdisplay, firstpagesubplots)\n",
    "        # if firstpagesubplots is not None:\n",
    "        #     elements.append(PageBreak())\n",
    "\n",
    "    # Add the critical incidents\n",
    "    addCriticalIncidents(itemCIDf, elements)\n",
    "\n",
    "    doc.build(elements)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'DENT90115'\n",
    "label = 'Simulation'\n",
    "filename = f'{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, subjectDict, label)\n",
    "createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dent90115 dict as workbook with keys as sheet names\n",
    "for sheetname, df in dent90115Dict.items():\n",
    "    saveDf(dent90115Dict[sheetname], f'{folder}/DENT90115.xlsx', sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixedprosdict = {}\n",
    "endodict = {}\n",
    "paedsdict = {}\n",
    "# fixed pros items are of type 6XX\n",
    "for sheetname, df in dent90115Dict.items():\n",
    "    if sheetname.startswith('6'):\n",
    "        fixedprosdict[sheetname] = df\n",
    "    elif sheetname.startswith('4'):\n",
    "        endodict[sheetname] = df\n",
    "    elif sheetname.startswith('5'):\n",
    "        paedsdict[sheetname] = df\n",
    "\n",
    "overallDict = {'Fixed Prosthodontics': fixedprosdict, 'Endodontics': endodict, 'Paediatric': paedsdict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'Fixed Prosthodontics'\n",
    "label = 'Simulation'\n",
    "filename = f'DENT90115_{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, overallDict, label)\n",
    "createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'Endodontics'\n",
    "label = 'Simulation'\n",
    "filename = f'DENT90115_{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, overallDict, label)\n",
    "createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'Paediatric'\n",
    "label = 'Simulation'\n",
    "filename = f'DENT90115_{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, overallDict, label)\n",
    "createSubjectReport10005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'ORAL20005'\n",
    "label = 'Clinic'\n",
    "filename = f'{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, subjectDict, label)\n",
    "createSubjectReport20005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORAL30002\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'ORAL30002'\n",
    "label = 'Clinic'\n",
    "filename = f'{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, subjectDict, label)\n",
    "createSubjectReport20005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DENT90120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSubject = 'DENT90120'\n",
    "label = 'Clinic'\n",
    "filename = f'{testSubject}_{label}'\n",
    "print(testSubject)\n",
    "countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems  = createDfs(testSubject, subjectDict, label)\n",
    "createSubjectReport20005(folder, filename, testSubject, countsDfMCDict, countsDfStudDict, countsDfRoleDict, countsDfPatientDict, itemCountsDf, itemLenDf, itemRoleDf, itemPatientDf, itemCIDf, countsDfRKCDict, itemReferenceDict, ageList, removeItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
