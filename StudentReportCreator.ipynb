{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841.68, 1190.8799999999999)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import openpyxl\n",
    "import re\n",
    "import os\n",
    "from variableUtils import *\n",
    "from Utils import *\n",
    "from ClassUtils import *\n",
    "from pprint import pprint\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from reportlab.lib.pagesizes import letter, landscape, A4, A3\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, PageBreak, Paragraph, Spacer, Image\n",
    "from reportlab.lib import colors\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from reportlab.platypus import Paragraph, Spacer, KeepTogether, KeepInFrame\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from io import BytesIO\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Loaded workbook: FullSpreadsheets\\\\CAF+v0.1_September+12,+2024_21.55 | CAF '\n",
      " 'v0.1_September 12 August guttman | .xlsx')\n",
      "(\"Workbook sheets: ['011_COE', '012_POE', '013_LIMITED OE', \"\n",
      " \"'014_CONSULTATION', '022_I-O RAD', '061_VITALITY', '071_DIAGNOSTIC MODEL', \"\n",
      " \"'072_PHOTOS', '111_CLINIC', '113_CLINIC', '113_SIM', '114_CLINIC', \"\n",
      " \"'115_CLINIC', '121_CLINIC REMIN', '121_SIM REMIN', '123_CLINIC', '123_SIM', \"\n",
      " \"'131_CLINIC', '141_CLINIC', '142_CLINIC', '161_CLINIC', '165_CLINIC', \"\n",
      " \"'221_CLINIC', '221_SIM', '222_CLINIC', '222_SIM', '311_CLINIC', '386_SIM', \"\n",
      " \"'411_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '414_SIM CVEK', \"\n",
      " \"'414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', \"\n",
      " \"'417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT \"\n",
      " \"FLG', '511_SIM', '521_CLINIC', '521_SIM', '522_CLINIC', '522_SIM', \"\n",
      " \"'523_CLINIC', '524_CLINIC', '524_SIM', '525_CLINIC', '525_SIM', \"\n",
      " \"'531_CLINIC', '531_SIM', '532_CLINIC', '532_SIM', '533_CLINIC', \"\n",
      " \"'534_CLINIC', '534_SIM', '535_CLINIC', '545_CLINIC', '555_CLINIC', \"\n",
      " \"'572_CLINIC', '572_SIM', '577_CLINIC', '577_SIM', '578_SIM', '579_BONDING', \"\n",
      " \"'586_SIM SEPARATORS', '586_SIM TOOTH PREP', '587_SIM SEPARATORS', '587_SIM \"\n",
      " \"TOOTH PREP', '613_CLINIC', '613_SIM', '615_CLINIC', '615_SIM', '618_CLINIC', \"\n",
      " \"'618_SIM', '625_CLINIC', '627_CLINIC', '631_CLINIC', '631_SIM', \"\n",
      " \"'655_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION']\")\n"
     ]
    }
   ],
   "source": [
    "workbookPath = 'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50.xlsx'\n",
    "savePath =  'FullSpreadsheets\\CAF+v0.1_August+6,+2024\\CAF v0.1_August 6, 2024_00.50 filtered.xlsx'\n",
    "guttmanPath = 'BOH3\\CAF+v0.1_September+25,+2024_20.31\\CAF v0.1_September 25, 2024_20.31 guttman.xlsx'\n",
    "guttmanPath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo guttman 28 Aug.xlsx'\n",
    "guttmanPath = 'DDS2\\CAF+v0.1_September+2,+2024_22.43\\CAF v0.1_September 2, 2024_22.43 endo guttman teeth standard 28 Aug.xlsx'\n",
    "guttmanPath = 'FullSpreadsheets\\CAF+v0.1_October+7,+2024_18.49\\CAF v0.1_October 7, 2024_18.49 guttman.xlsx'\n",
    "guttmanPath = 'BOH2\\CAF+v0.1_October+14,+2024 few students\\CAF v0.1_October 14, 2024_16.56 best guttman.xlsx'\n",
    "guttmanPath = 'BOH3\\CAF+v0.1_October+22,+2024_22.00\\CAF v0.1_October 22, 2024_22.00 guttman.xlsx'\n",
    "guttmanPath = 'FullSpreadsheets\\CAF+v0.1_September+12,+2024_21.55\\CAF v0.1_September 12 August guttman.xlsx'\n",
    "workbook, folder, file = loadWorkbook(guttmanPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sheet in workbook.sheetnames:\n",
    "#     df = loadDfFromSheet(workbook, sheet)\n",
    "#     # take dates on 28th Aug\n",
    "#     date = pd.to_datetime('2024-08-28')\n",
    "#     df[colDate] = pd.to_datetime(df[colDate], format = '%d/%m/%Y')\n",
    "#     print(df[colDate].dtype)\n",
    "#     df = df[df[colDate] == date]\n",
    "#     display(df)\n",
    "#     colorCols = getColorColumns(df, sheet.split('_')[0])\n",
    "#     saveDf(df, f'{folder}/{file} 28 Aug.xlsx', sheet, len(colorCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentDict= {}\n",
    "for i, sheet in enumerate(workbook.sheetnames):\n",
    "    code = sheet.split(' ')[0]\n",
    "    df = loadDfFromSheet(workbook, sheet)\n",
    "    df = df[~df[colId].isin([111111, 1111111, 0, 1, 12, 123, 1234, 12345, 123456, 1234567, 12345678])]\n",
    "    # df[colClinicChoice] = 'Simulation' # to remove later\n",
    "    # df[colSubject] = 'DENT90115'\n",
    "    stuId = df[colId].unique()\n",
    "    # remove Nan\n",
    "    stuId =  [x for x in stuId if str(x) != 'nan']\n",
    "    for s in stuId:\n",
    "        if s not in studentDict.keys():\n",
    "            studentDict[s] = {}\n",
    "        subdf = df[df[colId] == s]\n",
    "        if len(subdf) > 0:\n",
    "            studentDict[s][sheet] = subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students: 297\n",
      "1220151.0 4 dict_keys(['011_COE', '061_VITALITY', '535_CLINIC', 'LA_BLOCK'])\n",
      "1462377.0 12 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '222_CLINIC', '414_CLINIC DECIDUOUS', '531_SIM', '586_SIM TOOTH PREP', 'LA_BLOCK'])\n",
      "994883.0 9 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '222_CLINIC', '523_CLINIC'])\n",
      "1080271.0 7 dict_keys(['011_COE', '061_VITALITY', '114_CLINIC', '121_CLINIC REMIN', '131_CLINIC', '141_CLINIC', '613_CLINIC'])\n",
      "1472336.0 12 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '114_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP', '587_SIM TOOTH PREP'])\n",
      "1461394.0 12 dict_keys(['011_COE', '114_CLINIC', '115_CLINIC', '141_CLINIC', '222_CLINIC', '386_SIM', '414_SIM CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1461909.0 12 dict_keys(['011_COE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '221_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1463403.0 16 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '161_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1443777.0 11 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '121_CLINIC REMIN', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1423642.0 14 dict_keys(['011_COE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '165_CLINIC', '386_SIM', '414_SIM CVEK', '414_SIM DECIDUOUS', '531_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK'])\n",
      "1472645.0 10 dict_keys(['011_COE', '012_POE', '013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1452755.0 11 dict_keys(['011_COE', '022_I-O RAD', '061_VITALITY', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1452798.0 14 dict_keys(['011_COE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '222_CLINIC', '386_SIM', '414_SIM CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1461567.0 17 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '072_PHOTOS', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '531_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1443680.0 13 dict_keys(['011_COE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '141_CLINIC', '222_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '531_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1461325.0 11 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '141_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1464586.0 15 dict_keys(['011_COE', '022_I-O RAD', '111_CLINIC', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '533_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1472277.0 18 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '142_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '521_CLINIC', '522_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1473013.0 15 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '531_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1462155.0 11 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '111_CLINIC', '114_CLINIC', '141_CLINIC', '221_CLINIC', '414_SIM CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1048480.0 3 dict_keys(['011_COE', '022_I-O RAD', '525_CLINIC'])\n",
      "1460189.0 9 dict_keys(['011_COE', '022_I-O RAD', '114_CLINIC', '121_CLINIC REMIN', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1255058.0 9 dict_keys(['011_COE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '222_CLINIC', '531_CLINIC'])\n",
      "1452784.0 11 dict_keys(['011_COE', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1311884.0 4 dict_keys(['011_COE', '022_I-O RAD', '141_CLINIC', '161_CLINIC'])\n",
      "1473073.0 16 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '111_CLINIC', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '222_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '531_CLINIC', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1270549.0 5 dict_keys(['011_COE', '022_I-O RAD', '141_CLINIC', '221_CLINIC', '531_CLINIC'])\n",
      "1350428.0 9 dict_keys(['011_COE', '022_I-O RAD', '061_VITALITY', '113_CLINIC', '114_CLINIC', '121_CLINIC REMIN', '221_CLINIC', '521_CLINIC', '531_CLINIC'])\n",
      "996164.0 6 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '131_CLINIC', '141_CLINIC', '221_CLINIC'])\n",
      "1472938.0 12 dict_keys(['011_COE', '022_I-O RAD', '113_CLINIC', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1461861.0 10 dict_keys(['011_COE', '012_POE', '114_CLINIC', '142_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1460391.0 10 dict_keys(['011_COE', '022_I-O RAD', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1354148.0 7 dict_keys(['011_COE', '022_I-O RAD', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '222_CLINIC'])\n",
      "1353787.0 7 dict_keys(['011_COE', '022_I-O RAD', '115_CLINIC', '131_CLINIC', '141_CLINIC', '221_CLINIC', '222_CLINIC'])\n",
      "1337652.0 14 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1280725.0 8 dict_keys(['011_COE', '114_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM SEPARATORS'])\n",
      "1472447.0 10 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '579_BONDING'])\n",
      "1625104.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1472250.0 13 dict_keys(['011_COE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_SIM CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1617495.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1462810.0 8 dict_keys(['011_COE', '114_CLINIC', '141_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1419850.0 13 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1472946.0 10 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1472769.0 11 dict_keys(['011_COE', '022_I-O RAD', '115_CLINIC', '131_CLINIC', '221_CLINIC', '222_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1469829.0 21 dict_keys(['011_COE', '012_POE', '013_LIMITED OE', '014_CONSULTATION', '022_I-O RAD', '061_VITALITY', '111_CLINIC', '113_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '161_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '532_CLINIC', '572_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK'])\n",
      "1452727.0 7 dict_keys(['011_COE', '022_I-O RAD', '115_CLINIC', '221_CLINIC', '386_SIM', '414_SIM CVEK', '579_BONDING'])\n",
      "1472800.0 12 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '521_CLINIC', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1472810.0 12 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '532_CLINIC', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1455126.0 10 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '115_CLINIC', '141_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1452672.0 8 dict_keys(['011_COE', '022_I-O RAD', '114_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1637288.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1472445.0 12 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '414_SIM CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1605390.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1353765.0 9 dict_keys(['011_COE', '013_LIMITED OE', '022_I-O RAD', '072_PHOTOS', '114_CLINIC', '115_CLINIC', '221_CLINIC', '414_CLINIC DECIDUOUS', '586_SIM TOOTH PREP'])\n",
      "1352051.0 3 dict_keys(['011_COE', '221_CLINIC', '532_SIM'])\n",
      "1617958.0 2 dict_keys(['011_COE', '532_SIM'])\n",
      "1472831.0 2 dict_keys(['011_COE', '221_CLINIC'])\n",
      "1146177.0 5 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '532_SIM', '572_SIM'])\n",
      "1605793.0 1 dict_keys(['011_COE'])\n",
      "1469076.0 13 dict_keys(['011_COE', '012_POE', '022_I-O RAD', '114_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '161_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1606158.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '511_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1616141.0 3 dict_keys(['011_COE', '531_SIM', '532_SIM'])\n",
      "1473072.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '572_SIM'])\n",
      "1617003.0 5 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '532_SIM', '572_SIM'])\n",
      "1617304.0 5 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '532_SIM', '572_SIM'])\n",
      "1615261.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1615131.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1594851.0 7 dict_keys(['011_COE', '113_SIM', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1535538.0 5 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '532_SIM', '572_SIM'])\n",
      "1608030.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_SIM', '511_SIM', '531_SIM', '532_SIM'])\n",
      "1472717.0 13 dict_keys(['011_COE', '022_I-O RAD', '072_PHOTOS', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK'])\n",
      "1615593.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1637313.0 4 dict_keys(['011_COE', '221_CLINIC', '531_SIM', '532_SIM'])\n",
      "1605480.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1610017.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '531_SIM', '572_SIM'])\n",
      "1606153.0 5 dict_keys(['011_COE', '121_SIM REMIN', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1625619.0 3 dict_keys(['011_COE', '531_SIM', '532_SIM'])\n",
      "1617587.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1625191.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1615333.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1600923.0 6 dict_keys(['011_COE', '113_SIM', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM'])\n",
      "1462773.0 12 dict_keys(['011_COE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '521_CLINIC', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1616618.0 3 dict_keys(['011_COE', '531_SIM', '532_SIM'])\n",
      "1634259.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1606071.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1617334.0 5 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM'])\n",
      "1461457.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1625702.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '532_SIM', '572_SIM'])\n",
      "1321463.0 7 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '221_CLINIC', '511_SIM', '531_SIM', '572_SIM'])\n",
      "1624825.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1606077.0 7 dict_keys(['011_COE', '113_SIM', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1605538.0 6 dict_keys(['011_COE', '113_SIM', '121_SIM REMIN', '123_SIM', '531_SIM', '572_SIM'])\n",
      "1466081.0 2 dict_keys(['011_COE', '221_CLINIC'])\n",
      "1639983.0 5 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '532_SIM', '572_SIM'])\n",
      "1594958.0 6 dict_keys(['011_COE', '121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1377061.0 9 dict_keys(['012_POE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1460683.0 13 dict_keys(['012_POE', '111_CLINIC', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '161_CLINIC', '221_CLINIC', '222_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1197105.0 5 dict_keys(['013_LIMITED OE', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', 'LA_INFILTRATION'])\n",
      "980645.0 4 dict_keys(['013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '555_CLINIC'])\n",
      "1080594.0 6 dict_keys(['013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '131_CLINIC', '141_CLINIC', '615_CLINIC'])\n",
      "1203413.0 7 dict_keys(['013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '555_CLINIC', '627_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1067694.0 5 dict_keys(['013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '631_CLINIC', 'LA_BLOCK'])\n",
      "1211908.0 5 dict_keys(['013_LIMITED OE', '061_VITALITY', '572_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1473169.0 16 dict_keys(['013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '142_CLINIC', '221_CLINIC', '222_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1472637.0 14 dict_keys(['013_LIMITED OE', '022_I-O RAD', '113_CLINIC', '114_CLINIC', '115_CLINIC', '161_CLINIC', '386_SIM', '414_SIM CVEK', '414_SIM DECIDUOUS', '531_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "974490.0 5 dict_keys(['013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '071_DIAGNOSTIC MODEL', '072_PHOTOS'])\n",
      "1084710.0 4 dict_keys(['013_LIMITED OE', '532_CLINIC', '615_CLINIC', 'LA_INFILTRATION'])\n",
      "1129001.0 3 dict_keys(['013_LIMITED OE', '131_CLINIC', '141_CLINIC'])\n",
      "1082760.0 6 dict_keys(['013_LIMITED OE', '061_VITALITY', '531_CLINIC', '533_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "900511.0 9 dict_keys(['013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '071_DIAGNOSTIC MODEL', '072_PHOTOS', '114_CLINIC', '141_CLINIC', '555_CLINIC', 'LA_BLOCK'])\n",
      "1211920.0 3 dict_keys(['013_LIMITED OE', '022_I-O RAD', '071_DIAGNOSTIC MODEL'])\n",
      "1463086.0 13 dict_keys(['013_LIMITED OE', '022_I-O RAD', '072_PHOTOS', '114_CLINIC', '121_CLINIC REMIN', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '531_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1035913.0 4 dict_keys(['013_LIMITED OE', '022_I-O RAD', '071_DIAGNOSTIC MODEL', '072_PHOTOS'])\n",
      "1473664.0 14 dict_keys(['013_LIMITED OE', '022_I-O RAD', '111_CLINIC', '114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1472266.0 13 dict_keys(['013_LIMITED OE', '022_I-O RAD', '114_CLINIC', '115_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1473826.0 14 dict_keys(['013_LIMITED OE', '022_I-O RAD', '111_CLINIC', '114_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '531_CLINIC', '532_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_BLOCK'])\n",
      "1088656.0 14 dict_keys(['013_LIMITED OE', '022_I-O RAD', '061_VITALITY', '114_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '532_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', '587_SIM SEPARATORS', '587_SIM TOOTH PREP'])\n",
      "1084469.0 5 dict_keys(['013_LIMITED OE', '022_I-O RAD', '071_DIAGNOSTIC MODEL', '072_PHOTOS', '572_CLINIC'])\n",
      "947992.0 5 dict_keys(['013_LIMITED OE', '022_I-O RAD', '072_PHOTOS', '142_CLINIC', '555_CLINIC'])\n",
      "916569.0 4 dict_keys(['013_LIMITED OE', '627_CLINIC', '631_CLINIC', 'LA_INFILTRATION'])\n",
      "1302623.0 3 dict_keys(['013_LIMITED OE', '072_PHOTOS', '613_CLINIC'])\n",
      "832527.0 2 dict_keys(['022_I-O RAD', '545_CLINIC'])\n",
      "1213575.0 3 dict_keys(['022_I-O RAD', '555_CLINIC', 'LA_INFILTRATION'])\n",
      "913949.0 2 dict_keys(['022_I-O RAD', '613_CLINIC'])\n",
      "608989.0 5 dict_keys(['022_I-O RAD', '114_CLINIC', '221_CLINIC', '222_CLINIC', 'LA_INFILTRATION'])\n",
      "1222310.0 7 dict_keys(['022_I-O RAD', '061_VITALITY', '114_CLINIC', '123_CLINIC', '131_CLINIC', '141_CLINIC', '613_CLINIC'])\n",
      "1080466.0 3 dict_keys(['022_I-O RAD', '072_PHOTOS', 'LA_INFILTRATION'])\n",
      "1213084.0 5 dict_keys(['022_I-O RAD', '071_DIAGNOSTIC MODEL', '572_CLINIC', '625_CLINIC', 'LA_INFILTRATION'])\n",
      "1084203.0 4 dict_keys(['022_I-O RAD', '072_PHOTOS', '618_CLINIC', 'LA_INFILTRATION'])\n",
      "985101.0 5 dict_keys(['022_I-O RAD', '615_CLINIC', '618_CLINIC', '627_CLINIC', 'LA_INFILTRATION'])\n",
      "1306943.0 4 dict_keys(['022_I-O RAD', '061_VITALITY', '141_CLINIC', '531_CLINIC'])\n",
      "1079606.0 4 dict_keys(['022_I-O RAD', '121_CLINIC REMIN', '615_CLINIC', 'LA_INFILTRATION'])\n",
      "1213578.0 3 dict_keys(['022_I-O RAD', '555_CLINIC', 'LA_INFILTRATION'])\n",
      "1218071.0 2 dict_keys(['022_I-O RAD', '555_CLINIC'])\n",
      "1472568.0 8 dict_keys(['022_I-O RAD', '114_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC DECIDUOUS', '414_SIM CVEK', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "944792.0 2 dict_keys(['022_I-O RAD', '061_VITALITY'])\n",
      "1098429.0 3 dict_keys(['022_I-O RAD', '555_CLINIC', 'LA_INFILTRATION'])\n",
      "1241309.0 4 dict_keys(['022_I-O RAD', '555_CLINIC', '613_CLINIC', 'LA_INFILTRATION'])\n",
      "1452767.0 13 dict_keys(['061_VITALITY', '114_CLINIC', '115_CLINIC', '141_CLINIC', '222_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '531_CLINIC', '532_CLINIC', '579_BONDING', '586_SIM TOOTH PREP', 'LA_INFILTRATION'])\n",
      "1219506.0 3 dict_keys(['061_VITALITY', '072_PHOTOS', '613_CLINIC'])\n",
      "969985.0 2 dict_keys(['071_DIAGNOSTIC MODEL', '115_CLINIC'])\n",
      "1080800.0 3 dict_keys(['071_DIAGNOSTIC MODEL', '631_CLINIC', 'LA_BLOCK'])\n",
      "997453.0 6 dict_keys(['071_DIAGNOSTIC MODEL', '131_CLINIC', '141_CLINIC', '613_CLINIC', '631_CLINIC', 'LA_INFILTRATION'])\n",
      "995150.0 4 dict_keys(['071_DIAGNOSTIC MODEL', '545_CLINIC', '572_CLINIC', 'LA_INFILTRATION'])\n",
      "1215995.0 3 dict_keys(['071_DIAGNOSTIC MODEL', '631_CLINIC', 'LA_INFILTRATION'])\n",
      "900893.0 4 dict_keys(['071_DIAGNOSTIC MODEL', '532_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1083170.0 3 dict_keys(['071_DIAGNOSTIC MODEL', '613_CLINIC', 'LA_INFILTRATION'])\n",
      "1083399.0 3 dict_keys(['071_DIAGNOSTIC MODEL', '613_CLINIC', 'LA_INFILTRATION'])\n",
      "1102550.0 1 dict_keys(['071_DIAGNOSTIC MODEL'])\n",
      "984694.0 6 dict_keys(['072_PHOTOS', '531_CLINIC', '572_CLINIC', '627_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1211902.0 3 dict_keys(['072_PHOTOS', '311_CLINIC', 'LA_INFILTRATION'])\n",
      "1213105.0 5 dict_keys(['072_PHOTOS', '613_CLINIC', '655_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1222329.0 3 dict_keys(['072_PHOTOS', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1327995.0 3 dict_keys(['072_PHOTOS', '555_CLINIC', '572_CLINIC'])\n",
      "993257.0 3 dict_keys(['072_PHOTOS', '524_CLINIC', '631_CLINIC'])\n",
      "913592.0 4 dict_keys(['111_CLINIC', '121_CLINIC REMIN', '131_CLINIC', '141_CLINIC'])\n",
      "1328021.0 4 dict_keys(['113_CLINIC', '141_CLINIC', '613_CLINIC', 'LA_BLOCK'])\n",
      "913450.0 5 dict_keys(['113_CLINIC', '534_CLINIC', '572_CLINIC', '577_CLINIC', 'LA_BLOCK'])\n",
      "1328001.0 4 dict_keys(['114_CLINIC', '141_CLINIC', '222_CLINIC', 'LA_BLOCK'])\n",
      "1081205.0 10 dict_keys(['114_CLINIC', '115_CLINIC', '121_CLINIC REMIN', '123_CLINIC', '141_CLINIC', '221_CLINIC', '222_CLINIC', '532_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1461239.0 8 dict_keys(['114_CLINIC', '115_CLINIC', '141_CLINIC', '386_SIM', '414_SIM CVEK', '414_SIM DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1353677.0 4 dict_keys(['114_CLINIC', '141_CLINIC', '161_CLINIC', '222_CLINIC'])\n",
      "1472540.0 2 dict_keys(['114_CLINIC', '141_CLINIC'])\n",
      "1472625.0 8 dict_keys(['114_CLINIC', '141_CLINIC', '221_CLINIC', '386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1353950.0 4 dict_keys(['115_CLINIC', '141_CLINIC', '142_CLINIC', '221_CLINIC'])\n",
      "1605779.0 4 dict_keys(['121_SIM REMIN', '123_SIM', '532_SIM', '572_SIM'])\n",
      "1606096.0 5 dict_keys(['121_SIM REMIN', '123_SIM', '221_SIM', '222_SIM', '532_SIM'])\n",
      "1605677.0 5 dict_keys(['121_SIM REMIN', '123_SIM', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1430664.0 4 dict_keys(['121_SIM REMIN', '123_SIM', '531_SIM', '572_SIM'])\n",
      "1616745.0 4 dict_keys(['121_SIM REMIN', '531_SIM', '532_SIM', '572_SIM'])\n",
      "1463879.0 5 dict_keys(['386_SIM', '414_CLINIC CVEK', '414_CLINIC DECIDUOUS', '579_BONDING', '586_SIM TOOTH PREP'])\n",
      "1178529.0 16 dict_keys(['411_SIM', '414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '615_SIM', '631_SIM'])\n",
      "1387538.0 2 dict_keys(['414_CLINIC DECIDUOUS', '586_SIM TOOTH PREP'])\n",
      "1383423.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '587_SIM TOOTH PREP', '618_SIM'])\n",
      "1064909.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1377158.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "993640.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1082185.0 16 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '631_SIM'])\n",
      "985199.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1173101.0 17 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1079984.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM'])\n",
      "1083971.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1079946.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '615_SIM', '631_SIM'])\n",
      "1399221.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1307153.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM'])\n",
      "1384393.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1213577.0 17 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1080247.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '572_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM'])\n",
      "1384391.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '615_SIM', '631_SIM'])\n",
      "1309754.0 17 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1402039.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1388926.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1173233.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1171800.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM'])\n",
      "1420100.0 16 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '631_SIM'])\n",
      "1174172.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1420119.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "992914.0 12 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1399220.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1391596.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '532_SIM', '577_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1180737.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '613_SIM', '615_SIM'])\n",
      "1420083.0 16 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '631_SIM'])\n",
      "1170848.0 18 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '534_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1388600.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM'])\n",
      "1287253.0 12 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1391557.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1172496.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1085148.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '615_SIM'])\n",
      "1187088.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1184941.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1170745.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM'])\n",
      "1079663.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '615_SIM'])\n",
      "1212518.0 12 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1301220.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1113227.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1387067.0 17 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1420053.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1173430.0 16 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1402789.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM'])\n",
      "1394580.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM'])\n",
      "1420079.0 12 dict_keys(['414_SIM CVEK', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '615_SIM'])\n",
      "1420060.0 16 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '631_SIM'])\n",
      "1084831.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '631_SIM'])\n",
      "1394124.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1384390.0 16 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '521_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM'])\n",
      "1170316.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1420118.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1384392.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1211876.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '631_SIM'])\n",
      "1031163.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM'])\n",
      "1081308.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1027970.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1309751.0 17 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '522_SIM', '524_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1221853.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1329195.0 16 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM'])\n",
      "1300764.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1309763.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1069842.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1168876.0 11 dict_keys(['414_SIM CVEK', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM'])\n",
      "1171988.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "587525.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM'])\n",
      "1209449.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1181425.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1420124.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1174040.0 11 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1391578.0 12 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1371861.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1420122.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1171108.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1082412.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1170752.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "758770.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '631_SIM'])\n",
      "1394123.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1388256.0 12 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1170993.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1402031.0 17 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1330715.0 14 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM'])\n",
      "1107398.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1389354.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1232770.0 11 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '586_SIM TOOTH PREP'])\n",
      "1187046.0 13 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '522_SIM', '524_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1399214.0 15 dict_keys(['414_SIM CVEK', '414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '618_SIM', '631_SIM'])\n",
      "1081376.0 12 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1420096.0 13 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '631_SIM'])\n",
      "617915.0 12 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1402035.0 14 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM ROOT FLG', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1081787.0 15 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '618_SIM', '631_SIM'])\n",
      "1420062.0 14 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '613_SIM', '615_SIM', '631_SIM'])\n",
      "1082018.0 12 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP'])\n",
      "1181472.0 13 dict_keys(['414_SIM DECIDUOUS', '415_SIM ACCESS', '415_SIM WORK LENGTH', '416_SIM', '417_SIM CONE FIT', '417_SIM ROOT FLG', '418_SIM CONE FIT', '418_SIM ROOT FLG', '524_SIM', '525_SIM', '578_SIM', '586_SIM TOOTH PREP', '615_SIM'])\n",
      "1192826.0 2 dict_keys(['531_CLINIC', '555_CLINIC'])\n",
      "1617738.0 1 dict_keys(['532_SIM'])\n",
      "1192819.0 1 dict_keys(['545_CLINIC'])\n",
      "1079894.0 1 dict_keys(['555_CLINIC'])\n",
      "1082098.0 1 dict_keys(['555_CLINIC'])\n",
      "1213078.0 1 dict_keys(['613_CLINIC'])\n",
      "1112370.0 3 dict_keys(['613_CLINIC', '631_CLINIC', 'LA_INFILTRATION'])\n",
      "1213090.0 2 dict_keys(['613_CLINIC', 'LA_INFILTRATION'])\n",
      "1221841.0 2 dict_keys(['615_CLINIC', 'LA_INFILTRATION'])\n",
      "1081939.0 1 dict_keys(['615_CLINIC'])\n",
      "1067973.0 2 dict_keys(['615_CLINIC', 'LA_INFILTRATION'])\n",
      "1205045.0 1 dict_keys(['618_CLINIC'])\n",
      "1080136.0 2 dict_keys(['627_CLINIC', 'LA_INFILTRATION'])\n",
      "987912.0 3 dict_keys(['627_CLINIC', '631_CLINIC', 'LA_INFILTRATION'])\n",
      "1218058.0 2 dict_keys(['627_CLINIC', 'LA_INFILTRATION'])\n",
      "1126914.0 2 dict_keys(['631_CLINIC', 'LA_BLOCK'])\n",
      "1197946.0 1 dict_keys(['631_CLINIC'])\n",
      "734343.0 1 dict_keys(['631_CLINIC'])\n",
      "1213093.0 4 dict_keys(['631_CLINIC', '655_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1328023.0 2 dict_keys(['631_CLINIC', 'LA_INFILTRATION'])\n",
      "1079470.0 1 dict_keys(['655_CLINIC'])\n",
      "1328043.0 3 dict_keys(['655_CLINIC', 'LA_BLOCK', 'LA_INFILTRATION'])\n",
      "1328020.0 1 dict_keys(['LA_INFILTRATION'])\n",
      "1217909.0 1 dict_keys(['LA_INFILTRATION'])\n",
      "1286706.0 1 dict_keys(['LA_INFILTRATION'])\n",
      "1090673.0 1 dict_keys(['LA_INFILTRATION'])\n",
      "993553.0 1 dict_keys(['LA_INFILTRATION'])\n"
     ]
    }
   ],
   "source": [
    "studentDict.keys()\n",
    "print('Number of students:', len(studentDict.keys()))\n",
    "for id, items in studentDict.items():\n",
    "    print(id, len(items.keys()), items.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BH-BMED' 'BH-ORHLTH' 'BH-SCI' 'BOH1 (2024)' 'BOH2 (2024)' 'BOH3 (2024)'\n",
      " 'DCD (Endo)' 'DCD (Oral Med)' 'DCD (Ortho)' 'DCD (Paed)' 'DCD (Perio)'\n",
      " 'DCD (Pros)' 'DCD (SND)' 'DDS1 (2024)' 'DDS2 (2024)' 'DDS2 (2023)'\n",
      " 'DDS3 (2024)' 'DDS4 (2024)' 'DR-PHILMDH' 'Grad Dip (Implants)'\n",
      " 'MC-BMEDSC' 'MR-PHILDSC']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>GroupID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Gender</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Preferred Name</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Email</th>\n",
       "      <th>Date of Birth</th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Left or Right Handed</th>\n",
       "      <th>Liability Category</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Reps &amp; Role</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Latest EWS Date</th>\n",
       "      <th>SSP Status</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Institute</th>\n",
       "      <th>Overall WAM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BH-BMED</td>\n",
       "      <td>993898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ang</td>\n",
       "      <td>ian.ang@student.unimelb.edu.au</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commonwealth Supported Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SY 2021 Supervisor - Dr Antonio Celentano</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Biomedicine</td>\n",
       "      <td>UoM</td>\n",
       "      <td>70.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BH-BMED</td>\n",
       "      <td>912254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lin</td>\n",
       "      <td>b.lin9@student.unimelb.edu.au</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commonwealth Supported Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SY 2021 Supervisor - Dr Wenyi Li</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>UoM</td>\n",
       "      <td>70.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BH-BMED</td>\n",
       "      <td>1248604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O'Neil</td>\n",
       "      <td>mitchelloneil8@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commonwealth Supported Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SY 2021 Supervisor - Drs Monica Slavin &amp; Sophi...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Dental Surgery</td>\n",
       "      <td>University of Adelaide</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BH-BMED</td>\n",
       "      <td>1240507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patrycja</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solak</td>\n",
       "      <td>patsol1312@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commonwealth Supported Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SY 2021 Supervisor - Dr Catherine Butler</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Biomedicine</td>\n",
       "      <td>La Trobe University</td>\n",
       "      <td>86.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BH-BMED</td>\n",
       "      <td>912179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yathavan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sriharan</td>\n",
       "      <td>syathavan@icloud.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commonwealth Supported Place</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SY 2021 Supervisor - Dr Catherine Butler</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Biomedical Science</td>\n",
       "      <td>La Trobe University</td>\n",
       "      <td>79.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cohort  Student ID Group  GroupID Title Gender First Name Preferred Name  \\\n",
       "0  BH-BMED      993898   NaN      NaN   NaN    NaN        Ian            NaN   \n",
       "1  BH-BMED      912254   NaN      NaN   NaN    NaN      Bruce            NaN   \n",
       "2  BH-BMED     1248604   NaN      NaN   NaN    NaN   Mitchell            NaN   \n",
       "3  BH-BMED     1240507   NaN      NaN   NaN    NaN   Patrycja            NaN   \n",
       "4  BH-BMED      912179   NaN      NaN   NaN    NaN   Yathavan            NaN   \n",
       "\n",
       "    Surname                           Email Date of Birth  Mobile  \\\n",
       "0       Ang  ian.ang@student.unimelb.edu.au           NaN     NaN   \n",
       "1       Lin   b.lin9@student.unimelb.edu.au           NaN     NaN   \n",
       "2    O'Neil        mitchelloneil8@gmail.com           NaN     NaN   \n",
       "3     Solak            patsol1312@gmail.com           NaN     NaN   \n",
       "4  Sriharan            syathavan@icloud.com           NaN     NaN   \n",
       "\n",
       "  Left or Right Handed            Liability Category Religion Reps & Role  \\\n",
       "0                  NaN  Commonwealth Supported Place      NaN         NaN   \n",
       "1                  NaN  Commonwealth Supported Place      NaN         NaN   \n",
       "2                  NaN  Commonwealth Supported Place      NaN         NaN   \n",
       "3                  NaN  Commonwealth Supported Place      NaN         NaN   \n",
       "4                  NaN  Commonwealth Supported Place      NaN         NaN   \n",
       "\n",
       "                                               Notes Latest EWS Date  \\\n",
       "0          SY 2021 Supervisor - Dr Antonio Celentano             NaT   \n",
       "1                   SY 2021 Supervisor - Dr Wenyi Li             NaT   \n",
       "2  SY 2021 Supervisor - Drs Monica Slavin & Sophi...             NaT   \n",
       "3           SY 2021 Supervisor - Dr Catherine Butler             NaT   \n",
       "4           SY 2021 Supervisor - Dr Catherine Butler             NaT   \n",
       "\n",
       "  SSP Status                   Qualification               Institute  \\\n",
       "0        NaN         Bachelor of Biomedicine                     UoM   \n",
       "1        NaN             Bachelor of Science                     UoM   \n",
       "2        NaN      Bachelor of Dental Surgery  University of Adelaide   \n",
       "3        NaN         Bachelor of Biomedicine     La Trobe University   \n",
       "4        NaN  Bachelor of Biomedical Science     La Trobe University   \n",
       "\n",
       "   Overall WAM  \n",
       "0        70.95  \n",
       "1        70.96  \n",
       "2        80.00  \n",
       "3        86.38  \n",
       "4        79.88  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "listFile = '2024 MDS Student List_v10.xlsx'\n",
    "listDf = pd.read_excel(listFile)\n",
    "\n",
    "# listDf = listDf[['Student ID', 'Cohort']]\n",
    "print(listDf['Cohort'].unique())\n",
    "display(listDf.head())\n",
    "# Create Student ID: Cohort dictionary\n",
    "cohortDict = {}\n",
    "for i, row in listDf.iterrows():\n",
    "    id = row['Student ID']\n",
    "    cohort = row['Cohort']\n",
    "    if '2024' in cohort:\n",
    "        cohortDict[id] = cohort.split(' ')[0]\n",
    "\n",
    "# save cohortDict to json\n",
    "with open('cohortDict.json', 'w') as f:\n",
    "    json.dump(cohortDict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students: 297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([1220151.0, 1462377.0, 994883.0, 1080271.0, 1472336.0, 1461394.0, 1461909.0, 1463403.0, 1443777.0, 1423642.0, 1472645.0, 1452755.0, 1452798.0, 1461567.0, 1443680.0, 1461325.0, 1464586.0, 1472277.0, 1473013.0, 1462155.0, 1048480.0, 1460189.0, 1255058.0, 1452784.0, 1311884.0, 1473073.0, 1270549.0, 1350428.0, 996164.0, 1472938.0, 1461861.0, 1460391.0, 1354148.0, 1353787.0, 1337652.0, 1280725.0, 1472447.0, 1625104.0, 1472250.0, 1617495.0, 1462810.0, 1419850.0, 1472946.0, 1472769.0, 1469829.0, 1452727.0, 1472800.0, 1472810.0, 1455126.0, 1452672.0, 1637288.0, 1472445.0, 1605390.0, 1353765.0, 1352051.0, 1617958.0, 1472831.0, 1146177.0, 1605793.0, 1469076.0, 1606158.0, 1616141.0, 1473072.0, 1617003.0, 1617304.0, 1615261.0, 1615131.0, 1594851.0, 1535538.0, 1608030.0, 1472717.0, 1615593.0, 1637313.0, 1605480.0, 1610017.0, 1606153.0, 1625619.0, 1617587.0, 1625191.0, 1615333.0, 1600923.0, 1462773.0, 1616618.0, 1634259.0, 1606071.0, 1617334.0, 1461457.0, 1625702.0, 1321463.0, 1624825.0, 1606077.0, 1605538.0, 1466081.0, 1639983.0, 1594958.0, 1377061.0, 1460683.0, 1197105.0, 980645.0, 1080594.0, 1203413.0, 1067694.0, 1211908.0, 1473169.0, 1472637.0, 974490.0, 1084710.0, 1129001.0, 1082760.0, 900511.0, 1211920.0, 1463086.0, 1035913.0, 1473664.0, 1472266.0, 1473826.0, 1088656.0, 1084469.0, 947992.0, 916569.0, 1302623.0, 832527.0, 1213575.0, 913949.0, 608989.0, 1222310.0, 1080466.0, 1213084.0, 1084203.0, 985101.0, 1306943.0, 1079606.0, 1213578.0, 1218071.0, 1472568.0, 944792.0, 1098429.0, 1241309.0, 1452767.0, 1219506.0, 969985.0, 1080800.0, 997453.0, 995150.0, 1215995.0, 900893.0, 1083170.0, 1083399.0, 1102550.0, 984694.0, 1211902.0, 1213105.0, 1222329.0, 1327995.0, 993257.0, 913592.0, 1328021.0, 913450.0, 1328001.0, 1081205.0, 1461239.0, 1353677.0, 1472540.0, 1472625.0, 1353950.0, 1605779.0, 1606096.0, 1605677.0, 1430664.0, 1616745.0, 1463879.0, 1178529.0, 1387538.0, 1383423.0, 1064909.0, 1377158.0, 993640.0, 1082185.0, 985199.0, 1173101.0, 1079984.0, 1083971.0, 1079946.0, 1399221.0, 1307153.0, 1384393.0, 1213577.0, 1080247.0, 1384391.0, 1309754.0, 1402039.0, 1388926.0, 1173233.0, 1171800.0, 1420100.0, 1174172.0, 1420119.0, 992914.0, 1399220.0, 1391596.0, 1180737.0, 1420083.0, 1170848.0, 1388600.0, 1287253.0, 1391557.0, 1172496.0, 1085148.0, 1187088.0, 1184941.0, 1170745.0, 1079663.0, 1212518.0, 1301220.0, 1113227.0, 1387067.0, 1420053.0, 1173430.0, 1402789.0, 1394580.0, 1420079.0, 1420060.0, 1084831.0, 1394124.0, 1384390.0, 1170316.0, 1420118.0, 1384392.0, 1211876.0, 1031163.0, 1081308.0, 1027970.0, 1309751.0, 1221853.0, 1329195.0, 1300764.0, 1309763.0, 1069842.0, 1168876.0, 1171988.0, 587525.0, 1209449.0, 1181425.0, 1420124.0, 1174040.0, 1391578.0, 1371861.0, 1420122.0, 1171108.0, 1082412.0, 1170752.0, 758770.0, 1394123.0, 1388256.0, 1170993.0, 1402031.0, 1330715.0, 1107398.0, 1389354.0, 1232770.0, 1187046.0, 1399214.0, 1081376.0, 1420096.0, 617915.0, 1402035.0, 1081787.0, 1420062.0, 1082018.0, 1181472.0, 1192826.0, 1617738.0, 1192819.0, 1079894.0, 1082098.0, 1213078.0, 1112370.0, 1213090.0, 1221841.0, 1081939.0, 1067973.0, 1205045.0, 1080136.0, 987912.0, 1218058.0, 1126914.0, 1197946.0, 734343.0, 1213093.0, 1328023.0, 1079470.0, 1328043.0, 1328020.0, 1217909.0, 1286706.0, 1090673.0, 993553.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display(cohortDict)\n",
    "# remove students not in 2024 cohort\n",
    "keys = list(studentDict.keys())\n",
    "for key in keys:\n",
    "    if key not in cohortDict.keys():\n",
    "        del studentDict[key]\n",
    "        print(key)\n",
    "print('Number of students:', len(studentDict.keys()))\n",
    "display(studentDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students: 324\n",
      "1083129\n",
      "759735\n",
      "987528\n",
      "1035907\n",
      "1222331\n",
      "1081387\n",
      "693184\n",
      "835866\n",
      "1080894\n",
      "1352187\n",
      "1346822\n",
      "1354146\n",
      "1354147\n",
      "1268620\n",
      "1337581\n",
      "1354025\n",
      "1049674\n",
      "1337571\n",
      "1352197\n",
      "1350430\n",
      "1354161\n",
      "1362971\n",
      "1247370\n",
      "1350539\n",
      "1352179\n",
      "1354103\n",
      "1233586\n",
      "1343049\n",
      "\n",
      "\n",
      "1472831.0\n"
     ]
    }
   ],
   "source": [
    "listdf = pd.read_excel('Student ID for Kunal.xlsx')\n",
    "students = listdf['Student ID'].unique()\n",
    "print('Number of students:', len(students))\n",
    "if len(students) > 0:\n",
    "    for s in students:\n",
    "        if s not in studentDict.keys():\n",
    "            print(s)\n",
    "            # studentDict[s] = {}\n",
    "# Now the reverse, find students in the dictionary that are not in the list\n",
    "print('\\n')\n",
    "keys = list(studentDict.keys())\n",
    "for key in keys:\n",
    "    if key not in students:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(841.68, 1190.8799999999999)\n"
     ]
    }
   ],
   "source": [
    "pageSize = ( 11.69 * inch, 8.27 * 2 * inch) # page size\n",
    "print(pageSize)\n",
    "figSize = (pageSize[0] / 100, pageSize[1] / 100)\n",
    "\n",
    "# Define the margins\n",
    "leftMargin = 0 * inch\n",
    "rightMargin = 0 * inch\n",
    "topMargin = 1 * inch\n",
    "bottomMargin = 0 * inch\n",
    "\n",
    "# Define the styles for the headings\n",
    "styles = getSampleStyleSheet()\n",
    "styles.add(ParagraphStyle(name='Center', alignment=1))  # Center alignment\n",
    "headingStyle = ParagraphStyle('Heading1', parent=styles['Heading1'], fontSize=32, alignment=1)  # Centered\n",
    "heading2Style = ParagraphStyle('Heading2', parent=styles['Heading2'], fontSize=28, alignment=1)  # Centered\n",
    "subheadingStyle = ParagraphStyle('Heading2', parent=styles['Heading2'], fontSize=24, alignment=1)  # Centered\n",
    "subsubheadingStyle = ParagraphStyle('Heading3', parent=styles['Heading3'], fontSize=20, alignment=1)  # Centered\n",
    "normalLargeStyleLeft = ParagraphStyle('NormalLarge', parent=styles['Normal'], fontSize=18, alignment=0)  # Left aligned\n",
    "normalLargeStyleCenter = ParagraphStyle('NormalLarge2', parent=styles['Normal'], fontSize=18, alignment=1)  # Center aligned\n",
    "tableTextStyle = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=13, alignment=1)\n",
    "tableTextStyleSmall= ParagraphStyle('SmallFont', parent=styles['Normal'], fontSize=11, alignment=1)\n",
    "\n",
    "Checklistcolors = {'Yes': 'blue', 'No': 'orange', 'Not Reviewed': 'lightgrey'}\n",
    "# Set the colorblind-friendly palette\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_agg(series):\n",
    "    unique_vals = series.dropna().unique()\n",
    "    if len(unique_vals) == 0: # All values are NA\n",
    "        return pd.NA\n",
    "    if len(unique_vals) == 1: # Only one unique value \n",
    "        return unique_vals[0]\n",
    "    else:\n",
    "        if '1' in unique_vals:\n",
    "            return '1'\n",
    "        elif 1 in unique_vals:\n",
    "            return 1\n",
    "        elif '0' in unique_vals:\n",
    "            return '0'\n",
    "        elif 0 in unique_vals:\n",
    "            return 0\n",
    "        else:\n",
    "            return pd.NA\n",
    "\n",
    "def CEAgg(series):\n",
    "    unique_vals = series.dropna().unique()\n",
    "    if len(unique_vals) == 0: # All values are NA\n",
    "        return pd.NA\n",
    "    if len(unique_vals) == 1: # Only one unique value \n",
    "        return unique_vals[0]\n",
    "    else:\n",
    "        if 'Yes' in unique_vals:\n",
    "            return 'Yes'\n",
    "        elif 'No' in unique_vals:\n",
    "            return 'No'\n",
    "        else:\n",
    "            return pd.NA\n",
    "        \n",
    "def processLabel(label):\n",
    "    words = label.split()  # Split the label into words\n",
    "    if len(words) >= 3:\n",
    "        # Truncate the third word to its first four letters\n",
    "        words = words[:2] + [words[2][:4]]\n",
    "    elif len(words) == 2:\n",
    "        # If there are only two words, use them as is\n",
    "        words = words\n",
    "    elif len(words) == 1:\n",
    "        # If there is only one word, use it as is\n",
    "        words = words\n",
    "    return ' '.join(words)\n",
    "\n",
    "def sortByTotal(df):\n",
    "    # row wise sum of the dataframe\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    # sort by the row wise sum\n",
    "    df.sort_values(by='Total', ascending=False, inplace=True)\n",
    "    # drop the total column\n",
    "    df.drop(columns=['Total'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637313 Moe Myint Tha BOH2 Simulation\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "         Date   PS\n",
      "0  07/08/2024  2.0\n",
      "1  14/08/2024  2.0\n",
      "Date PS 0    07/08/2024\n",
      "1    14/08/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "1    2.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  07/08/2024  2.0\n",
      "1  14/08/2024  2.0\n",
      "Date CS 0    07/08/2024\n",
      "1    14/08/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "1    2.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  07/08/2024  2.0\n",
      "1  14/08/2024  4.0\n",
      "Date TS 0    07/08/2024\n",
      "1    14/08/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "1    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  07/08/2024  2.0\n",
      "1  14/08/2024  3.0\n",
      "Date ES 0    07/08/2024\n",
      "1    14/08/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "1    3.0\n",
      "Name: ES, dtype: Float64\n",
      "1637313 Moe Myint Tha BOH2 Clinic\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "         Date   PS\n",
      "0  05/08/2024  3.0\n",
      "Date PS 0    05/08/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  05/08/2024  2.0\n",
      "Date CS 0    05/08/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  05/08/2024  3.0\n",
      "Date TS 0    05/08/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  05/08/2024  2.0\n",
      "Date ES 0    05/08/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "Name: ES, dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "id = 1295910\n",
    "labelItem = 'Item'\n",
    "labelYes = 'Yes'\n",
    "labelNo = 'No'\n",
    "labelNA = 'Not Reviewed'\n",
    "labelCountItem = '# forms filled'\n",
    "sawPatientText = 'I saw a patient'\n",
    "operatorRoleText = 'Operator'\n",
    "rubricTitle = {'PS': 'Professionalism', 'CS': 'Communication', 'TS': 'Time Management', 'ES': 'Entrustment'}\n",
    "rubricReferenceTableDf = pd.read_excel('Rubric Reference Table.xlsx')\n",
    "# display(rubricReferenceTableDf)\n",
    "barsPerSubplot = 6\n",
    "subplotsPerPage = 6\n",
    "with open(variableUtils.mcReferenceFile) as f:\n",
    "    mcReferenceDict = json.load(f)\n",
    "\n",
    "class StudentInfo:\n",
    "    def __init__(self, id, locationLabel=None) -> None: # locationLabel is the label for the location of the student Simulation or Clinic\n",
    "        self.id = id\n",
    "        name = listDf[listDf[colId] == id]['First Name'].values[0] + ' ' + listDf[listDf[colId] == id]['Surname'].values[0]\n",
    "        cohort = cohortDict[id]\n",
    "        print(id, name, cohort, locationLabel)\n",
    "        saveFolder = f'{folder}/{cohort}'\n",
    "        os.makedirs(saveFolder, exist_ok=True)\n",
    "        self.dfDict = studentDict[id]\n",
    "        self.locationLabel = locationLabel\n",
    "\n",
    "        self.doc = SimpleDocTemplate(f\"{saveFolder}/{str(int(id))} - {name} ({locationLabel}).pdf\", pagesize=pageSize, leftMargin=leftMargin,\n",
    "                    rightMargin=rightMargin, topMargin=topMargin, bottomMargin=bottomMargin)\n",
    "        self.elements = []\n",
    "        self.elements.append(Paragraph(f\"{name} ({str(int(id))})\", headingStyle))\n",
    "        self.elements.append(Spacer(1, 12))\n",
    "        self.elements.append(Paragraph(f\"{locationLabel.upper()}\", heading2Style))\n",
    "        self.elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Function to create and return a plot image as BytesIO\n",
    "    def createPlotImage(self, fig):\n",
    "            buf = BytesIO()\n",
    "            fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "            buf.seek(0)\n",
    "            return buf\n",
    "\n",
    "    def addPlotImage(self, fig, ratio = None):\n",
    "            plotImage = self.createPlotImage(fig)\n",
    "            image = Image(plotImage)\n",
    "            # print(image.drawWidth, image.drawHeight)\n",
    "            \n",
    "            # Resize image to fit within margins\n",
    "            max_height = pageSize[1] - topMargin - bottomMargin  # Max height for Page\n",
    "            max_width = pageSize[0] - leftMargin - rightMargin  # Max width for Page\n",
    "            if ratio is not None:\n",
    "                max_width = max_width * ratio\n",
    "                max_height = max_height * ratio\n",
    "            aspect_ratio = min(max_width / image.drawWidth, max_height / image.drawHeight)\n",
    "            image.drawWidth *= aspect_ratio\n",
    "            image.drawHeight *= aspect_ratio\n",
    "            # print(image.drawWidth, image.drawHeight, aspect_ratio)\n",
    "            self.elements.append(image)\n",
    "            # if idx + 1 < numSubplots:\n",
    "            #    self.elements.append(PageBreak())\n",
    "            #self.elements.append(PageBreak())\n",
    "            plt.close(fig)\n",
    "    \n",
    "    def createMcReferenceDf(self, code, tag):\n",
    "        respectiveMCKey = [key for key in mcReferenceDict.keys() if re.match(f'{code}_MC\\d+', key)]\n",
    "        respectiveMCKey = [key for key in respectiveMCKey if tag in key]\n",
    "        # get the dict part of mcReferenceDict based on the respectiveMCKey\n",
    "        mcRef = {key: mcReferenceDict[key] for key in respectiveMCKey}\n",
    "        # print(mcRef)\n",
    "        # Trun mcRef into a DataFrame\n",
    "        if mcRef:\n",
    "            mcRefdf = pd.DataFrame(list(mcRef.items()), columns=['Abbreviation', 'Full Text'])\n",
    "        \n",
    "            # extract MC\\d+ from Abbreviation and replace it\n",
    "            if code!= '114' and code != '115':\n",
    "                mcRefdf['MC'] = mcRefdf['Abbreviation'].str.extract(r'(MC\\d+)')\n",
    "            else:\n",
    "                mcRefdf['MC'] = mcRefdf['Abbreviation'].str.extract(r'(MC\\d+)')\n",
    "                extracted_values = mcRefdf['Abbreviation'].str.extract(r'(H/S|U/S)', expand=False)\n",
    "                # print(extracted_values)\n",
    "                # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "                mcRefdf['MC'] = mcRefdf['MC'] + ' ' + extracted_values\n",
    "            # drop the Abbreviation column\n",
    "            # print(mcRefdf.columns)\n",
    "            # Swap columns\n",
    "            mcRefdf = mcRefdf[['MC', 'Full Text']]\n",
    "            # mcRefdf.drop(columns=['Abbreviation'], inplace=True)\n",
    "            # display(mcRefdf)\n",
    "        \n",
    "        else:\n",
    "            # print(mcRef)\n",
    "            mcRefdf = None\n",
    "        return mcRefdf\n",
    "\n",
    "    def plotPie(self, ax, valueCounts, title, colors=None):\n",
    "        # print(valueCounts)\n",
    "        # define a fixed colour palette color blind friendly\n",
    "        # print(valueCounts.index)\n",
    "        colorList = [colors[val] for val in valueCounts.index] if colors is not None else None\n",
    "        total = valueCounts.values.sum()\n",
    "        # print(total)\n",
    "        def autopct(pct):\n",
    "            val = int(round(pct * total / 100.0))\n",
    "            return '{:.0f}%\\n({v:d})'.format(pct, v=val) if pct > 0 else ''\n",
    "        \n",
    "        wedges, texts, autotexts = ax.pie(valueCounts, labels=valueCounts.index, autopct=autopct, startangle=90, colors=sns.color_palette() if colorList is None else colorList,\n",
    "                wedgeprops={'edgecolor': 'black', 'linewidth': 0.35}, labeldistance = 0.7, pctdistance=1.15, textprops={'color': 'black', 'fontsize': 10})\n",
    "        for autotext in texts:\n",
    "            autotext.set_color('black')\n",
    "            autotext.set_fontsize(10)\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "    def plotLineSeries(self, ax, data, xcol, ycol, title, color=None):\n",
    "        print(xcol, ycol, data[xcol], data[ycol])\n",
    "        data.plot(x=xcol, y=ycol, kind='line', ax=ax, color=color if color is not None else sns.color_palette(), marker='o', legend=False)\n",
    "        ax.set_title(title)\n",
    "        ax.set_yticks(range(1, 5))\n",
    "        ax.set_ylim(0, 4.5)\n",
    "        ax.set_xlabel(None)\n",
    "        # rotate by 90\n",
    "        ax.set_xticks(range(len(data[xcol])))\n",
    "        ax.set_xticklabels(data[xcol], rotation=30, fontsize=8)\n",
    "        ax.set_ylabel('')\n",
    "\n",
    "    def createSubplot(self, ax, subset, show_legend=False, colors = None, xticks = None):\n",
    "     \n",
    "        subset.plot(kind='bar', stacked=True, ax=ax, edgecolor='black', color=colors if colors is not None else sns.color_palette(), legend=show_legend)\n",
    "        # Add the legend only if show_legend is True\n",
    "        if show_legend:\n",
    "            ax.legend(title='', loc='upper right', bbox_to_anchor=(1, 1), bbox_transform=ax.transAxes)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('Count')\n",
    "        # desired_ticks = range(len(xticks))\n",
    "        # print(desired_ticks)\n",
    "        # ax.set_xticks(range(len(xticks)))\n",
    "        # ax.set_xticklabels(xticks)\n",
    "        # y ticks should be integers\n",
    "        ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "        # ylim should start from 0\n",
    "        ax.set_ylim(0, ax.get_ylim()[1] * 1.1)\n",
    "        # minimum gap of y ticks is 1\n",
    "        if ax.get_ylim()[1] < 5:\n",
    "            ax.yaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "        # Show gridlines on the y-axis\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        # Convert index to strings to avoid errors with re.sub\n",
    "        subset.index = [str(i) for i in subset.index]\n",
    "        # x tick labels, remove _ and put space\n",
    "        subset.index = [processLabel(i) for i in subset.index]\n",
    "        ax.set_xticklabels(subset.index, rotation=45, ha='center')\n",
    "\n",
    "        # Check for bars with total value of zero\n",
    "        for i, total in enumerate(subset.sum(axis=1)):\n",
    "            if total == 0 and subset.index[i] != '':\n",
    "                # Overlay 'No data available' text vertically, adjusted lower\n",
    "                ax.text(i, ax.get_ylim()[0] + 0.25 * ax.get_ylim()[1], 'No data available', \n",
    "                        ha='center', va='center', rotation=90, fontsize=10, color='black', alpha=0.7)\n",
    "\n",
    "\n",
    "    def addGraphs(self, countsDf, maxBars = 6, maxNSubplots = 6, nCols=2, colors = None, dynamicHeight = True, startingSubplots = None):\n",
    "        df = countsDf.copy()\n",
    "\n",
    "        # Number of rows and columns for subplots\n",
    "        numSubplots = len(df) // maxBars + (1 if len(df) % maxBars > 0 else 0)\n",
    "        if len(df) < maxBars:\n",
    "            maxBars = len(df)\n",
    "        maxRows = maxNSubplots // nCols\n",
    "        if dynamicHeight:\n",
    "            maxRows = int(np.ceil(min(numSubplots, maxNSubplots)/ nCols))\n",
    "        # Display starting subplots number of plots on the first page\n",
    "        if startingSubplots is None:\n",
    "            startingSubplots = maxNSubplots\n",
    "            lastPageSubplots = numSubplots % maxNSubplots\n",
    "        else:\n",
    "            alreadyNumPlots = 3 - startingSubplots\n",
    "            if alreadyNumPlots + numSubplots <= 3:\n",
    "                lastPageSubplots = (alreadyNumPlots + numSubplots)\n",
    "            else:\n",
    "                lastPageSubplots = abs(numSubplots - startingSubplots) % maxNSubplots\n",
    "            startingSubplots = min(startingSubplots, numSubplots)\n",
    "\n",
    "        # Loop over the DataFrame and create subplots\n",
    "        # for i in range(0, numSubplots, maxNSubplots):\n",
    "        i = 0\n",
    "        while i < numSubplots:\n",
    "            if i == 0:\n",
    "                    current_subplots = startingSubplots\n",
    "            else:\n",
    "                    current_subplots = maxNSubplots\n",
    "            # print(i, current_subplots, (figsize[0], figsize[1] / maxNSubplots * current_subplots))\n",
    "            nRows = int(np.ceil(current_subplots/nCols))\n",
    "            fig, axes = plt.subplots(nrows=nRows, ncols=nCols, figsize=(figSize[0], figSize[1] / maxRows * nRows))\n",
    "            if current_subplots == 1:\n",
    "                axes = [axes]\n",
    "            else:\n",
    "                axes = axes.flatten()\n",
    "            \n",
    "            for j in range(current_subplots):\n",
    "                idx = i + j\n",
    "                if idx < numSubplots:\n",
    "                    start_idx = idx * maxBars\n",
    "                    end_idx = start_idx + maxBars\n",
    "                    subset = df.iloc[start_idx:end_idx]\n",
    "                    xticks = subset.index\n",
    "                    # If there are fewer than maxBars, pad with empty rows\n",
    "                    if len(subset) < maxBars:\n",
    "                        empty_rows = pd.DataFrame(0, index=[''] * (maxBars - len(subset)), columns=subset.columns)\n",
    "                        subset = pd.concat([subset, empty_rows])\n",
    "                    # Show legend only for the first subplot\n",
    "                    self.createSubplot(axes[j], subset, show_legend=(i == 0 and j == 0), colors=colors, xticks=xticks)\n",
    "                else:\n",
    "                    axes[j].remove()\n",
    "            i+=current_subplots\n",
    "            # fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1, 1), bbox_transform=fig.transFigure)\n",
    "            plt.subplots_adjust(hspace=0.4)\n",
    "            # plt.suptitle('Counts for each item')\n",
    "            fig.tight_layout(rect=[0, 0, 1, 1])  # Adjust layout to make room for the legend\n",
    "            self.addPlotImage(fig, 0.9)\n",
    "            if idx + 1 < numSubplots:\n",
    "                self.elements.append(PageBreak())\n",
    "            #self.elements.append(PageBreak())\n",
    "            plt.close(fig)\n",
    "        \n",
    "        if lastPageSubplots == 0:\n",
    "            lastPageSubplots = maxNSubplots\n",
    "        return lastPageSubplots  \n",
    "\n",
    "    def addMCReferenceTable(self, mcRefdf, header):\n",
    "        \n",
    "        if mcRefdf is None:\n",
    "            self.elements.append(Paragraph(\"No marking checklist reference found\", subsubheadingStyle))\n",
    "            return\n",
    "        largeFontStyle = ParagraphStyle('LargeFont', parent=styles['Normal'], fontSize=13, alignment=0)\n",
    "\n",
    "        # Create a table with MC and Full Text columns\n",
    "        data = [mcRefdf.columns.to_list()] + mcRefdf.values.tolist()\n",
    "        for i in range(1, len(data)):\n",
    "            data[i][1] = Paragraph(data[i][1], largeFontStyle)\n",
    "            data[i][0] = Paragraph(data[i][0], largeFontStyle)\n",
    "        table = Table(data, colWidths=[1.5 * inch, 9 * inch])\n",
    "\n",
    "        # Set the style for the table text as large font\n",
    "        \n",
    "\n",
    "        table_style = TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#236DB0')),  # Header row\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "            ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "            ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "            ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "            ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, -1), 12),  # Increase bottom padding\n",
    "            ('TOPPADDING', (0, 0), (-1, -1), 12),  # Increase top padding\n",
    "        ])\n",
    "        table.setStyle(table_style)\n",
    "        mergedElement = KeepTogether([header, Spacer(1, 12), table])\n",
    "        self.elements.append(mergedElement)\n",
    "        # self.elements.append(table)\n",
    "        # self.elements.append(PageBreak())\n",
    "\n",
    "        \n",
    "    def createTable(self, df, title, colRatio, tableWidth = 0.9, customTextCols = [], tableTextStyle = tableTextStyle, topPadding = 12, bottomPadding = 12, cellHighlight = False, headerColor = '#9C27B0'):\n",
    "        \n",
    "        if df.empty:\n",
    "            table = Paragraph(\"No data found\", subsubheadingStyle)\n",
    "        else:\n",
    "            data = [df.columns.to_list()] + df.values.tolist()\n",
    "            \n",
    "            # Convert the custom text columns to paragraphs\n",
    "            for i in range(1, len(data)):\n",
    "                for j in customTextCols:\n",
    "                    data[i][j] = Paragraph(str(data[i][j]), tableTextStyle)\n",
    "            \n",
    "            if colRatio is not None:\n",
    "                colWidths = [ratio/sum(colRatio) * pageSize[0] * tableWidth for ratio in colRatio]\n",
    "            else:\n",
    "                colWidths = [1 for i in range(len(df.columns))] # Equal column widths\n",
    "            # print(f'Column widths: {colWidths}')\n",
    "            table = Table(data, colWidths=colWidths)\n",
    "            \n",
    "            table_style = TableStyle([\n",
    "                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor(headerColor)),  # Header row\n",
    "                ('TEXTCOLOR', (0, 0), (-1, 0), colors.HexColor('#FFFFFF')),  # Header text\n",
    "                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),  # Center align all cells\n",
    "                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),  # Center align all cells\n",
    "                ('GRID', (0, 0), (-1, -1), 1, colors.black),  # Add border around cells\n",
    "                ('ALIGN', (3, 1), (3, -1), 'LEFT'),  # Left align Reason column cells\n",
    "                ('FONTNAME', (0, 0), (-1, -1), 'Helvetica-Bold'),  # Change font to bold\n",
    "                ('FONTSIZE', (0, 0), (-1, -1), 14),  # Increase font size\n",
    "                ('BOTTOMPADDING', (0, 0), (-1, -1), bottomPadding),  # Increase bottom padding\n",
    "                ('TOPPADDING', (0, 0), (-1, -1), topPadding),  # Increase top padding\n",
    "            ])\n",
    "            table.setStyle(table_style)\n",
    "\n",
    "        mergedElement = KeepTogether([Paragraph(title, subsubheadingStyle), Spacer(1, 12), table, Spacer(1, 12)])\n",
    "        self.elements.append(mergedElement)\n",
    "        # self.elements.append(Spacer(1, 12))\n",
    "\n",
    "        # Add red colour where cell values are No\n",
    "        if not cellHighlight:\n",
    "            return\n",
    "        for i in range(1, len(data)):\n",
    "            for j in range(len(data[i])):\n",
    "                if data[i][j] == 'No':\n",
    "                    table.setStyle(TableStyle([('TEXTCOLOR', (j, i), (j, i), colors.red)]))\n",
    "\n",
    "    def getDfs(self):\n",
    "        self.subjectDateItemDf = pd.DataFrame(columns=[colSubject, colDate, labelItem])\n",
    "        self.CEDf = pd.DataFrame(columns=[colSubject, labelItem, colDate, colCE, colCEReason])\n",
    "        self.operatorCount = None if self.locationLabel == 'Simulation' else 0\n",
    "        self.sawPatientCount = None if self.locationLabel == 'Simulation' else 0\n",
    "        self.rubricDf = pd.DataFrame(columns=[colSubject, colDate, labelItem] + rubricQues)\n",
    "        self.countsMCWiseDfDict = {}\n",
    "        self.fullMCDfDict = {}\n",
    "        self.mcCountsDf = pd.DataFrame(index = [item.replace('_', ' ') for item in self.dfDict.keys()], columns=[labelYes, labelNo, labelNA])\n",
    "        self.overallRKCDf = pd.DataFrame()\n",
    "        self.itemMCReferenceDict = {}\n",
    "        for item, itemDf in self.dfDict.items():\n",
    "\n",
    "            # itemDisplay = item.replace('_', ' ')\n",
    "            code = item.split('_')[0]\n",
    "            tag = item.split('_')[1]\n",
    "            tag = tag.replace('-', '/')\n",
    "            itemDisplay = code + ' ' + tag\n",
    "            if code == '941':\n",
    "                continue\n",
    "            mcColumns = findMCColumns(itemDf, code)\n",
    "            # print(code, tag)\n",
    "            # display(itemDf)\n",
    "            # print(mcColumns)\n",
    "            countsClinic = itemDf[colClinicChoice].value_counts()\n",
    "            highestClinic = countsClinic.idxmax()\n",
    "            \n",
    "            if self.locationLabel is not None:\n",
    "                # print(highestClinic, label)\n",
    "                if self.locationLabel == 'Simulation' and self.locationLabel != highestClinic:\n",
    "                    # print('Skipping', item)\n",
    "                    continue\n",
    "                elif self.locationLabel == 'Clinic' and highestClinic == 'Simulation':\n",
    "                    # print('Skipping', item)\n",
    "                    continue\n",
    "\n",
    "            # Aggregate if tag is SIM (Take the best value for each column for each student)\n",
    "            if highestClinic == 'Simulation':\n",
    "                # Step 1: Define the aggregation functions for each group of columns\n",
    "                aggFuncs = {col: 'first' for col in itemDf.columns if col not in mcColumns + rubricQues + [colCE, colCEReason]}\n",
    "                aggFuncs.update({col: custom_agg for col in mcColumns})\n",
    "                aggFuncs.update({col: 'max' for col in rubricQues})\n",
    "                aggFuncs.update({colCE: CEAgg})\n",
    "                aggFuncs.update({colCEReason: lambda x: ';\\n '.join(x.dropna().unique())})\n",
    "                itemDf = itemDf.groupby([colDate, colId], as_index=False).agg(aggFuncs) \n",
    "            \n",
    "            # Get the count of operators and patients seen if clinic\n",
    "            if self.locationLabel == 'Clinic':\n",
    "                operatorcount = itemDf[colRole].apply(lambda x: 1 if x == operatorRoleText else 0).sum()\n",
    "                # print(itemDisplay, operatorcount, len(itemDf))\n",
    "                self.operatorCount += operatorcount\n",
    "\n",
    "                sawPatientcount = itemDf[colPatient].apply(lambda x: 1 if x == sawPatientText else 0).sum()\n",
    "                # print(itemDisplay, sawPatientcount, len(itemDf))\n",
    "                self.sawPatientCount += sawPatientcount\n",
    "\n",
    "            # create a df to store counts of Yes, No and Not Reviewed for each MC column\n",
    "            countsMCWiseDf = pd.DataFrame(index=mcColumns, columns=[labelYes, labelNo, labelNA])\n",
    "            for col in mcColumns:\n",
    "                countsMCWiseDf.at[col, labelYes] = (itemDf[col] == 1).sum() + (itemDf[col] == '1').sum()\n",
    "                countsMCWiseDf.at[col, labelNo] = (itemDf[col] == 0).sum() + (itemDf[col] == '0').sum()\n",
    "                countsMCWiseDf.at[col, labelNA] = (itemDf[col] == 'NA').sum()\n",
    "            # sort the columns based on the MC number\n",
    "            countsMCWiseDf['_sort_key'] = countsMCWiseDf.index # sort based on MC column\n",
    "            countsMCWiseDf['_sort_key'] = countsMCWiseDf['_sort_key'].str.extract(r'MC(\\d+)').astype(int) # extract digit\n",
    "            countsMCWiseDf.sort_values(by='_sort_key', inplace=True)\n",
    "            countsMCWiseDf.drop(columns=['_sort_key'], inplace=True)   \n",
    "            self.countsMCWiseDfDict[itemDisplay] = countsMCWiseDf\n",
    "\n",
    "            # store the overall counts in the main df\n",
    "            self.mcCountsDf.at[itemDisplay, labelYes] = countsMCWiseDf[labelYes].sum()\n",
    "            self.mcCountsDf.at[itemDisplay, labelNo] = countsMCWiseDf[labelNo].sum()\n",
    "            self.mcCountsDf.at[itemDisplay, labelNA] = countsMCWiseDf[labelNA].sum()\n",
    "\n",
    "            # Get full MC df\n",
    "            sort_keys = [int(re.search(r'MC(\\d+)', col_name).group(1)) for col_name in mcColumns]\n",
    "            # print(sort_keys)\n",
    "            # Sort the columns based on the extracted numeric values\n",
    "            sortedColumns = [mcColumns[i] for i in np.argsort(sort_keys)]\n",
    "            fullMCDf = itemDf[[colDate]+sortedColumns]\n",
    "            fullMCDf.sort_values(by=colDate, inplace=True) \n",
    "            # sort columns based on MC number\n",
    "            self.fullMCDfDict[itemDisplay] = fullMCDf\n",
    "            \n",
    "            # Get the MC reference table\n",
    "            referenceDf = self.createMcReferenceDf(code, tag)\n",
    "            self.itemMCReferenceDict[itemDisplay] = referenceDf\n",
    "\n",
    "            for i, row in itemDf.iterrows():\n",
    "                # print(row[colFinished])\n",
    "                if row[colFinished] == 0:\n",
    "                    continue\n",
    "                new_row = pd.DataFrame({colSubject: [row[colSubject]], colDate: [row[colDate]], labelItem: [itemDisplay]})\n",
    "                # print(new_row)\n",
    "                self.subjectDateItemDf = pd.concat([self.subjectDateItemDf, new_row], ignore_index=True)\n",
    "                \n",
    "                ceRow = pd.DataFrame({colSubject: [row[colSubject]], labelItem: [itemDisplay], colDate: [row[colDate]], colCE: [row[colCE]], colCEReason: [row[colCEReason]]})\n",
    "                self.CEDf = pd.concat([self.CEDf, ceRow], ignore_index=True)\n",
    "\n",
    "                rubricRowDict1 = {colSubject: [row[colSubject]], colDate: [row[colDate]], labelItem: [itemDisplay]}\n",
    "                rubricRowDict2 = {col: [row[col]] for col in rubricQues}\n",
    "                rubricRowDict1.update(rubricRowDict2)\n",
    "                rubricRow = pd.DataFrame(rubricRowDict1)\n",
    "                self.rubricDf = pd.concat([self.rubricDf, rubricRow], ignore_index=True)\n",
    "\n",
    "        # Group by Subject and Date, then aggregate the items\n",
    "        # self.groupedDf = self.subjectDateItemDf.groupby(['Subject', 'Date'])['Item'].apply(lambda x: ', '.join(sorted(set(x)))).reset_index()\n",
    "        self.groupedDf = self.subjectDateItemDf.groupby([colDate])[labelItem].apply(lambda x: ', '.join(sorted(set(x)))).reset_index()\n",
    "        self.ceGroupedDf = self.CEDf.groupby([colSubject, colDate, colCE, colCEReason])[labelItem].apply(lambda x: ', '.join(sorted(set(x)))).reset_index()\n",
    "\n",
    "        for col in rubricQues:\n",
    "            self.rubricDf[col] = self.rubricDf[col].astype('Int64')\n",
    "\n",
    "        self.rubricGroupedDf = self.rubricDf.groupby([colSubject, colDate] + rubricQues)[labelItem].apply(lambda x: ', '.join(sorted(set(x)))).reset_index() # group by subject, date and rubric questions\n",
    "        \n",
    "        # groupo by date for a time series plot\n",
    "        aggDict1 = {labelItem: ','.join}\n",
    "        aggDict2 = {col: 'mean' for col in rubricQues}\n",
    "        aggDict1.update(aggDict2)\n",
    "        self.rubricGroupedDfDate = self.rubricGroupedDf.groupby([colDate]).agg(aggDict1).reset_index()\n",
    "        self.rubricGroupedDfDate.sort_values(colDate, inplace=True)\n",
    "\n",
    "        # group rubric by item for a average score comparison\n",
    "        self.rubricGroupedDfItem = self.rubricDf.groupby([labelItem])[rubricQues].agg('mean').reset_index()\n",
    "        \n",
    "        # mc counts df drop na rows \n",
    "        self.mcCountsDf.dropna(inplace=True)\n",
    "        sortByTotal(self.mcCountsDf)\n",
    "        # display(self.subjectDateItemDf)\n",
    "        # display(self.groupedDf)\n",
    "        # display(self.CEDf)\n",
    "        # display(self.ceGroupedDf)\n",
    "        # display(self.rubricDf)\n",
    "        # display(self.rubricGroupedDf)\n",
    "        # display(self.rubricGroupedDfDate)\n",
    "        # display(self.rubricGroupedDfItem)\n",
    "        # display(self.mcCountsDf)\n",
    "\n",
    "    def reIndexMcCountsDf(self, code, countsMCWiseDf):\n",
    "        if code!= '114' and code!='115':\n",
    "            countsMCWiseDf.index = [re.search(r'MC\\d+', str(i)).group() if re.search(r'MC\\d+', str(i)) else i for i in countsMCWiseDf.index]\n",
    "        else:\n",
    "            countsMCWiseDf['newIndex'] = countsMCWiseDf.index\n",
    "            countsMCWiseDf['newIndex'] = countsMCWiseDf['newIndex'].str.extract(r'(MC\\d+)')\n",
    "\n",
    "            #display(countsMCWiseDf)\n",
    "            extracted_values = countsMCWiseDf.index.str.extract(r'(H/S|U/S)', expand=False)\n",
    "                # print(extracted_values)\n",
    "                # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "            countsMCWiseDf['newIndex'] = countsMCWiseDf['newIndex'] + ' ' + extracted_values\n",
    "            countsMCWiseDf.set_index('newIndex', inplace=True)\n",
    "    \n",
    "    def renameMcColumns(self, code, mcDf):\n",
    "        if code!= '114' and code!='115':    \n",
    "            mcDf.columns = [re.search(r'MC\\d+', str(i)).group() if re.search(r'MC\\d+', str(i)) else i for i in mcDf.columns]\n",
    "        else:\n",
    "            extracted_values = mcDf.columns.str.extract(r'(H/S|U/S)', expand=False).dropna()\n",
    "            changedCols = [re.search(r'MC\\d+', str(i)).group() for i in mcDf.columns if re.search(r'MC\\d+', str(i)) ]\n",
    "            # print(changedCols)\n",
    "            # print(extracted_values)\n",
    "            unchangedCols = [i for i in mcDf.columns if not re.search(r'MC\\d+', str(i))]\n",
    "            # print(unchangedCols)\n",
    "            changedCols = [changedCols[i] + ' ' + extracted_values[i] for i in range(len(changedCols))]\n",
    "            mcDf.columns = unchangedCols + changedCols\n",
    "            # print(extracted_values)\n",
    "            # Add H/S or U/S to the MC column based on what is present in the Abbreviation\n",
    "            # mcDf.columns = mcDf.columns + ' ' + extracted_values\n",
    "\n",
    "    def createPDF(self):\n",
    "\n",
    "        # Create a table with Date, and Items\n",
    "        # allSubjects = self.groupedDf[colSubject].unique()\n",
    "        # display(self.subjectDateItemDf)\n",
    "        if self.subjectDateItemDf.empty:\n",
    "            return\n",
    "        # print(self.subjectDateItemDf[colSubject].value_counts())\n",
    "        allSubjects = [self.subjectDateItemDf[colSubject].value_counts().idxmax()]\n",
    "        self.elements.append(Paragraph('Items Performed with dates', subheadingStyle))\n",
    "        self.elements.append(Spacer(1, 12))\n",
    "        for subject in allSubjects:\n",
    "            # tableDf = self.groupedDf[self.groupedDf[colSubject] == subject][[colDate, labelItem]]\n",
    "            tableDf = self.groupedDf[[colDate, labelItem]]\n",
    "            tableDf[colDate] = pd.to_datetime(tableDf[colDate], format = '%d/%m/%Y')\n",
    "            tableDf.sort_values(colDate, inplace=True)\n",
    "            tableDf[colDate] = tableDf[colDate].dt.strftime('%d/%m/%Y')\n",
    "            # tableDf[colDate] = tableDf[colDate].astype(str)\n",
    "            self.createTable(tableDf, subject, [2, 8], 0.9, [1], tableTextStyle)\n",
    "\n",
    "            # Create a table with the count of items\n",
    "            # itemCountDf = self.subjectDateItemDf[self.subjectDateItemDf[colSubject] == subject][labelItem].value_counts().reset_index()\n",
    "            itemCountDf = self.subjectDateItemDf[labelItem].value_counts().reset_index()\n",
    "            itemCountDf.columns = [labelItem, labelCountItem]\n",
    "            itemCountDf = itemCountDf.sort_values(labelCountItem, ascending=False)\n",
    "            # Add bar plot for the counts\n",
    "            fig, ax = plt.subplots(figsize=(figSize[0], figSize[1] / 2))\n",
    "            itemCountDf.plot(x=labelItem, y=labelCountItem, kind='bar', ax=ax, color='skyblue', legend=False)\n",
    "            ax.set_title(f'Count of items completed')\n",
    "            ax.set_xlabel('')\n",
    "            ax.set_ylabel('Count')\n",
    "            xlabels = [processLabel(i) for i in itemCountDf[labelItem]]\n",
    "            ax.set_xticklabels(xlabels, rotation=90, ha='center')\n",
    "            ax.yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "            ax.set_ylim(0, ax.get_ylim()[1] * 1.1)\n",
    "            if ax.get_ylim()[1] < 5:\n",
    "                ax.yaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "            plt.tight_layout()\n",
    "            self.addPlotImage(fig, 0.9)\n",
    "            # self.createTable(itemCountDf, f'Count of items for {subject}', [5, 2], 0.5, [0], tableTextStyle)\n",
    "\n",
    "        # Create a table with the CE\n",
    "        yesCE = self.ceGroupedDf[self.ceGroupedDf[colCE] == 'Yes'][[colDate, labelItem, colCE, colCEReason]]\n",
    "        # display(yesCE)\n",
    "    \n",
    "        # self.elements.append(Paragraph('Items with CE', subheadingStyle))\n",
    "        self.elements.append(Spacer(1, 12))\n",
    "        yesCE[colDate] = yesCE[colDate].astype(str)\n",
    "        self.createTable(yesCE, 'Critical Incidents', [2, 2.7, 2.3, 7], 0.9, [0, 1, 2, 3], tableTextStyle)\n",
    "\n",
    "        # General Information\n",
    "        if self.locationLabel == 'Clinic':\n",
    "            self.elements.append(Paragraph('Operator and Patient Count', subheadingStyle))\n",
    "            self.elements.append(Spacer(1, 12))\n",
    "            self.elements.append(Paragraph(f'Number of times Operator: {self.operatorCount}, Number of Patients Seen: {self.sawPatientCount}', normalLargeStyleCenter))\n",
    "            # self.elements.append(Spacer(1, 6))\n",
    "            # self.elements.append(Paragraph(f'Number of Patients Seen: {self.sawPatientCount}', normalLargeStyleCenter))\n",
    "\n",
    "        # Overall Rubric Information\n",
    "        self.elements.append(PageBreak())\n",
    "        self.elements.append(Paragraph('Overall Rubric Scores', subheadingStyle))\n",
    "        self.elements.append(Spacer(1, 30))\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(figSize[0]/1.1, figSize[1]/1.1))\n",
    "        colors = {1:'#0072B2', 2: '#E69F00', 3: '#009E73', 4: '#F0E442'}\n",
    "        axes = axes.flatten()\n",
    "        validAxes = 0\n",
    "        # display(self.rubricGroupedDf)\n",
    "        # replace 0 with 1\n",
    "        self.rubricGroupedDf.replace(0, 1, inplace=True)\n",
    "        for i, col in enumerate(rubricQues):\n",
    "            valueCounts = self.rubricGroupedDf[col].value_counts()\n",
    "            valueCounts.sort_index(inplace=True, ascending=False)\n",
    "            if len(valueCounts) == 0:\n",
    "                continue\n",
    "            self.plotPie(axes[validAxes], valueCounts, rubricTitle[col], colors)\n",
    "            validAxes += 1\n",
    "        \n",
    "        for ax in axes[validAxes:]:\n",
    "            fig.delaxes(ax)\n",
    "        plt.subplots_adjust(hspace=0.2, wspace=0.5)\n",
    "        plt.tight_layout()\n",
    "        self.addPlotImage(fig, 0.7)\n",
    "\n",
    "        # Add reference table\n",
    "        # self.elements.append(Paragraph('Rubric Reference Table', subsubheadingStyle))\n",
    "        self.createTable(rubricReferenceTableDf, 'Rubric Reference Table', [1, 4, 4, 4, 4], 0.95, [0, 1, 2, 3, 4], tableTextStyleSmall, 6, 6)\n",
    "        \n",
    "\n",
    "        # Add date series for each of the rubric questions (average for the date)\n",
    "        self.elements.append(PageBreak())\n",
    "        self.elements.append(Paragraph('Rubric Scores Over Time', subheadingStyle))\n",
    "        self.elements.append(Spacer(1, 30))\n",
    "\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(figSize[0]/1.0, figSize[1]/1.0))\n",
    "        axes = axes.flatten()\n",
    "        validAxes = 0\n",
    "        for i, col in enumerate(rubricQues):\n",
    "            data = self.rubricGroupedDfDate[[colDate, col]].dropna()\n",
    "            if data.empty:\n",
    "                continue\n",
    "            data[colDate] = data[colDate].astype(str)\n",
    "            print(data)\n",
    "            self.plotLineSeries(axes[validAxes], data, colDate, col, rubricTitle[col], colors[i+1])\n",
    "            validAxes += 1\n",
    "        \n",
    "        for ax in axes[validAxes:]:\n",
    "            fig.delaxes(ax)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "        self.addPlotImage(fig, 0.9)\n",
    "\n",
    "        # Add average rubric scores for each item\n",
    "        self.elements.append(PageBreak())\n",
    "        self.elements.append(Paragraph('Average Rubric Scores for Each Item', subheadingStyle))\n",
    "        self.elements.append(Spacer(1, 30))\n",
    "\n",
    "        fig, axes = plt.subplots(4, 1, figsize=(figSize[0]/1.2, figSize[1]/1.2))\n",
    "        axes = axes.flatten()\n",
    "        validAxes = 0\n",
    "        for i, col in enumerate(rubricQues):\n",
    "            data = self.rubricGroupedDfItem[[labelItem, col]].dropna()\n",
    "            data.sort_values(col, inplace=True, ascending=False)\n",
    "            if data.empty:\n",
    "                continue\n",
    "            # plot a bar plot\n",
    "            ax = axes[validAxes]\n",
    "            data.plot(x=labelItem, y=col, kind='bar', ax=axes[validAxes], color=colors[i+1], legend=False)\n",
    "            ax.set_title(rubricTitle[col])\n",
    "            ax.set_yticks(range(1, 5))\n",
    "            ax.set_ylim(0, 4.5)\n",
    "            newLables = [processLabel(label) for label in data[labelItem]]\n",
    "            ax.set_xticklabels(newLables, rotation=45, ha='center', fontsize=8)\n",
    "            # ax.set_xlabel(labelItem)\n",
    "            ax.set_ylabel('')\n",
    "            validAxes += 1\n",
    "\n",
    "        for ax in axes[validAxes:]:\n",
    "            fig.delaxes(ax)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        # plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "        self.addPlotImage(fig, 0.9)\n",
    "       \n",
    "\n",
    "        # Now time for MC plots\n",
    "        self.elements.append(PageBreak())\n",
    "        self.elements.append(Paragraph('Overall Marking Checklist Counts', subheadingStyle))\n",
    "        self.elements.append(Spacer(1, 30))\n",
    "        self.addGraphs(self.mcCountsDf, 6, 6, 2, colors = Checklistcolors)\n",
    "\n",
    "        # Go itemwise\n",
    "        for itemDisplay, countsMCWiseDf in self.countsMCWiseDfDict.items():\n",
    "            # if all the values are zero, skip the plot\n",
    "            if countsMCWiseDf.sum().sum() == 0:\n",
    "                continue\n",
    "            code = itemDisplay.split(' ')[0]\n",
    "            self.reIndexMcCountsDf(code, countsMCWiseDf)\n",
    "            self.elements.append(PageBreak())\n",
    "            fullMCDf = self.fullMCDfDict[itemDisplay]\n",
    "            fullMCDf.set_index(colDate, inplace=True)\n",
    "            # remove rows with all values as NA\n",
    "            fullMCDf.dropna(how='all', inplace=True)\n",
    "            fullMCDf.reset_index(inplace=True)\n",
    "\n",
    "            # If the maximum rowwise total of Yes, No and NA is less than equal to two, skip the plot and make table\n",
    "            if len(fullMCDf.index) > 2 or len(countsMCWiseDf.index) > 14:\n",
    "                self.elements.append(Paragraph(f'Marking Checklist Counts for {itemDisplay}', subheadingStyle))\n",
    "                self.elements.append(Spacer(1, 30))\n",
    "                self.addGraphs(countsMCWiseDf, 14, 3, 1, colors = Checklistcolors, dynamicHeight = False)\n",
    "\n",
    "            else:\n",
    "                # Full MC df\n",
    "                \n",
    "                self.renameMcColumns(code, fullMCDf)\n",
    "                # print(fullMCDf.columns)\n",
    "                fullMCDf[colDate] = fullMCDf[colDate].astype(str)\n",
    "                fullMCDf.replace({1: 'Yes', 0: 'No', 'NA': 'NA', np.nan: ''}, inplace=True)\n",
    "                # display(fullMCDf)\n",
    "                # split fullMCDf with max 14 columns in each table\n",
    "                # Maximum number of columns per table\n",
    "                max_columns = 18\n",
    "\n",
    "                # Initialize list to store DataFrame chunks\n",
    "                df_chunks = []\n",
    "                self.elements.append(Paragraph(f'Marking Checklist for {itemDisplay}', subheadingStyle))\n",
    "                self.elements.append(Spacer(1, 30))\n",
    "                # Split the DataFrame into chunks\n",
    "                for i in range(0, len(fullMCDf.columns), max_columns):\n",
    "                    # Select a chunk of columns\n",
    "                    df_chunk = fullMCDf.iloc[:, i:i + max_columns]\n",
    "                    \n",
    "                    # Add the chunk to the list\n",
    "                    df_chunks.append(df_chunk)\n",
    "\n",
    "                # Create tables for each chunk\n",
    "                for index, df_chunk in enumerate(df_chunks):\n",
    "                    # Adjust colRatio for the current chunk\n",
    "                    colRatio = [2] + [1 for _ in range(len(df_chunk.columns) - 1)]\n",
    "                    \n",
    "                    # Determine the title for the table\n",
    "                    if index == 0:\n",
    "                        title = ''\n",
    "                    else:\n",
    "                        title = ''  # No title for subsequent chunks\n",
    "                    \n",
    "                    # Create a table for the current chunk\n",
    "                    self.createTable(\n",
    "                        df_chunk, \n",
    "                        title, colRatio, 0.9, [0], tableTextStyle, 6, 6, cellHighlight=True\n",
    "                    )\n",
    "                # break\n",
    "            # Add the MC reference table\n",
    "            header = f\"Marking Checklist Reference for {itemDisplay}\"\n",
    "            header = Paragraph(header, subsubheadingStyle)\n",
    "            self.addMCReferenceTable(self.itemMCReferenceDict[itemDisplay], header)\n",
    "        self.doc.build(self.elements)\n",
    "    \n",
    "\n",
    "id = 1637313\n",
    "student = StudentInfo(id, 'Simulation')\n",
    "student.getDfs()\n",
    "student.createPDF()\n",
    "\n",
    "student = StudentInfo(id, 'Clinic')\n",
    "student.getDfs()\n",
    "student.createPDF()\n",
    "\n",
    "# id =1295910\n",
    "# student = StudentInfo(id, 'Simulation')\n",
    "# student.getDfs()\n",
    "# student.createPDF()\n",
    "\n",
    "# student = StudentInfo(id, 'Clinic')\n",
    "# student.getDfs()\n",
    "# student.createPDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1233586.0 Kristine Yako BOH3 Simulation\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 012_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 121_MC\\d+\n",
      "MC search pattern: 131_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "1233586.0 Kristine Yako BOH3 Clinic\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 012_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 121_MC\\d+\n",
      "MC search pattern: 131_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "         Date   PS\n",
      "0  10/10/2024  3.0\n",
      "1  14/10/2024  3.0\n",
      "2  30/09/2024  3.5\n",
      "Date PS 0    10/10/2024\n",
      "1    14/10/2024\n",
      "2    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.5\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  10/10/2024  3.0\n",
      "1  14/10/2024  3.0\n",
      "2  30/09/2024  3.5\n",
      "Date CS 0    10/10/2024\n",
      "1    14/10/2024\n",
      "2    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.5\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  10/10/2024  3.0\n",
      "1  14/10/2024  3.5\n",
      "2  30/09/2024  4.0\n",
      "Date TS 0    10/10/2024\n",
      "1    14/10/2024\n",
      "2    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.5\n",
      "2    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  10/10/2024  3.0\n",
      "1  14/10/2024  3.5\n",
      "2  30/09/2024  3.0\n",
      "Date ES 0    10/10/2024\n",
      "1    14/10/2024\n",
      "2    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.5\n",
      "2    3.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1233586.0\n",
      "1354025.0 Catrina Le BOH3 Simulation\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 142_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 521_MC\\d+\n",
      "MC search pattern: 524_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "1354025.0 Catrina Le BOH3 Clinic\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 142_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 521_MC\\d+\n",
      "MC search pattern: 524_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "         Date   PS\n",
      "0  02/10/2024  3.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.0\n",
      "3  16/10/2024  3.0\n",
      "4  26/09/2024  2.0\n",
      "5  30/09/2024  3.0\n",
      "Date PS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    26/09/2024\n",
      "5    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    2.0\n",
      "5    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  02/10/2024  3.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.0\n",
      "3  16/10/2024  3.0\n",
      "4  26/09/2024  2.0\n",
      "5  30/09/2024  3.0\n",
      "Date CS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    26/09/2024\n",
      "5    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    2.0\n",
      "5    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  02/10/2024  4.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  4.0\n",
      "3  16/10/2024  4.0\n",
      "4  26/09/2024  3.0\n",
      "5  30/09/2024  4.0\n",
      "Date TS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    26/09/2024\n",
      "5    30/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    3.0\n",
      "5    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  02/10/2024  3.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  4.0\n",
      "3  16/10/2024  4.0\n",
      "4  26/09/2024  3.0\n",
      "5  30/09/2024  4.0\n",
      "Date ES 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    26/09/2024\n",
      "5    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    3.0\n",
      "5    4.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1354025.0\n",
      "1343049.0 Xiaochuan Yang BOH3 Simulation\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 012_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 061_MC\\d+\n",
      "MC search pattern: 113_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 121_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 523_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "1343049.0 Xiaochuan Yang BOH3 Clinic\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 012_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 061_MC\\d+\n",
      "MC search pattern: 113_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 121_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 523_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "         Date   PS\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  3.0\n",
      "2  23/09/2024  3.0\n",
      "3  25/09/2024  3.0\n",
      "Date PS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    23/09/2024\n",
      "3    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  03/10/2024  2.0\n",
      "1  09/10/2024  3.0\n",
      "2  23/09/2024  3.0\n",
      "3  25/09/2024  3.0\n",
      "Date CS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    23/09/2024\n",
      "3    25/09/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  4.0\n",
      "2  23/09/2024  3.5\n",
      "3  25/09/2024  4.0\n",
      "Date TS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    23/09/2024\n",
      "3    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    4.0\n",
      "2    3.5\n",
      "3    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  3.0\n",
      "2  23/09/2024  3.0\n",
      "3  25/09/2024  4.0\n",
      "Date ES 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    23/09/2024\n",
      "3    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    4.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1343049.0\n",
      "1352187.0 Fathima Zakiya Ahamed Zuhdi BOH3 Simulation\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 061_MC\\d+\n",
      "MC search pattern: 072_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 131_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 533_MC\\d+\n",
      "MC search pattern: 534_MC\\d+\n",
      "MC search pattern: 572_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "1352187.0 Fathima Zakiya Ahamed Zuhdi BOH3 Clinic\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 061_MC\\d+\n",
      "MC search pattern: 072_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 131_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 533_MC\\d+\n",
      "MC search pattern: 534_MC\\d+\n",
      "MC search pattern: 572_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "         Date   PS\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  3.0\n",
      "2  17/10/2024  4.0\n",
      "3  23/09/2024  3.0\n",
      "4  25/09/2024  3.0\n",
      "Date PS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date        CS\n",
      "0  03/10/2024       2.5\n",
      "1  09/10/2024       3.0\n",
      "2  17/10/2024       4.0\n",
      "3  23/09/2024  2.666667\n",
      "4  25/09/2024       3.0\n",
      "Date CS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0         2.5\n",
      "1         3.0\n",
      "2         4.0\n",
      "3    2.666667\n",
      "4         3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date        TS\n",
      "0  03/10/2024       3.5\n",
      "1  09/10/2024       4.0\n",
      "2  17/10/2024       3.0\n",
      "3  23/09/2024  3.333333\n",
      "4  25/09/2024       4.0\n",
      "Date TS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0         3.5\n",
      "1         4.0\n",
      "2         3.0\n",
      "3    3.333333\n",
      "4         4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date        ES\n",
      "0  03/10/2024       3.0\n",
      "1  09/10/2024       3.0\n",
      "2  17/10/2024       3.0\n",
      "3  23/09/2024  3.333333\n",
      "4  25/09/2024       3.0\n",
      "Date ES 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0         3.0\n",
      "1         3.0\n",
      "2         3.0\n",
      "3    3.333333\n",
      "4         3.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1352187.0\n",
      "1337581.0 Anjeela Khaliq BOH3 Simulation\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 014_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 131_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 161_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 411_MC\\d+\n",
      "MC search pattern: 523_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "1337581.0 Anjeela Khaliq BOH3 Clinic\n",
      "MC search pattern: 011_MC\\d+\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 014_MC\\d+\n",
      "MC search pattern: 022_MC\\d+\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 131_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 161_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 411_MC\\d+\n",
      "MC search pattern: 523_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "         Date   PS\n",
      "0  02/10/2024  3.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.0\n",
      "3  16/10/2024  3.0\n",
      "4  30/09/2024  3.0\n",
      "Date PS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  02/10/2024  3.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.0\n",
      "3  16/10/2024  3.0\n",
      "4  30/09/2024  3.0\n",
      "Date CS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  02/10/2024  4.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  4.0\n",
      "3  16/10/2024  4.0\n",
      "4  30/09/2024  3.0\n",
      "Date TS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    3.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  02/10/2024  4.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.5\n",
      "3  16/10/2024  4.0\n",
      "4  30/09/2024  3.0\n",
      "Date ES 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    3.0\n",
      "2    3.5\n",
      "3    4.0\n",
      "4    3.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1337581.0\n",
      "1362971.0 Martina Selim BOH3 Simulation\n",
      "MC search pattern: 012_MC\\d+\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 113_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: 533_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "1362971.0 Martina Selim BOH3 Clinic\n",
      "MC search pattern: 012_MC\\d+\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 113_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 222_MC\\d+\n",
      "MC search pattern: 531_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: 533_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "         Date   PS\n",
      "0  02/10/2024  3.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.0\n",
      "3  16/10/2024  3.0\n",
      "4  30/09/2024  3.0\n",
      "Date PS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  02/10/2024  3.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.0\n",
      "3  16/10/2024  3.0\n",
      "4  30/09/2024  3.0\n",
      "Date CS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  02/10/2024  4.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  4.0\n",
      "3  16/10/2024  4.0\n",
      "4  30/09/2024  4.0\n",
      "Date TS 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  02/10/2024  4.0\n",
      "1  10/10/2024  3.0\n",
      "2  14/10/2024  3.5\n",
      "3  16/10/2024  4.0\n",
      "4  30/09/2024  4.0\n",
      "Date ES 0    02/10/2024\n",
      "1    10/10/2024\n",
      "2    14/10/2024\n",
      "3    16/10/2024\n",
      "4    30/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    3.0\n",
      "2    3.5\n",
      "3    4.0\n",
      "4    4.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1362971.0\n",
      "1354147.0 Jessica Fry BOH3 Simulation\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 121_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 524_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "1354147.0 Jessica Fry BOH3 Clinic\n",
      "MC search pattern: 013_MC\\d+\n",
      "MC search pattern: 114_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 121_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 221_MC\\d+\n",
      "MC search pattern: 524_MC\\d+\n",
      "MC search pattern: 532_MC\\d+\n",
      "MC search pattern: LA_MC\\d+\n",
      "         Date   PS\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  4.0\n",
      "2  17/10/2024  3.0\n",
      "3  23/09/2024  3.0\n",
      "4  25/09/2024  3.0\n",
      "Date PS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    4.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  4.0\n",
      "2  17/10/2024  3.0\n",
      "3  23/09/2024  3.0\n",
      "4  25/09/2024  3.0\n",
      "Date CS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    4.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  03/10/2024  3.5\n",
      "1  09/10/2024  4.0\n",
      "2  17/10/2024  4.0\n",
      "3  23/09/2024  3.5\n",
      "4  25/09/2024  4.0\n",
      "Date TS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0    3.5\n",
      "1    4.0\n",
      "2    4.0\n",
      "3    3.5\n",
      "4    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  03/10/2024  3.5\n",
      "1  09/10/2024  3.0\n",
      "2  17/10/2024  4.0\n",
      "3  23/09/2024  3.5\n",
      "4  25/09/2024  3.0\n",
      "Date ES 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    17/10/2024\n",
      "3    23/09/2024\n",
      "4    25/09/2024\n",
      "Name: Date, dtype: object 0    3.5\n",
      "1    3.0\n",
      "2    4.0\n",
      "3    3.5\n",
      "4    3.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1354147.0\n",
      "1350430.0 Uyen Phan BOH3 Simulation\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 521_MC\\d+\n",
      "1350430.0 Uyen Phan BOH3 Clinic\n",
      "MC search pattern: 111_MC\\d+\n",
      "MC search pattern: 115_MC\\d+\n",
      "MC search pattern: 141_MC\\d+\n",
      "MC search pattern: 521_MC\\d+\n",
      "         Date   PS\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  3.0\n",
      "2  25/09/2024  3.0\n",
      "Date PS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  03/10/2024  3.0\n",
      "1  09/10/2024  3.0\n",
      "2  25/09/2024  3.0\n",
      "Date CS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    25/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  03/10/2024  4.0\n",
      "1  09/10/2024  4.0\n",
      "2  25/09/2024  4.0\n",
      "Date TS 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    25/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    4.0\n",
      "2    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  03/10/2024  4.0\n",
      "1  09/10/2024  3.0\n",
      "2  25/09/2024  4.0\n",
      "Date ES 0    03/10/2024\n",
      "1    09/10/2024\n",
      "2    25/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1350430.0\n",
      "996164.0 Jennifer Ha BOH3 Simulation\n",
      "MC search pattern: 123_MC\\d+\n",
      "MC search pattern: 587_MC\\d+\n",
      "996164.0 Jennifer Ha BOH3 Clinic\n",
      "MC search pattern: 123_MC\\d+\n",
      "MC search pattern: 587_MC\\d+\n",
      "         Date   PS\n",
      "0  04/07/2024  3.0\n",
      "1  16/09/2024  3.0\n",
      "Date PS 0    04/07/2024\n",
      "1    16/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  04/07/2024  3.0\n",
      "1  16/09/2024  3.0\n",
      "Date CS 0    04/07/2024\n",
      "1    16/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  04/07/2024  4.0\n",
      "1  16/09/2024  4.0\n",
      "Date TS 0    04/07/2024\n",
      "1    16/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  04/07/2024  4.0\n",
      "1  16/09/2024  4.0\n",
      "Date ES 0    04/07/2024\n",
      "1    16/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    4.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 996164.0\n",
      "1350428.0 Monique Huynh BOH3 Simulation\n",
      "MC search pattern: 123_MC\\d+\n",
      "1350428.0 Monique Huynh BOH3 Clinic\n",
      "MC search pattern: 123_MC\\d+\n",
      "         Date   PS\n",
      "0  16/09/2024  3.0\n",
      "Date PS 0    16/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  16/09/2024  3.0\n",
      "Date CS 0    16/09/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  16/09/2024  4.0\n",
      "Date TS 0    16/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  16/09/2024  4.0\n",
      "Date ES 0    16/09/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1350428.0\n",
      "1350539.0 Stephanie Tat BOH3 Simulation\n",
      "MC search pattern: 123_MC\\d+\n",
      "1350539.0 Stephanie Tat BOH3 Clinic\n",
      "MC search pattern: 123_MC\\d+\n",
      "         Date   PS\n",
      "0  29/07/2024  3.0\n",
      "Date PS 0    29/07/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  29/07/2024  3.0\n",
      "Date CS 0    29/07/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  29/07/2024  4.0\n",
      "Date TS 0    29/07/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  29/07/2024  3.0\n",
      "Date ES 0    29/07/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1350539.0\n",
      "1081205.0 Mona Zhao BOH3 Simulation\n",
      "MC search pattern: 123_MC\\d+\n",
      "MC search pattern: 522_MC\\d+\n",
      "MC search pattern: 577_MC\\d+\n",
      "1081205.0 Mona Zhao BOH3 Clinic\n",
      "MC search pattern: 123_MC\\d+\n",
      "MC search pattern: 522_MC\\d+\n",
      "MC search pattern: 577_MC\\d+\n",
      "         Date   PS\n",
      "0  12/08/2024  3.0\n",
      "1  18/09/2024  3.0\n",
      "2  24/06/2024  4.0\n",
      "Date PS 0    12/08/2024\n",
      "1    18/09/2024\n",
      "2    24/06/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  12/08/2024  3.0\n",
      "1  18/09/2024  3.0\n",
      "2  24/06/2024  4.0\n",
      "Date CS 0    12/08/2024\n",
      "1    18/09/2024\n",
      "2    24/06/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "2    4.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  12/08/2024  4.0\n",
      "1  18/09/2024  4.0\n",
      "2  24/06/2024  4.0\n",
      "Date TS 0    12/08/2024\n",
      "1    18/09/2024\n",
      "2    24/06/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    4.0\n",
      "2    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  12/08/2024  3.0\n",
      "1  18/09/2024  4.0\n",
      "2  24/06/2024  2.0\n",
      "Date ES 0    12/08/2024\n",
      "1    18/09/2024\n",
      "2    24/06/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    4.0\n",
      "2    2.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1081205.0\n",
      "1268620.0 Xin-Pei Hsieh BOH3 Simulation\n",
      "MC search pattern: 123_MC\\d+\n",
      "1268620.0 Xin-Pei Hsieh BOH3 Clinic\n",
      "MC search pattern: 123_MC\\d+\n",
      "         Date   PS\n",
      "0  22/02/2024  3.0\n",
      "Date PS 0    22/02/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  22/02/2024  3.0\n",
      "Date CS 0    22/02/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  22/02/2024  3.0\n",
      "Date TS 0    22/02/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  22/02/2024  3.0\n",
      "Date ES 0    22/02/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1268620.0\n",
      "1180109.0 Paloma Araos-West BOH3 Simulation\n",
      "MC search pattern: 511_MC\\d+\n",
      "1180109.0 Paloma Araos-West BOH3 Clinic\n",
      "MC search pattern: 511_MC\\d+\n",
      "Completed 1180109.0\n",
      "1354103.0 Yaanula Wanigasekera BOH3 Simulation\n",
      "MC search pattern: 522_MC\\d+\n",
      "1354103.0 Yaanula Wanigasekera BOH3 Clinic\n",
      "MC search pattern: 522_MC\\d+\n",
      "         Date   PS\n",
      "0  04/07/2024  3.0\n",
      "1  24/06/2024  3.0\n",
      "Date PS 0    04/07/2024\n",
      "1    24/06/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  04/07/2024  3.0\n",
      "1  24/06/2024  3.0\n",
      "Date CS 0    04/07/2024\n",
      "1    24/06/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  04/07/2024  4.0\n",
      "1  24/06/2024  4.0\n",
      "Date TS 0    04/07/2024\n",
      "1    24/06/2024\n",
      "Name: Date, dtype: object 0    4.0\n",
      "1    4.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  04/07/2024  3.0\n",
      "1  24/06/2024  3.0\n",
      "Date ES 0    04/07/2024\n",
      "1    24/06/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "1    3.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1354103.0\n",
      "1354146.0 Nestor Del Carmen BOH3 Simulation\n",
      "MC search pattern: 587_MC\\d+\n",
      "1354146.0 Nestor Del Carmen BOH3 Clinic\n",
      "MC search pattern: 587_MC\\d+\n",
      "         Date   PS\n",
      "0  27/06/2024  2.0\n",
      "Date PS 0    27/06/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "Name: PS, dtype: Float64\n",
      "         Date   CS\n",
      "0  27/06/2024  2.0\n",
      "Date CS 0    27/06/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "Name: CS, dtype: Float64\n",
      "         Date   TS\n",
      "0  27/06/2024  3.0\n",
      "Date TS 0    27/06/2024\n",
      "Name: Date, dtype: object 0    3.0\n",
      "Name: TS, dtype: Float64\n",
      "         Date   ES\n",
      "0  27/06/2024  2.0\n",
      "Date ES 0    27/06/2024\n",
      "Name: Date, dtype: object 0    2.0\n",
      "Name: ES, dtype: Float64\n",
      "Completed 1354146.0\n"
     ]
    }
   ],
   "source": [
    "for id in studentDict.keys():\n",
    "    if id in completed:\n",
    "        continue\n",
    "    student = StudentInfo(id, 'Simulation')\n",
    "    student.getDfs()\n",
    "    student.createPDF()\n",
    "\n",
    "    student = StudentInfo(id, 'Clinic')\n",
    "    student.getDfs()\n",
    "    student.createPDF()\n",
    "    print(f'Completed {id}')\n",
    "    completed.append(id)\n",
    "    with open('students done.npy', 'wb') as f:\n",
    "        np.save(f, completed)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Later Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamically add element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def addElement(self, element):\n",
    "#     # Estimate the height of the element\n",
    "#     element_height = self.estimateElementHeight(element)\n",
    "\n",
    "#     # Check if the element fits in the remaining space\n",
    "#     if self.y_pos - element_height < bottomMargin:\n",
    "#         self.elements.append(PageBreak())\n",
    "#         self.y_pos = self.page_height - topMargin  # Reset position for new page\n",
    "\n",
    "#     # Add the element and adjust the remaining space\n",
    "#     self.elements.append(element)\n",
    "#     self.y_pos -= element_height\n",
    "\n",
    "# def estimateElementHeight(self, element):\n",
    "#     if isinstance(element, Spacer):\n",
    "#         return element.height\n",
    "#     elif isinstance(element, Paragraph):\n",
    "#         return element.wrap(self.page_width - leftMargin - rightMargin, self.page_height)[1]\n",
    "#     elif isinstance(element, Table):\n",
    "#         # Wrap the table to get its height\n",
    "#         return element.wrap(self.page_width - leftMargin - rightMargin, self.page_height)[1]\n",
    "#     else:\n",
    "#         return 0  # Default case, can be expanded based on element type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
